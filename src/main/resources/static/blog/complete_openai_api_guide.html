<!DOCTYPE html><!--N_0l2p_6kjCD7mOd_93Pj--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/aea965b6eab027a3.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-ca26d2052b029d27.js"/><script src="/_next/static/chunks/4bd1b696-409494caf8c83275.js" async=""></script><script src="/_next/static/chunks/255-4b295af61a735c07.js" async=""></script><script src="/_next/static/chunks/main-app-ce81299649427511.js" async=""></script><script src="/_next/static/chunks/335-ebaa30ec5d8be766.js" async=""></script><script src="/_next/static/chunks/619-1108b4c084a63a2d.js" async=""></script><script src="/_next/static/chunks/26-c8312ff7df085f9c.js" async=""></script><script src="/_next/static/chunks/552-7a1a7c42975f72da.js" async=""></script><script src="/_next/static/chunks/298-4e2d45a58d8b8e81.js" async=""></script><script src="/_next/static/chunks/app/layout-aa3aaf2a5ede1856.js" async=""></script><script src="/_next/static/chunks/356-47b75043c8e7fd96.js" async=""></script><script src="/_next/static/chunks/242-225df27543a9ab2e.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bid%5D/page-8e144e2fb57494e5.js" async=""></script><meta name="next-size-adjust" content=""/><title>The Complete Guide to OpenAI API: A Practical Developer&#x27;s Handbook | Hung Pham</title><meta name="description" content="Explore a complete guide to the OpenAI API, covering everything from setup and core functionality to advanced features, performance optimization, error handling, and practical use cases. Perfect for developers looking to integrate and leverage OpenAI models effectively."/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_f367f3 antialiased"><div hidden=""><!--$--><!--/$--></div><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&false)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}else{c.add('dark')}if(e==='light'||e==='dark'||!e)d.style.colorScheme=e||'dark'}catch(e){}}()</script><div data-overlay-container="true"><div class="min-h-screen bg-background text-foreground"><header class="sticky top-0 z-50 w-full border-b border-border/40 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><nav class="container mx-auto px-4 sm:px-6 lg:px-8"><div class="flex h-16 items-center justify-between"><div class="flex items-center"><a class="text-3xl font-bold text-foreground" href="/">âµ£</a></div><div class="hidden md:block"><div class="ml-10 flex items-center space-x-4"><a class="group flex items-center rounded-md px-3 py-2 text-sm font-medium text-foreground/80 hover:text-foreground" href="/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-house mr-2 h-5 w-5" aria-hidden="true"><path d="M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"></path><path d="M3 10a2 2 0 0 1 .709-1.528l7-5.999a2 2 0 0 1 2.582 0l7 5.999A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path></svg>Home<span class="absolute bottom-0 left-0 h-0.5 w-full scale-x-0 transform bg-primary group-hover:scale-x-100"></span></a><a class="group flex items-center rounded-md px-3 py-2 text-sm font-medium text-foreground/80 hover:text-foreground" href="/projects"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-briefcase mr-2 h-5 w-5" aria-hidden="true"><path d="M16 20V4a2 2 0 0 0-2-2h-4a2 2 0 0 0-2 2v16"></path><rect width="20" height="14" x="2" y="6" rx="2"></rect></svg>Projects<span class="absolute bottom-0 left-0 h-0.5 w-full scale-x-0 transform bg-primary group-hover:scale-x-100"></span></a><a class="group flex items-center rounded-md px-3 py-2 text-sm font-medium text-foreground/80 hover:text-foreground" href="/blog"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-book-open mr-2 h-5 w-5" aria-hidden="true"><path d="M12 7v14"></path><path d="M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z"></path></svg>Blog<span class="absolute bottom-0 left-0 h-0.5 w-full scale-x-0 transform bg-primary group-hover:scale-x-100"></span></a><a class="group flex items-center rounded-md px-3 py-2 text-sm font-medium text-foreground/80 hover:text-foreground" href="/tech-stack-architect"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-box mr-2 h-5 w-5" aria-hidden="true"><path d="M21 8a2 2 0 0 0-1-1.73l-7-4a2 2 0 0 0-2 0l-7 4A2 2 0 0 0 3 8v8a2 2 0 0 0 1 1.73l7 4a2 2 0 0 0 2 0l7-4A2 2 0 0 0 21 16Z"></path><path d="m3.3 7 8.7 5 8.7-5"></path><path d="M12 22V12"></path></svg>Stack Architect<span class="absolute bottom-0 left-0 h-0.5 w-full scale-x-0 transform bg-primary group-hover:scale-x-100"></span></a></div></div><div class="hidden md:block"><div class="ml-4 flex items-center md:ml-6"><div class="h-6 w-6" aria-hidden="true"></div></div></div><div class="-mr-2 flex md:hidden"><button class="inline-flex items-center justify-center rounded-md p-2 text-foreground focus:outline-none focus:ring-2 focus:ring-inset focus:ring-primary"><span class="sr-only">Open main menu</span><svg class="block h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></nav></header><main class="py-8 px-4 md:px-6 mx-auto max-w-7xl"><div class="max-w-7xl mx-auto px-4 py-12"><a class="inline-flex items-center text-blue-600 hover:text-blue-800 mb-6 transition-colors duration-200" href="/blog"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left mr-2" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg><span class="text-lg">Back to blog</span></a><div class="grid grid-cols-1 lg:grid-cols-[1fr_280px] gap-8"><div class="max-w-3xl mx-auto lg:mx-0 w-full"><h1 class="text-3xl md:text-4xl lg:text-5xl font-bold mb-6 text-gray-900 dark:text-white leading-tight">The Complete Guide to OpenAI API: A Practical Developer&#x27;s Handbook</h1><div class="flex flex-wrap items-center text-sm text-gray-600 dark:text-gray-400 mb-8 space-x-4"><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar mr-2" aria-hidden="true"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>2025-04-03</span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock mr-2" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>125 min read</span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag mr-2" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Artificial Intelligence</span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-user mr-2" aria-hidden="true"><path d="M19 21v-2a4 4 0 0 0-4-4H9a4 4 0 0 0-4 4v2"></path><circle cx="12" cy="7" r="4"></circle></svg>Hung Pham</span></div><img alt="The Complete Guide to OpenAI API: A Practical Developer&#x27;s Handbook" width="800" height="400" decoding="async" data-nimg="1" class="rounded-lg mb-8 object-cover w-full" style="color:transparent"/><div class="block lg:hidden mb-8"></div><article class="overflow-hidden"><div class="prose dark:prose-invert max-w-none"><p class="my-4 leading-relaxed">In the rapidly evolving landscape of artificial intelligence, few technologies have made as significant an impact as OpenAI&#x27;s suite of powerful language models. At the forefront of this revolution is the OpenAI API, a versatile interface that grants developers access to some of the most sophisticated AI models ever created. Whether you&#x27;re building a conversational assistant, automating content generation, or implementing advanced natural language processing capabilities, the OpenAI API offers unprecedented opportunities to integrate cutting-edge AI into your applications.</p>
<p class="my-4 leading-relaxed">The journey of OpenAI&#x27;s API offerings has been nothing short of remarkable. What began with GPT-3 has evolved into a comprehensive ecosystem of models and services, each designed to address specific use cases and requirements. From the versatile GPT-4o to specialized tools for embeddings, moderation, and fine-tuning, the OpenAI API has expanded to meet the growing demands of developers and businesses worldwide.</p>
<p class="my-4 leading-relaxed">This comprehensive guide is crafted for developers, data scientists, product managers, and businesses looking to harness the full potential of OpenAI&#x27;s technology. Whether you&#x27;re taking your first steps into the world of AI or seeking to optimize your existing implementations, this resource aims to provide you with the knowledge, best practices, and practical examples needed to succeed.</p>
<h2 class="text-3xl font-semibold my-5">Who This Guide Is For</h2>
<p class="my-4 leading-relaxed">This guide is designed to serve a diverse audience with varying levels of expertise:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Developers</strong> seeking to integrate AI capabilities into their applications</li>
<li class="pl-2"><strong>Data scientists</strong> looking to leverage language models for analysis and insights</li>
<li class="pl-2"><strong>Product managers</strong> exploring AI features for their product roadmaps</li>
<li class="pl-2"><strong>Businesses</strong> evaluating the potential of AI to transform their operations</li>
<li class="pl-2"><strong>AI enthusiasts</strong> wanting to deepen their understanding of large language models</li>
</ul>
<p class="my-4 leading-relaxed">No matter where you fall on this spectrum, you&#x27;ll find valuable insights tailored to your needs and experience level.</p>
<h2 class="text-3xl font-semibold my-5">What You&#x27;ll Learn</h2>
<p class="my-4 leading-relaxed">By the end of this comprehensive guide, you will have gained:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">A thorough understanding of the OpenAI API architecture and capabilities</li>
<li class="pl-2">Practical knowledge of how to authenticate, make requests, and process responses</li>
<li class="pl-2">Insights into choosing the right models for specific use cases</li>
<li class="pl-2">Hands-on experience with code examples covering various API features</li>
<li class="pl-2">Strategies for optimizing performance and managing costs</li>
<li class="pl-2">Best practices for error handling, security, and responsible AI implementation</li>
<li class="pl-2">Awareness of ethical considerations and limitations of AI models</li>
</ul>
<h2 class="text-3xl font-semibold my-5">The Evolution of OpenAI&#x27;s API</h2>
<p class="my-4 leading-relaxed">The OpenAI API has undergone significant evolution since its initial release. What started as access to a single model has expanded into a comprehensive platform offering multiple specialized services:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>2020</strong>: Initial release of the GPT-3 API with text completion capabilities</li>
<li class="pl-2"><strong>2021</strong>: Introduction of Codex models for code generation and understanding</li>
<li class="pl-2"><strong>2022</strong>: Launch of DALL-E for image generation and GPT-3.5 series models</li>
<li class="pl-2"><strong>2023</strong>: Release of GPT-4, function calling capabilities, and the Assistants API</li>
<li class="pl-2"><strong>2024</strong>: Introduction of GPT-4o, multimodal capabilities, and the Responses API</li>
</ul>
<p class="my-4 leading-relaxed">Each iteration has brought improvements in capabilities, performance, and usability, making the API more powerful and accessible to developers worldwide.</p>
<h2 class="text-3xl font-semibold my-5">Why OpenAI API Matters</h2>
<p class="my-4 leading-relaxed">The significance of the OpenAI API extends beyond its technical capabilities. It represents a democratization of advanced AI technology, allowing organizations of all sizes to implement solutions that were previously only available to those with extensive resources and expertise. This accessibility has sparked innovation across industries, from healthcare and education to customer service and content creation.</p>
<p class="my-4 leading-relaxed">For developers, the API offers a way to focus on building valuable applications without needing to train and maintain complex AI models. For businesses, it provides a competitive edge through enhanced automation, personalization, and data analysis capabilities. And for society at large, it presents both opportunities and challenges as we navigate the implications of increasingly capable AI systems.</p>
<h2 class="text-3xl font-semibold my-5">The Current Landscape</h2>
<p class="my-4 leading-relaxed">As of 2025, the OpenAI API stands at the intersection of several important trends in AI development:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Multimodal capabilities</strong> that combine text, image, and potentially other forms of data</li>
<li class="pl-2"><strong>Specialized models</strong> optimized for specific tasks and domains</li>
<li class="pl-2"><strong>Enhanced reasoning abilities</strong> that approach human-like problem-solving in certain contexts</li>
<li class="pl-2"><strong>Improved fine-tuning</strong> options for customizing models to specific use cases</li>
<li class="pl-2"><strong>Greater focus on responsible AI</strong> development and deployment</li>
</ol>
<p class="my-4 leading-relaxed">Understanding these trends is crucial for developers looking to make the most of the API&#x27;s capabilities while navigating its limitations and ethical considerations.</p>
<h2 class="text-3xl font-semibold my-5">Getting the Most from This Guide</h2>
<p class="my-4 leading-relaxed">To maximize the value of this guide, we recommend:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Following along with the code examples in your own development environment</li>
<li class="pl-2">Experimenting with different parameters and inputs to understand their effects</li>
<li class="pl-2">Referring to the official OpenAI documentation for the most up-to-date information</li>
<li class="pl-2">Joining community forums to share experiences and learn from other developers</li>
<li class="pl-2">Approaching AI implementation with both creativity and responsibility</li>
</ul>
<p class="my-4 leading-relaxed">The field of AI is evolving rapidly, and staying informed about the latest developments will help you make the most of these powerful tools.</p>
<p class="my-4 leading-relaxed">In the following sections, we&#x27;ll dive deeper into the technical aspects of the OpenAI API, starting with a comprehensive overview of its architecture and components. Whether you&#x27;re building your first AI-powered application or optimizing an existing one, this guide will provide you with the knowledge and tools you need to succeed.</p>
<p class="my-4 leading-relaxed">Let&#x27;s begin our journey into the world of OpenAI&#x27;s API.</p>
<h1 class="text-4xl font-bold my-6">Understanding the OpenAI API</h1>
<h2 class="text-3xl font-semibold my-5">What is the OpenAI API?</h2>
<p class="my-4 leading-relaxed">The OpenAI API provides developers with access to OpenAI&#x27;s state-of-the-art artificial intelligence models through a simple and consistent interface. At its core, the API serves as a bridge between your applications and OpenAI&#x27;s powerful language models, allowing you to integrate advanced AI capabilities without needing to train or maintain complex models yourself.</p>
<p class="my-4 leading-relaxed">Unlike traditional APIs that might perform specific, limited functions, the OpenAI API offers a versatile set of capabilities that can be applied to virtually any task involving language understanding, generation, or reasoning. This flexibility makes it suitable for a wide range of applications, from conversational agents and content creation to data analysis and code generation.</p>
<h2 class="text-3xl font-semibold my-5">Key Features and Capabilities</h2>
<p class="my-4 leading-relaxed">The OpenAI API offers a comprehensive set of features designed to meet diverse development needs:</p>
<h3 class="text-2xl font-semibold my-4">Natural Language Processing</h3>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Text generation with human-like quality</li>
<li class="pl-2">Summarization of long documents</li>
<li class="pl-2">Question answering based on provided context</li>
<li class="pl-2">Language translation across numerous languages</li>
<li class="pl-2">Sentiment analysis and emotion detection</li>
<li class="pl-2">Entity recognition and extraction</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Reasoning and Problem-Solving</h3>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Step-by-step problem decomposition</li>
<li class="pl-2">Logical reasoning through complex scenarios</li>
<li class="pl-2">Mathematical calculations and equation solving</li>
<li class="pl-2">Decision-making based on provided criteria</li>
<li class="pl-2">Structured data extraction from unstructured text</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Creative Content Generation</h3>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Writing in various styles and formats</li>
<li class="pl-2">Story and narrative creation</li>
<li class="pl-2">Marketing copy and product descriptions</li>
<li class="pl-2">Email drafting and communication assistance</li>
<li class="pl-2">Poetry, scripts, and creative writing</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Code and Technical Capabilities</h3>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Code generation in multiple programming languages</li>
<li class="pl-2">Code explanation and documentation</li>
<li class="pl-2">Debugging assistance</li>
<li class="pl-2">Converting natural language to code</li>
<li class="pl-2">API documentation generation</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Multimodal Understanding</h3>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Processing and analyzing images alongside text</li>
<li class="pl-2">Describing visual content</li>
<li class="pl-2">Answering questions about images</li>
<li class="pl-2">Generating text based on visual inputs</li>
</ul>
<h2 class="text-3xl font-semibold my-5">API Architecture and Components</h2>
<p class="my-4 leading-relaxed">The OpenAI API is structured around several key components that work together to provide a comprehensive development platform:</p>
<h3 class="text-2xl font-semibold my-4">Core APIs</h3>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Chat Completions API</strong>: The traditional interface for interacting with OpenAI&#x27;s models, structured around conversation-style interactions with role-based messages.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Responses API</strong>: A newer, streamlined interface that simplifies interactions with the models and provides enhanced capabilities for certain use cases.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Embeddings API</strong>: Generates vector representations of text that capture semantic meaning, useful for search, clustering, and recommendations.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Moderation API</strong>: Helps identify potentially harmful or inappropriate content to ensure responsible AI use.</p>
</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Specialized Services</h3>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Assistants API</strong>: A higher-level interface for building AI assistants with persistent memory and specialized tools.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Fine-tuning API</strong>: Allows customization of models for specific use cases by training on your own data.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Files API</strong>: Manages file uploads for use with various API features.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Batch API</strong>: Enables processing large volumes of requests efficiently.</p>
</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Supporting Infrastructure</h3>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Authentication System</strong>: Secures API access through API keys and organization IDs.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Rate Limiting</strong>: Manages request volumes to ensure fair usage and system stability.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Monitoring and Logging</strong>: Provides visibility into API usage and performance.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Versioning System</strong>: Ensures compatibility as the API evolves.</p>
</li>
</ol>
<h2 class="text-3xl font-semibold my-5">Responses API vs. Chat Completions API</h2>
<p class="my-4 leading-relaxed">OpenAI offers two primary interfaces for generating text with their models: the newer Responses API and the traditional Chat Completions API. Understanding the differences between these interfaces is crucial for choosing the right approach for your application.</p>
<h3 class="text-2xl font-semibold my-4">Responses API</h3>
<p class="my-4 leading-relaxed">The Responses API represents OpenAI&#x27;s latest approach to model interaction, designed to simplify the developer experience while offering enhanced capabilities:</p>
<p class="my-4 leading-relaxed"><strong>Key Features:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Streamlined interface with fewer required parameters</li>
<li class="pl-2">Built-in support for multimodal inputs (text and images)</li>
<li class="pl-2">Simplified handling of conversation context</li>
<li class="pl-2">More consistent output formatting</li>
<li class="pl-2">Enhanced support for structured outputs</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Example Usage:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant that provides concise explanations.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What is the difference between supervised and unsupervised learning?&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Chat Completions API</h3>
<p class="my-4 leading-relaxed">The Chat Completions API is the traditional interface that has been available since the introduction of ChatGPT models:</p>
<p class="my-4 leading-relaxed"><strong>Key Features:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Fine-grained control through numerous parameters</li>
<li class="pl-2">Explicit conversation management through message arrays</li>
<li class="pl-2">Support for function calling</li>
<li class="pl-2">Detailed token usage information</li>
<li class="pl-2">Compatibility with a wider range of models</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Example Usage:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>completion </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant that provides concise explanations.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What is the difference between supervised and unsupervised learning?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>completion</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">When to Use Each API</h3>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Choose the Responses API when:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">You need a simpler interface with fewer parameters</li>
<li class="pl-2">You&#x27;re working with multimodal inputs (text + images)</li>
<li class="pl-2">You want more consistent output formatting</li>
<li class="pl-2">You&#x27;re building new applications from scratch</li>
</ul>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Choose the Chat Completions API when:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">You need maximum control over model parameters</li>
<li class="pl-2">You&#x27;re implementing complex function calling</li>
<li class="pl-2">You require detailed token usage statistics</li>
<li class="pl-2">You&#x27;re maintaining existing applications built on this API</li>
</ul>
</li>
</ul>
<p class="my-4 leading-relaxed">Both APIs access the same underlying models and capabilities, so your choice should be based on your specific development needs and preferences rather than model performance considerations.</p>
<p class="my-4 leading-relaxed">In the following sections, we&#x27;ll explore how to get started with the OpenAI API, including account setup, authentication, and making your first API calls.</p>
<h1 class="text-4xl font-bold my-6">Getting Started with OpenAI API</h1>
<h2 class="text-3xl font-semibold my-5">Creating an OpenAI Account</h2>
<p class="my-4 leading-relaxed">Before you can start using the OpenAI API, you&#x27;ll need to create an account and obtain API credentials. The process is straightforward:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Visit the OpenAI Platform</strong>: Navigate to <a class="text-blue-600 hover:underline" href="https://platform.openai.com">platform.openai.com</a> and click on the &quot;Sign Up&quot; button.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Create Your Account</strong>: You can sign up using an email address and password, or through single sign-on options like Google or Microsoft accounts.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Verify Your Email</strong>: Check your inbox for a verification email from OpenAI and follow the instructions to verify your account.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Complete Your Profile</strong>: Provide the required information about yourself and your intended use case for the API.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Set Up Billing</strong>: To access the full capabilities of the API, you&#x27;ll need to add a payment method. OpenAI offers a free tier with limited usage, but for production applications, you&#x27;ll want to set up proper billing.</p>
</li>
</ol>
<p class="my-4 leading-relaxed">Once your account is created and verified, you&#x27;ll have access to the OpenAI platform dashboard, where you can manage your API keys, monitor usage, and access documentation.</p>
<h2 class="text-3xl font-semibold my-5">Obtaining and Managing API Keys</h2>
<p class="my-4 leading-relaxed">API keys are the primary method for authenticating your requests to the OpenAI API. Here&#x27;s how to obtain and manage them:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Generate an API Key</strong>:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Log in to your OpenAI account</li>
<li class="pl-2">Navigate to the &quot;API Keys&quot; section in your account settings</li>
<li class="pl-2">Click &quot;Create new secret key&quot;</li>
<li class="pl-2">Give your key a descriptive name (e.g., &quot;Development Environment&quot;)</li>
<li class="pl-2">Copy and securely store the key immediately, as you won&#x27;t be able to view it again</li>
</ul>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>API Key Best Practices</strong>:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Treat your API keys like passwords</li>
<li class="pl-2">Never hardcode keys directly in your application code</li>
<li class="pl-2">Don&#x27;t share keys in public repositories or client-side code</li>
<li class="pl-2">Use different keys for development and production environments</li>
<li class="pl-2">Regularly rotate keys, especially if you suspect they may have been compromised</li>
</ul>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Revoking Keys</strong>:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">If a key is compromised or no longer needed, immediately revoke it from the API Keys dashboard</li>
<li class="pl-2">Create a new key to replace any revoked keys</li>
</ul>
</li>
</ol>
<p class="my-4 leading-relaxed">Remember that your API key provides access to your OpenAI account and billing, so it&#x27;s crucial to keep it secure.</p>
<h2 class="text-3xl font-semibold my-5">Setting Up Your Development Environment</h2>
<p class="my-4 leading-relaxed">To start working with the OpenAI API, you&#x27;ll need to set up your development environment. Here&#x27;s a step-by-step guide for Python, the most commonly used language for OpenAI API integration:</p>
<h3 class="text-2xl font-semibold my-4">Installing the OpenAI Python Library</h3>
<p class="my-4 leading-relaxed">The official OpenAI Python library provides a convenient interface for making API calls. Install it using pip:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>pip </span><span class="token" style="color:hsl(207, 82%, 66%)">install</span><span> openai</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">For production environments, it&#x27;s recommended to pin the version to avoid unexpected changes:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>pip </span><span class="token" style="color:hsl(207, 82%, 66%)">install</span><span> </span><span class="token assign-left" style="color:hsl(207, 82%, 66%)">openai</span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span class="token" style="color:hsl(29, 54%, 61%)">1.70</span><span>.0  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Replace with the latest version</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Environment Configuration</h3>
<p class="my-4 leading-relaxed">Best practice is to store your API key in environment variables rather than in your code:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Create a <code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">.env</code> file</strong> in your project root (make sure to add it to <code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">.gitignore</code>):</li>
</ol>
<pre class="my-4 bg-transparent"><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">OPENAI_API_KEY=your-api-key-here
</code></pre>
<ol class="list-decimal pl-6 my-4 space-y-2" start="2">
<li class="pl-2"><strong>Load environment variables</strong> in your application:</li>
</ol>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> dotenv </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> load_dotenv
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Load environment variables from .env file</span><span>
</span><span>load_dotenv</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Access the API key</span><span>
</span><span>api_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">You&#x27;ll need to install the <code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">python-dotenv</code> package:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>pip </span><span class="token" style="color:hsl(207, 82%, 66%)">install</span><span> python-dotenv</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Initializing the OpenAI Client</h3>
<p class="my-4 leading-relaxed">With your environment set up, you can now initialize the OpenAI client:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI
</span>
<span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># This is the default and can be omitted if OPENAI_API_KEY is set in your environment</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">For applications that need to make asynchronous requests, use the async client:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> asyncio
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> AsyncOpenAI
</span>
<span>async_client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AsyncOpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">main</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Use the async client here</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> async_client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello!&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Run the async function</span><span>
</span><span>asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>run</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>main</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Authentication Best Practices</h2>
<p class="my-4 leading-relaxed">Securing your OpenAI API integration is crucial for both security and cost management. Here are some best practices for authentication:</p>
<h3 class="text-2xl font-semibold my-4">Environment-Based Configuration</h3>
<p class="my-4 leading-relaxed">Always use environment variables or secure secret management systems to store API keys:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">In development: Use <code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">.env</code> files with tools like <code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">python-dotenv</code></li>
<li class="pl-2">In production: Use your platform&#x27;s secret management (AWS Secrets Manager, Google Secret Manager, Azure Key Vault, etc.)</li>
</ul>
<h3 class="text-2xl font-semibold my-4">API Key Rotation</h3>
<p class="my-4 leading-relaxed">Implement a regular schedule for rotating API keys:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example function to check if key rotation is needed</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">should_rotate_api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>last_rotation_date</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> rotation_period_days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">90</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> datetime </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> timedelta
</span>    
<span>    rotation_threshold </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> last_rotation_date </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> timedelta</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>rotation_period_days</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> rotation_threshold</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Request Signing</h3>
<p class="my-4 leading-relaxed">For enterprise applications, consider implementing request signing for additional security:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> hmac
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> hashlib
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">sign_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>payload</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> secret_key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    timestamp </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">int</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>time</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">timestamp</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">payload</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>    signature </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> hmac</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>new</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        secret_key</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        hashlib</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sha256
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>hexdigest</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;payload&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> payload</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> timestamp</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;signature&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> signature
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Proxy Services</h3>
<p class="my-4 leading-relaxed">For applications where the client needs to make API calls, consider using a proxy service to avoid exposing your API key:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Server-side code (your proxy API)</span><span>
</span><span></span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">@app</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">.</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">route</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;/api/openai&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> methods</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;POST&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">proxy_openai_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate the user&#x27;s session/authentication</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> is_authenticated</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>request</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Unauthorized&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">401</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract the request parameters</span><span>
</span><span>    request_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>json
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the OpenAI API call using your server&#x27;s API key</span><span>
</span><span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>request_data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model_dump</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">500</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">API Request Structure Basics</h2>
<p class="my-4 leading-relaxed">Understanding the structure of API requests is fundamental to working effectively with the OpenAI API. Let&#x27;s examine the basic components of a request:</p>
<h3 class="text-2xl font-semibold my-4">Common Request Parameters</h3>
<p class="my-4 leading-relaxed">Regardless of which API endpoint you&#x27;re using, several parameters are commonly used:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">model</code></strong>: Specifies which model to use (e.g., &quot;gpt-4o&quot;, &quot;gpt-3.5-turbo&quot;)</li>
<li class="pl-2"><strong>Authentication</strong>: Your API key, typically provided in the request header</li>
<li class="pl-2"><strong>Request Body</strong>: JSON payload containing the parameters specific to the endpoint</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Chat Completions Request Structure</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello, who are you?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">150</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    top_p</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1.0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    frequency_penalty</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    presence_penalty</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.0</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Responses API Request Structure</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello, who are you?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">150</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Embeddings Request Structure</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-small&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The food was delicious and the service was excellent.&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Making Your First API Call</h2>
<p class="my-4 leading-relaxed">Let&#x27;s put everything together and make your first API call. This example demonstrates a simple chat completion request:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> dotenv </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> load_dotenv
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Load environment variables</span><span>
</span><span>load_dotenv</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Initialize the OpenAI client</span><span>
</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make a simple request</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_ai_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Using a less expensive model for testing</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;An error occurred: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Test the function</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> __name__ </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;__main__&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    user_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Explain what an API is in simple terms.&quot;</span><span>
</span><span>    result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_ai_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>user_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Prompt: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">user_prompt</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Response: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">Save this code to a file (e.g., <code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">first_api_call.py</code>), ensure your <code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">.env</code> file contains your API key, and run it:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>python first_api_call.py</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">If everything is set up correctly, you should receive a response explaining what an API is in simple terms.</p>
<h2 class="text-3xl font-semibold my-5">Understanding API Responses</h2>
<p class="my-4 leading-relaxed">When you make a request to the OpenAI API, the response contains several important components:</p>
<h3 class="text-2xl font-semibold my-4">Chat Completions Response Structure</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-json" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;id&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;chatcmpl-123abc&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;object&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;chat.completion&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;created&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1677858242</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;model&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;choices&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>      </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;message&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;role&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;content&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello! I&#x27;m an AI assistant created by OpenAI. How can I help you today?&quot;</span><span>
</span><span>      </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>      </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;index&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>      </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;finish_reason&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;stop&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>  </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;usage&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>    </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">13</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">16</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">29</span><span>
</span><span>  </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Responses API Response Structure</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-json" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;id&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;resp-123abc&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;object&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;response&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;created&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1677858242</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;model&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;output_text&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello! I&#x27;m an AI assistant created by OpenAI. How can I help you today?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>  </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;usage&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>    </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">13</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">16</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(355, 65%, 65%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(207, 82%, 66%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">29</span><span>
</span><span>  </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Key Response Fields</h3>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">id</code></strong>: A unique identifier for the response</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">created</code></strong>: Timestamp of when the response was generated</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">model</code></strong>: The model used to generate the response</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">choices</code></strong> or <strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">output_text</code></strong>: The actual content generated by the model</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">finish_reason</code></strong>: Indicates why the model stopped generating (e.g., &quot;stop&quot;, &quot;length&quot;, &quot;content_filter&quot;)</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">usage</code></strong>: Token usage information for billing purposes</li>
</ul>
<p class="my-4 leading-relaxed">Understanding these response structures will help you effectively integrate the OpenAI API into your applications and handle the responses appropriately.</p>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore the various models available through the OpenAI API and how to choose the right one for your specific use case.</p>
<h1 class="text-4xl font-bold my-6">OpenAI Models in Depth</h1>
<h2 class="text-3xl font-semibold my-5">Available Models Overview</h2>
<p class="my-4 leading-relaxed">OpenAI offers a diverse range of models through its API, each with unique capabilities, performance characteristics, and pricing. Understanding the differences between these models is crucial for selecting the right one for your specific use case. Here&#x27;s a comprehensive overview of the main model families available:</p>
<h3 class="text-2xl font-semibold my-4">GPT-4 Family</h3>
<p class="my-4 leading-relaxed">The GPT-4 family represents OpenAI&#x27;s most advanced models, offering superior reasoning, creativity, and instruction-following capabilities.</p>
<h4>GPT-4o</h4>
<p class="my-4 leading-relaxed">GPT-4o (&quot;o&quot; for &quot;omni&quot;) is OpenAI&#x27;s flagship multimodal model, capable of processing both text and images with remarkable performance.</p>
<p class="my-4 leading-relaxed"><strong>Key Features:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Multimodal capabilities (text and image inputs)</li>
<li class="pl-2">Improved reasoning and problem-solving</li>
<li class="pl-2">Enhanced instruction following</li>
<li class="pl-2">Reduced latency compared to previous GPT-4 models</li>
<li class="pl-2">Competitive pricing relative to capabilities</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Best For:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Applications requiring both text and image understanding</li>
<li class="pl-2">Complex reasoning tasks</li>
<li class="pl-2">Production applications needing balanced performance and cost</li>
<li class="pl-2">User-facing applications where response speed is important</li>
</ul>
<h4>GPT-4 Turbo</h4>
<p class="my-4 leading-relaxed">GPT-4 Turbo offers high performance with optimizations for faster response times and lower cost compared to the original GPT-4.</p>
<p class="my-4 leading-relaxed"><strong>Key Features:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Large 128K token context window</li>
<li class="pl-2">Strong reasoning capabilities</li>
<li class="pl-2">Good balance of performance and cost</li>
<li class="pl-2">Support for function calling</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Best For:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Applications requiring processing of long documents</li>
<li class="pl-2">Complex reasoning tasks with budget considerations</li>
<li class="pl-2">Enterprise applications needing reliable performance</li>
</ul>
<h4>GPT-4</h4>
<p class="my-4 leading-relaxed">The original GPT-4 model, still available for applications that have been optimized for its specific characteristics.</p>
<p class="my-4 leading-relaxed"><strong>Key Features:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Consistent, well-tested performance</li>
<li class="pl-2">Strong reasoning capabilities</li>
<li class="pl-2">Reliable instruction following</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Best For:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Applications already optimized for GPT-4</li>
<li class="pl-2">Use cases requiring the most consistent outputs</li>
</ul>
<h3 class="text-2xl font-semibold my-4">GPT-3.5 Family</h3>
<p class="my-4 leading-relaxed">The GPT-3.5 family offers a more economical option while still providing strong capabilities for many common use cases.</p>
<h4>GPT-3.5 Turbo</h4>
<p class="my-4 leading-relaxed">GPT-3.5 Turbo is OpenAI&#x27;s most cost-effective model for general-purpose text generation and understanding.</p>
<p class="my-4 leading-relaxed"><strong>Key Features:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Fast response times</li>
<li class="pl-2">Cost-effective pricing</li>
<li class="pl-2">Good performance for straightforward tasks</li>
<li class="pl-2">16K token context window</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Best For:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">High-volume applications with budget constraints</li>
<li class="pl-2">Simpler conversational agents</li>
<li class="pl-2">Content generation where absolute cutting-edge quality isn&#x27;t required</li>
<li class="pl-2">Prototyping and development</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Specialized Models</h3>
<p class="my-4 leading-relaxed">Beyond the general-purpose GPT models, OpenAI offers specialized models for specific tasks:</p>
<h4>Text Embedding Models</h4>
<p class="my-4 leading-relaxed">Embedding models convert text into numerical vector representations that capture semantic meaning, enabling similarity comparisons and other vector operations.</p>
<p class="my-4 leading-relaxed"><strong>Available Models:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>text-embedding-3-small</strong>: Efficient, cost-effective embeddings</li>
<li class="pl-2"><strong>text-embedding-3-large</strong>: Higher-quality embeddings with more dimensions</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Best For:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Semantic search implementations</li>
<li class="pl-2">Recommendation systems</li>
<li class="pl-2">Document clustering</li>
<li class="pl-2">Information retrieval</li>
</ul>
<h4>Moderation Models</h4>
<p class="my-4 leading-relaxed">Moderation models help identify potentially harmful or inappropriate content.</p>
<p class="my-4 leading-relaxed"><strong>Available Model:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>text-moderation-latest</strong>: Classifies text across various harm categories</li>
</ul>
<p class="my-4 leading-relaxed"><strong>Best For:</strong></p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Content filtering</li>
<li class="pl-2">User-generated content moderation</li>
<li class="pl-2">Safety systems for AI applications</li>
</ul>
<h2 class="text-3xl font-semibold my-5">Model Capabilities and Limitations</h2>
<p class="my-4 leading-relaxed">Understanding what each model can and cannot do is essential for setting appropriate expectations and designing effective applications.</p>
<h3 class="text-2xl font-semibold my-4">Common Capabilities Across Models</h3>
<p class="my-4 leading-relaxed">All OpenAI models share certain fundamental capabilities:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Natural Language Understanding</strong>: Comprehending user inputs across various topics and domains</li>
<li class="pl-2"><strong>Text Generation</strong>: Producing coherent, contextually relevant text</li>
<li class="pl-2"><strong>Conversation</strong>: Maintaining context through multi-turn interactions</li>
<li class="pl-2"><strong>Instruction Following</strong>: Responding to specific directions about how to complete a task</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Model-Specific Capabilities</h3>
<p class="my-4 leading-relaxed">Different models excel in different areas:</p>
<h4>GPT-4o and GPT-4 Family</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Complex Reasoning</strong>: Multi-step problem solving and logical deduction</li>
<li class="pl-2"><strong>Nuanced Understanding</strong>: Grasping subtle implications and context</li>
<li class="pl-2"><strong>Creative Generation</strong>: Producing high-quality creative content</li>
<li class="pl-2"><strong>Code Generation</strong>: Writing and explaining complex code</li>
<li class="pl-2"><strong>Multimodal Understanding</strong> (GPT-4o): Processing and reasoning about images</li>
</ul>
<h4>GPT-3.5 Family</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Straightforward Q&amp;A</strong>: Answering factual questions</li>
<li class="pl-2"><strong>Basic Content Generation</strong>: Creating simple articles, emails, and summaries</li>
<li class="pl-2"><strong>Lightweight Conversation</strong>: Handling straightforward dialogue</li>
<li class="pl-2"><strong>Simple Instructions</strong>: Following clear, direct instructions</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Common Limitations</h3>
<p class="my-4 leading-relaxed">All current AI models, including OpenAI&#x27;s, have certain limitations:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Knowledge Cutoff</strong>: Models have a training cutoff date and lack knowledge of events after that date</li>
<li class="pl-2"><strong>Hallucinations</strong>: Models may occasionally generate plausible-sounding but incorrect information</li>
<li class="pl-2"><strong>Reasoning Limitations</strong>: Complex logical or mathematical reasoning may be inconsistent</li>
<li class="pl-2"><strong>Context Window Constraints</strong>: Models can only consider a finite amount of text at once</li>
<li class="pl-2"><strong>Lack of True Understanding</strong>: Models don&#x27;t truly &quot;understand&quot; content the way humans do</li>
<li class="pl-2"><strong>No External Tools</strong>: Models cannot access the internet, run code, or use external tools unless specifically enabled through API features</li>
</ul>
<h2 class="text-3xl font-semibold my-5">Choosing the Right Model for Your Use Case</h2>
<p class="my-4 leading-relaxed">Selecting the appropriate model involves balancing several factors:</p>
<h3 class="text-2xl font-semibold my-4">Decision Factors</h3>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Task Complexity</strong>: More complex tasks generally benefit from more capable models</li>
<li class="pl-2"><strong>Budget Constraints</strong>: More capable models typically cost more per token</li>
<li class="pl-2"><strong>Response Speed Requirements</strong>: Some applications prioritize low latency</li>
<li class="pl-2"><strong>Context Length Needs</strong>: Consider how much context your application requires</li>
<li class="pl-2"><strong>Multimodal Requirements</strong>: Whether your application needs to process images</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Use Case Recommendations</h3>
<p class="my-4 leading-relaxed">Here are some common use cases and recommended models:</p>
<h4>Customer Support Automation</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Recommended</strong>: GPT-3.5 Turbo for most queries, GPT-4o for complex issues</li>
<li class="pl-2"><strong>Rationale</strong>: Cost-effective for high-volume, mostly straightforward queries</li>
</ul>
<h4>Content Creation</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Recommended</strong>: GPT-4o or GPT-4 Turbo</li>
<li class="pl-2"><strong>Rationale</strong>: Higher quality output justifies the increased cost</li>
</ul>
<h4>Code Generation and Explanation</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Recommended</strong>: GPT-4o</li>
<li class="pl-2"><strong>Rationale</strong>: Superior code generation capabilities and ability to understand code screenshots</li>
</ul>
<h4>Document Analysis</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Recommended</strong>: GPT-4 Turbo with 128K context</li>
<li class="pl-2"><strong>Rationale</strong>: Can process longer documents in a single request</li>
</ul>
<h4>Semantic Search</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Recommended</strong>: text-embedding-3-large</li>
<li class="pl-2"><strong>Rationale</strong>: Optimized specifically for creating high-quality text embeddings</li>
</ul>
<h4>Educational Applications</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Recommended</strong>: GPT-4o</li>
<li class="pl-2"><strong>Rationale</strong>: Better reasoning and explanation capabilities, plus ability to understand visual materials</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Cost-Efficiency Strategies</h3>
<p class="my-4 leading-relaxed">To optimize your model selection for cost efficiency:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Use Tiered Approach</strong>: Start with GPT-3.5 Turbo and escalate to GPT-4 models only when needed</li>
<li class="pl-2"><strong>Implement Caching</strong>: Cache common responses to avoid redundant API calls</li>
<li class="pl-2"><strong>Optimize Prompts</strong>: Well-designed prompts can get better results from less expensive models</li>
<li class="pl-2"><strong>Monitor Token Usage</strong>: Regularly review token consumption to identify optimization opportunities</li>
</ol>
<h2 class="text-3xl font-semibold my-5">Understanding Context Windows and Token Limits</h2>
<p class="my-4 leading-relaxed">The context window is a crucial concept in working with language models, as it determines how much information the model can consider at once.</p>
<h3 class="text-2xl font-semibold my-4">What Are Tokens?</h3>
<p class="my-4 leading-relaxed">Tokens are the basic units that models process:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">A token is approximately 4 characters or 3/4 of a word in English</li>
<li class="pl-2">Punctuation, spaces, and special characters also count as tokens</li>
<li class="pl-2">Code and non-English languages may tokenize differently</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Context Window Sizes</h3>
<p class="my-4 leading-relaxed">Different models have different context window sizes:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">GPT-4 Turbo: 128,000 tokens</li>
<li class="pl-2">GPT-4o: 128,000 tokens</li>
<li class="pl-2">GPT-3.5 Turbo: 16,384 tokens</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Managing Long Contexts</h3>
<p class="my-4 leading-relaxed">When working with content that exceeds the context window:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Chunking</strong>: Break long documents into smaller pieces</li>
<li class="pl-2"><strong>Summarization</strong>: Create summaries of previous context</li>
<li class="pl-2"><strong>Retrieval-Augmented Generation (RAG)</strong>: Only include relevant context based on the query</li>
<li class="pl-2"><strong>Fine-tuning</strong>: Train the model to work with specialized formats that convey information more efficiently</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Token Counting Example</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> tiktoken
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">count_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Count the number of tokens in a text string.&quot;&quot;&quot;</span><span>
</span><span>    encoding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tiktoken</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encoding_for_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>sample_text </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;This is a sample text to demonstrate token counting.&quot;</span><span>
</span><span>token_count </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> count_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>sample_text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;The text contains </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">token_count</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> tokens.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Model Versioning and Deprecation Policies</h2>
<p class="my-4 leading-relaxed">OpenAI regularly updates its models and occasionally deprecates older versions. Understanding their versioning and deprecation policies is important for maintaining stable applications.</p>
<h3 class="text-2xl font-semibold my-4">Versioning Approach</h3>
<p class="my-4 leading-relaxed">OpenAI uses several approaches to versioning:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Named Versions</strong>: Major models get distinct names (e.g., GPT-4, GPT-4o)</li>
<li class="pl-2"><strong>Suffixed Versions</strong>: Variants may have suffixes (e.g., GPT-4 Turbo)</li>
<li class="pl-2"><strong>Date-Based Versions</strong>: Some models include dates (e.g., gpt-3.5-turbo-0125)</li>
<li class="pl-2"><strong>Latest Pointers</strong>: Aliases like &quot;gpt-4-turbo&quot; point to the latest version</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Deprecation Timeline</h3>
<p class="my-4 leading-relaxed">When a model is scheduled for deprecation:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">OpenAI typically announces deprecation 3+ months in advance</li>
<li class="pl-2">The model remains available during this period</li>
<li class="pl-2">After deprecation, requests to that specific model version will fail</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Best Practices for Version Management</h3>
<p class="my-4 leading-relaxed">To handle model versioning effectively:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Use Latest Pointers Carefully</strong>: They provide automatic updates but may change behavior</li>
<li class="pl-2"><strong>Monitor Announcements</strong>: Subscribe to OpenAI&#x27;s developer newsletter and monitor their blog</li>
<li class="pl-2"><strong>Version Testing</strong>: Test new versions before migrating production systems</li>
<li class="pl-2"><strong>Graceful Fallbacks</strong>: Implement fallback mechanisms if a model becomes unavailable</li>
</ol>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example of version-aware client initialization</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_openai_client</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>use_latest</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Choose model version based on preference</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> use_latest</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Latest pointer</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4-0613&quot;</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Specific version for stability</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Usage</span><span>
</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_openai_client</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>use_latest</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello!&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Latest Model Innovations</h2>
<p class="my-4 leading-relaxed">OpenAI continuously improves its models. Here are some of the latest innovations as of 2025:</p>
<h3 class="text-2xl font-semibold my-4">Multimodal Capabilities</h3>
<p class="my-4 leading-relaxed">The ability to process and reason about both text and images represents a significant advancement in AI capabilities:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Vision Understanding</strong>: Models can analyze and describe images</li>
<li class="pl-2"><strong>Visual Reasoning</strong>: Models can answer questions about visual content</li>
<li class="pl-2"><strong>Combined Inputs</strong>: Processing text and images together for holistic understanding</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Enhanced Reasoning</h3>
<p class="my-4 leading-relaxed">Recent models show improved abilities in complex reasoning tasks:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Step-by-Step Problem Solving</strong>: Breaking down complex problems methodically</li>
<li class="pl-2"><strong>Logical Consistency</strong>: Maintaining coherent reasoning across complex scenarios</li>
<li class="pl-2"><strong>Self-Correction</strong>: Identifying and fixing errors in reasoning</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Specialized Instruction Following</h3>
<p class="my-4 leading-relaxed">Models have become better at following specific instructions about how to respond:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Format Adherence</strong>: Consistently producing outputs in requested formats</li>
<li class="pl-2"><strong>Style Matching</strong>: Adopting specific tones or writing styles</li>
<li class="pl-2"><strong>Constraint Satisfaction</strong>: Working within defined limitations</li>
</ul>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore the core functionality of the OpenAI API, including detailed examples of how to use the Chat Completions and Responses APIs effectively.</p>
<h1 class="text-4xl font-bold my-6">Core API Functionality</h1>
<h2 class="text-3xl font-semibold my-5">Chat Completions API</h2>
<p class="my-4 leading-relaxed">The Chat Completions API is one of the primary interfaces for interacting with OpenAI&#x27;s language models. It&#x27;s designed around a conversational format, making it ideal for applications that involve dialogue or multi-turn interactions.</p>
<h3 class="text-2xl font-semibold my-4">Basic Usage and Parameters</h3>
<p class="my-4 leading-relaxed">At its most basic, a Chat Completions request requires a model name and a list of messages:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI
</span>
<span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello, how are you today?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">However, the API offers numerous parameters to control the generation process:</p>
<h4>Essential Parameters</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">model</code></strong> (string, required): Specifies which model to use (e.g., &quot;gpt-4o&quot;, &quot;gpt-3.5-turbo&quot;)</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">messages</code></strong> (array, required): The conversation history formatted as an array of message objects</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">temperature</code></strong> (number, optional, default 1): Controls randomness. Lower values make responses more deterministic, higher values more creative</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">max_tokens</code></strong> (integer, optional): The maximum number of tokens to generate</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">stream</code></strong> (boolean, optional, default false): Whether to stream back partial progress</li>
</ul>
<h4>Advanced Parameters</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">top_p</code></strong> (number, optional, default 1): An alternative to temperature, using nucleus sampling</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">n</code></strong> (integer, optional, default 1): How many chat completion choices to generate</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">stop</code></strong> (string or array, optional): Sequences where the API will stop generating further tokens</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">presence_penalty</code></strong> (number, optional, default 0): Penalizes new tokens based on whether they appear in the text so far</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">frequency_penalty</code></strong> (number, optional, default 0): Penalizes new tokens based on their frequency in the text so far</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">logit_bias</code></strong> (map, optional): Modifies the likelihood of specified tokens appearing in the completion</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">tools</code></strong> (array, optional): List of tools the model may call</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">tool_choice</code></strong> (string or object, optional): Controls how the model calls functions</li>
</ul>
<h3 class="text-2xl font-semibold my-4">System, User, and Assistant Messages</h3>
<p class="my-4 leading-relaxed">The Chat Completions API uses a role-based message system to structure conversations:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>System Messages</strong>: Set the behavior of the assistant</li>
<li class="pl-2"><strong>User Messages</strong>: Represent user inputs</li>
<li class="pl-2"><strong>Assistant Messages</strong>: Represent previous responses from the assistant</li>
<li class="pl-2"><strong>Tool Messages</strong>: Contain the results of tool calls</li>
</ol>
<p class="my-4 leading-relaxed">Here&#x27;s an example using multiple message types:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant that speaks like Shakespeare.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Tell me about artificial intelligence.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Verily, artificial intelligence doth mimic the workings of the human mind, yet &#x27;tis crafted by mortal hands.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;How does it work?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Temperature and Other Control Parameters</h3>
<p class="my-4 leading-relaxed">The generation behavior can be fine-tuned using various parameters:</p>
<h4>Temperature</h4>
<p class="my-4 leading-relaxed">Temperature controls randomness in the model&#x27;s outputs. Lower values make responses more deterministic and focused, while higher values introduce more creativity and variability.</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># More deterministic response</span><span>
</span><span>response_deterministic </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a tagline for a coffee shop.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.2</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># More creative response</span><span>
</span><span>response_creative </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a tagline for a coffee shop.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.9</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Top P (Nucleus Sampling)</h4>
<p class="my-4 leading-relaxed">An alternative to temperature, top_p controls diversity by considering only the tokens comprising the top p probability mass.</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a short poem about the ocean.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    top_p</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.8</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Presence and Frequency Penalties</h4>
<p class="my-4 leading-relaxed">These parameters help control repetition in the generated text:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a paragraph about climate change.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    presence_penalty</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Discourage repeating the same topics</span><span>
</span><span>    frequency_penalty</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.5</span><span>   </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Discourage repeating the same words</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Streaming Responses</h3>
<p class="my-4 leading-relaxed">For applications where you want to show responses as they&#x27;re being generated (similar to typing), you can use streaming:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>stream </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a short story about a robot learning to paint.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    stream</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process the stream</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> chunk </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> stream</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> chunk</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>chunk</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> end</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> flush</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">For asynchronous applications:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> asyncio
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">stream_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    stream </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a short story about a robot learning to paint.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        stream</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> chunk </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> stream</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> chunk</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>chunk</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> end</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> flush</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>run</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>stream_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Code Examples and Use Cases</h3>
<h4>Building a Simple Chatbot</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">chatbot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Chatbot: Hello! How can I help you today? (Type &#x27;exit&#x27; to quit)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        user_input </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;exit&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Chatbot: Goodbye!&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>        
<span>        messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Using a less expensive model for a chatbot</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        assistant_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Chatbot: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">assistant_response</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the assistant&#x27;s response to the conversation history</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> assistant_response</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Content Summarization</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">summarize_text</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_length</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;short&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    length_instructions </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;short&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Summarize this in 2-3 sentences.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Provide a paragraph-length summary.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;long&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a detailed summary with key points.&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    instruction </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> length_instructions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>max_length</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> length_instructions</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;short&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;You are a summarization assistant. </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">instruction</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.3</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Lower temperature for more focused summaries</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h4>Language Translation</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">translate_text</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> source_language</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;auto&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> target_language</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;English&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;You are a translation assistant. Translate the following text from </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">source_language</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> to </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">target_language</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Responses API</h2>
<p class="my-4 leading-relaxed">The Responses API is OpenAI&#x27;s newer interface for generating text, designed to simplify the developer experience while offering enhanced capabilities.</p>
<h3 class="text-2xl font-semibold my-4">When to Use Responses API vs Chat Completions</h3>
<p class="my-4 leading-relaxed">The Responses API is generally preferable when:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">You want a simpler interface with fewer required parameters</li>
<li class="pl-2">You need to work with multimodal inputs (text and images)</li>
<li class="pl-2">You prefer a more streamlined response format</li>
<li class="pl-2">You&#x27;re building new applications from scratch</li>
</ul>
<p class="my-4 leading-relaxed">The Chat Completions API remains better when:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">You need maximum control over generation parameters</li>
<li class="pl-2">You&#x27;re implementing complex function calling</li>
<li class="pl-2">You require detailed token usage statistics</li>
<li class="pl-2">You&#x27;re maintaining existing applications built on this API</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Structure and Parameters</h3>
<p class="my-4 leading-relaxed">The Responses API has a more straightforward structure compared to Chat Completions:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What is artificial intelligence?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Key Parameters</h4>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">model</code></strong> (string, required): Specifies which model to use</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">instructions</code></strong> (string, optional): Provides system-level instructions for the model</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">input</code></strong> (string or array, required): The user&#x27;s input, which can be text or a structured array for multimodal inputs</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">temperature</code></strong> (number, optional): Controls randomness in generation</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">max_tokens</code></strong> (integer, optional): Maximum number of tokens to generate</li>
<li class="pl-2"><strong><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">stream</code></strong> (boolean, optional): Whether to stream back partial progress</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Practical Examples</h3>
<h4>Basic Text Generation</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>instructions</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>prompt
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<h4>Multimodal Input (Text + Image)</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_image</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_image&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;image_url&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<h4>Streaming with the Responses API</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>stream </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Explain quantum computing to a high school student.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    stream</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> event </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> stream</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">hasattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>event</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;delta&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> event</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>event</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> end</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> flush</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Structured Conversation</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">structured_conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Convert chat-style messages to Responses API format</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Single message case</span><span>
</span><span>        input_content </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Multi-message conversation case</span><span>
</span><span>        input_content </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> msg </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            input_content</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> msg</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> msg</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>input_content
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Comparing API Approaches with Real Examples</h2>
<p class="my-4 leading-relaxed">To illustrate the differences between the Chat Completions API and the Responses API, let&#x27;s implement the same functionality using both approaches:</p>
<h3 class="text-2xl font-semibold my-4">Example 1: Simple Question Answering</h3>
<p class="my-4 leading-relaxed"><strong>Chat Completions API:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">answer_question_chat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant that provides accurate and concise answers.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<p class="my-4 leading-relaxed"><strong>Responses API:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">answer_question_responses</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant that provides accurate and concise answers.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>question
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Example 2: Multi-turn Conversation</h3>
<p class="my-4 leading-relaxed"><strong>Chat Completions API:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">chat_conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> new_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the new message to the history</span><span>
</span><span>    conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> new_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>conversation_history
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    assistant_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update the conversation history</span><span>
</span><span>    conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> conversation_history</span></code></pre></div></pre>
<p class="my-4 leading-relaxed"><strong>Responses API:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">responses_conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> new_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Format the conversation history for the Responses API</span><span>
</span><span>    formatted_input </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> message </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        formatted_input</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the new message</span><span>
</span><span>    formatted_input</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> new_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>formatted_input
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    assistant_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update the conversation history</span><span>
</span><span>    conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> new_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> conversation_history</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Example 3: Content Generation with Specific Parameters</h3>
<p class="my-4 leading-relaxed"><strong>Chat Completions API:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_content_chat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> creativity_level</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Map creativity level to temperature</span><span>
</span><span>    temperature_map </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.0</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    temperature </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> temperature_map</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>creativity_level</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a creative content generator.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        presence_penalty</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        frequency_penalty</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.2</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<p class="my-4 leading-relaxed"><strong>Responses API:</strong></p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_content_responses</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> creativity_level</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Map creativity level to temperature</span><span>
</span><span>    temperature_map </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.0</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    temperature </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> temperature_map</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>creativity_level</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a creative content generator.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore advanced API features, including function calling, embeddings, and multimodal capabilities.</p>
<h1 class="text-4xl font-bold my-6">Advanced API Features</h1>
<h2 class="text-3xl font-semibold my-5">Function Calling</h2>
<p class="my-4 leading-relaxed">Function calling is a powerful capability that allows models to generate structured data and invoke external functions. This feature enables developers to create more interactive and capable applications by connecting AI models with external tools and services.</p>
<h3 class="text-2xl font-semibold my-4">Defining Functions for the Model to Call</h3>
<p class="my-4 leading-relaxed">To use function calling, you first need to define the functions that the model can call. These definitions include the function name, description, and parameter schema:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI
</span>
<span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define the functions that the model can call</span><span>
</span><span>tools </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;get_weather&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Get the current weather in a given location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The city and state, e.g. San Francisco, CA&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;enum&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;celsius&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;fahrenheit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The temperature unit to use&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Handling Function Responses</h3>
<p class="my-4 leading-relaxed">Once you&#x27;ve defined the functions, you can make a request to the model and process any function calls it generates:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_weather</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>location</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> unit</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;celsius&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get the current weather in a location (mock implementation)&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real application, you would call a weather API here</span><span>
</span><span>    weather_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> location</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;temperature&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;22&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> unit </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;celsius&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;72&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> unit</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;forecast&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sunny&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;windy&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;humidity&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;65%&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>weather_data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make a request to the model</span><span>
</span><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What&#x27;s the weather like in Boston?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>tools</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tool_choice</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;auto&quot;</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Let the model decide when to call functions</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if the model wants to call a function</span><span>
</span><span>message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message
</span><span>tool_calls </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>tool_calls
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> tool_calls</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># The model wants to call a function</span><span>
</span><span>    available_functions </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;get_weather&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> get_weather</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Prepare messages for the second request</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What&#x27;s the weather like in Boston?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        message  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Include the assistant&#x27;s response with the function call</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process each function call</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> tool_call </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> tool_calls</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        function_name </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>function</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>name
</span><span>        function_args </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>function</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>arguments</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> function_name </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> available_functions</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            function_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> available_functions</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>function_name</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>function_args</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Append the function response to the messages</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tool&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tool_call_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> function_name</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> function_response
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make a second request to get the final response</span><span>
</span><span>    second_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>second_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># The model didn&#x27;t call a function</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Complex Function Calling Patterns</h3>
<p class="my-4 leading-relaxed">Function calling can be used in more complex scenarios, such as:</p>
<h4>Multiple Functions</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>tools </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;get_weather&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Get the current weather in a given location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The city and state&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;enum&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;celsius&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;fahrenheit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;get_restaurant_recommendations&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Get restaurant recommendations for a location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The city and state&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cuisine&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Type of cuisine&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price_range&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;enum&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$$&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$$$&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$$$$&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span></code></pre></div></pre>
<h4>Forcing Specific Functions</h4>
<p class="my-4 leading-relaxed">You can force the model to use a specific function:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What&#x27;s the weather like in San Francisco?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>tools</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tool_choice</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;get_weather&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Parallel Function Calling</h4>
<p class="my-4 leading-relaxed">The model can call multiple functions in a single response:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What&#x27;s the weather like in Miami, and can you recommend some Italian restaurants there?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>tools</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tool_choice</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;auto&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process multiple function calls in parallel</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>tool_calls</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process each function call as shown earlier</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">pass</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Real-World Examples</h3>
<h4>Building a Travel Assistant</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">travel_assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    tools </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;search_flights&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Search for flights between two cities on a specific date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;origin&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Origin city or airport code&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;destination&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Destination city or airport code&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Date in YYYY-MM-DD format&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;passengers&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;integer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Number of passengers&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;origin&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;destination&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;search_hotels&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Search for hotels in a city for specific dates&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;city&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;City name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;check_in&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Check-in date in YYYY-MM-DD format&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;check_out&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Check-out date in YYYY-MM-DD format&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;guests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;integer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Number of guests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;city&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;check_in&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;check_out&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Mock implementations of the functions</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">search_flights</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>origin</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> destination</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> date</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> passengers</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flights&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;airline&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Example Air&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;departure&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;10:00&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;arrival&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;12:00&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$350&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;airline&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Sample Airlines&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;departure&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;14:00&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;arrival&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;16:00&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$310&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">search_hotels</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>city</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> check_in</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> check_out</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> guests</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;hotels&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Grand Hotel&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rating&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4.5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price_per_night&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$200&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;City Center Inn&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rating&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4.2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price_per_night&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$150&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    available_functions </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;search_flights&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> search_flights</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;search_hotels&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> search_hotels
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful travel assistant.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Travel Assistant: Hello! I can help you plan your trip. What are your travel plans?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        user_input </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;exit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;quit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;bye&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Travel Assistant: Goodbye! Have a great trip!&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>        
<span>        messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>tools</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            tool_choice</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;auto&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        assistant_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message
</span><span>        messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process any function calls</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>tool_calls</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> tool_call </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>tool_calls</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                function_name </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>function</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>name
</span><span>                function_args </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>function</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>arguments</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                
<span>                function_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> available_functions</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>function_name</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>function_args</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                
<span>                messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tool&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tool_call_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> function_name</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> function_response
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get the final response after function calls</span><span>
</span><span>            final_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            final_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> final_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>            messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> final_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Travel Assistant: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">final_message</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Travel Assistant: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">assistant_message</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">content</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Embeddings</h2>
<p class="my-4 leading-relaxed">Embeddings are numerical representations of text that capture semantic meaning, allowing for operations like similarity comparison, clustering, and search.</p>
<h3 class="text-2xl font-semibold my-4">Understanding Vector Embeddings</h3>
<p class="my-4 leading-relaxed">Vector embeddings convert text into high-dimensional vectors where:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Similar texts have vectors that are close together</li>
<li class="pl-2">Different texts have vectors that are far apart</li>
<li class="pl-2">The relationships between words and concepts are preserved in the vector space</li>
</ul>
<p class="my-4 leading-relaxed">This makes embeddings powerful for a wide range of applications:</p>
<ul class="list-disc pl-6 my-4 space-y-2">
<li class="pl-2">Semantic search</li>
<li class="pl-2">Recommendation systems</li>
<li class="pl-2">Document clustering</li>
<li class="pl-2">Information retrieval</li>
<li class="pl-2">Anomaly detection</li>
</ul>
<h3 class="text-2xl font-semibold my-4">Creating and Using Embeddings</h3>
<p class="my-4 leading-relaxed">The OpenAI API provides dedicated embedding models that generate these vector representations:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> numpy </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> np
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI
</span>
<span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-small&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get the embedding for a given text&quot;&quot;&quot;</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>text
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>embedding
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>text1 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The cat sat on the mat.&quot;</span><span>
</span><span>text2 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The feline rested on the rug.&quot;</span><span>
</span><span>text3 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Quantum physics explores subatomic particles.&quot;</span><span>
</span>
<span>embedding1 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>embedding2 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text2</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>embedding3 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text3</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate cosine similarity between embeddings</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">cosine_similarity</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>a</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> b</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>a</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> b</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>linalg</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>norm</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>a</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>linalg</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>norm</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>b</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>similarity_1_2 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cosine_similarity</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>embedding1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> embedding2</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>similarity_1_3 </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cosine_similarity</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>embedding1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> embedding3</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Similarity between text1 and text2: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">similarity_1_2</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Similarity between text1 and text3: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">similarity_1_3</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Semantic Search Implementation</h3>
<p class="my-4 leading-relaxed">One of the most common applications of embeddings is semantic search:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">create_document_embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>documents</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-small&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Create embeddings for a list of documents&quot;&quot;&quot;</span><span>
</span><span>    document_embeddings </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> doc </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>documents</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        embedding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>doc</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        document_embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>i</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> embedding
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> document_embeddings
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">semantic_search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>query</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> document_embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> documents</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> top_n</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Search for documents most similar to the query&quot;&quot;&quot;</span><span>
</span><span>    query_embedding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>query</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate similarities</span><span>
</span><span>    similarities </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> idx</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> doc_embedding </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> document_embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        similarities</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>idx</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cosine_similarity</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>query_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> doc_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Sort by similarity</span><span>
</span><span>    sorted_similarities </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">sorted</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>similarities</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(286, 60%, 67%)">lambda</span><span> x</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> x</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> reverse</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Return top results</span><span>
</span><span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> idx</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> score </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> sorted_similarities</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>top_n</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;document&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> documents</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>idx</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;similarity_score&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> score
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>documents </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OpenAI was founded in December 2015.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;GPT stands for Generative Pre-trained Transformer.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Python is a popular programming language for AI development.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Machine learning models require large amounts of data for training.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The transformer architecture revolutionized natural language processing.&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>
<span>document_embeddings </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> create_document_embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>documents</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>query </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What is GPT?&quot;</span><span>
</span><span>search_results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> semantic_search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>query</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> document_embeddings</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> documents</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> result </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>search_results</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Result </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;document&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> (Score: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;similarity_score&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.4f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Similarity Comparison Techniques</h3>
<p class="my-4 leading-relaxed">Beyond cosine similarity, there are other techniques for comparing embeddings:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">euclidean_distance</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>a</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> b</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Calculate Euclidean distance between two vectors&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>linalg</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>norm</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>array</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>a</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>array</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>b</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">dot_product</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>a</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> b</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Calculate dot product between two vectors&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>a</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> b</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example comparison</span><span>
</span><span>embedding_a </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I love programming&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>embedding_b </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> get_embedding</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Coding is my passion&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Cosine similarity: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">cosine_similarity</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">embedding_a</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> embedding_b</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Euclidean distance: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">euclidean_distance</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">embedding_a</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> embedding_b</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Dot product: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">dot_product</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">embedding_a</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> embedding_b</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Image and Multimodal Capabilities</h2>
<p class="my-4 leading-relaxed">OpenAI&#x27;s models have evolved to handle both text and images, enabling powerful multimodal applications.</p>
<h3 class="text-2xl font-semibold my-4">Processing Images with the API</h3>
<p class="my-4 leading-relaxed">The Responses API allows you to include images alongside text in your requests:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> base64
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_image_from_url</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Analyze an image from a URL&quot;&quot;&quot;</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_image&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;image_url&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_image_from_file</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_path</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Analyze an image from a local file&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Read and encode the image</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_path</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rb&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> image_file</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        base64_image </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> base64</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>b64encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_file</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>read</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>decode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;utf-8&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Format as a data URL</span><span>
</span><span>    data_url </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;data:image/jpeg;base64,</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">base64_image</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_image&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;image_url&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> data_url</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Combined Text and Image Inputs</h3>
<p class="my-4 leading-relaxed">You can create more complex interactions by combining multiple images and text:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">compare_images</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_url1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> image_url2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Compare two images based on a prompt&quot;&quot;&quot;</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_image&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;image_url&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> image_url1</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_image&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;image_url&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> image_url2</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Implementation Examples</h3>
<h4>Visual Question Answering</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">visual_qa_system</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Visual Question Answering System&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Enter &#x27;exit&#x27; to quit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        image_url </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;\nEnter image URL (or path to local image): &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;exit&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>        
<span>        question </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Enter your question about the image: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;exit&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Determine if it&#x27;s a URL or local path</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>startswith</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;http://&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;https://&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> analyze_image_from_url</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> analyze_image_from_file</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error processing image: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;\nAnswer: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Image-Based Content Generation</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_content_from_image</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> content_type</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate content based on an image&quot;&quot;&quot;</span><span>
</span><span>    prompts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Describe this image in detail.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;story&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a short story inspired by this image.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;social_post&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a social media post caption for this image.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;analysis&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Analyze the composition and elements of this image.&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>content_type</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_image&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;image_url&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<h4>Document Analysis System</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_document</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>document_image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Extract and analyze information from a document image&quot;&quot;&quot;</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Extract all text from this document. Then identify key information such as names, dates, amounts, and summarize the main content.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_image&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;image_url&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> document_image_url</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>output_text</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore specialized API services, including the Assistants API, fine-tuning, and the Moderation API.</p>
<h1 class="text-4xl font-bold my-6">Specialized API Services</h1>
<h2 class="text-3xl font-semibold my-5">Assistants API</h2>
<p class="my-4 leading-relaxed">The Assistants API provides a higher-level interface for building AI assistants with persistent memory and specialized tools. It&#x27;s designed to simplify the development of complex, stateful AI applications.</p>
<h3 class="text-2xl font-semibold my-4">Creating and Managing Assistants</h3>
<p class="my-4 leading-relaxed">An Assistant is a persistent entity with specific instructions, capabilities, and tools:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI
</span>
<span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create an assistant</span><span>
</span><span>assistant </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    name</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Math Tutor&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a personal math tutor. Explain concepts in simple terms and provide step-by-step guidance for solving problems.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;code_interpreter&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Created assistant with ID: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">assistant</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">id</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Retrieve an assistant</span><span>
</span><span>retrieved_assistant </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>retrieve</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update an assistant</span><span>
</span><span>updated_assistant </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>update</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a personal math tutor. Explain concepts in simple terms, provide step-by-step guidance, and use examples to illustrate mathematical principles.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># List assistants</span><span>
</span><span>assistants </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">list</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    order</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;desc&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    limit</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> assistant </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Assistant: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">assistant</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">name</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">, ID: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">assistant</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">id</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Delete an assistant</span><span>
</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delete</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Threads and Messages</h3>
<p class="my-4 leading-relaxed">Threads maintain conversation history and state across multiple interactions:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a thread</span><span>
</span><span>thread </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Created thread with ID: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">thread</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">id</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add a message to the thread</span><span>
</span><span>message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    role</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    content</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I&#x27;m having trouble understanding how to solve quadratic equations.&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Retrieve messages from a thread</span><span>
</span><span>messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">list</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> message </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Role: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">message</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">role</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">, Content: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">message</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">content</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">0</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">value</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Run the assistant on the thread</span><span>
</span><span>run </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>runs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    assistant_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check the run status</span><span>
</span><span>run_status </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>runs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>retrieve</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    run_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>run</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Run status: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">run_status</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">status</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Once completed, retrieve the assistant&#x27;s response</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> run_status</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>status </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;completed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">list</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># The latest message will be the assistant&#x27;s response</span><span>
</span><span>    latest_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> latest_message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>role </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Assistant&#x27;s response: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">latest_message</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">content</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">0</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">value</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Tools (Code Interpreter, Retrieval, Function Calling)</h3>
<p class="my-4 leading-relaxed">Assistants can be equipped with various tools to enhance their capabilities:</p>
<h4>Code Interpreter</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create an assistant with code interpreter</span><span>
</span><span>code_assistant </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    name</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Python Coding Assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a Python programming assistant. Help users write, debug, and optimize Python code.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;code_interpreter&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a thread with a coding question</span><span>
</span><span>thread </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    role</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    content</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Can you write a Python function to calculate the Fibonacci sequence up to n terms?&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Run the assistant</span><span>
</span><span>run </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>runs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    assistant_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>code_assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real application, you would poll for completion</span><span>
</span><span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For demonstration, we assume the run completes successfully</span></code></pre></div></pre>
<h4>Retrieval</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Upload a file for retrieval</span><span>
</span><span></span><span class="token" style="color:hsl(95, 38%, 62%)">file</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>files</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;math_textbook.pdf&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rb&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    purpose</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistants&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create an assistant with retrieval</span><span>
</span><span>retrieval_assistant </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    name</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Math Textbook Assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful teaching assistant. Use the provided textbook to answer questions about mathematics.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;retrieval&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    file_ids</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">file</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a thread with a question about the textbook</span><span>
</span><span>thread </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    role</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    content</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What does the textbook say about the quadratic formula?&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Run the assistant</span><span>
</span><span>run </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>runs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    assistant_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>retrieval_assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h4>Function Calling</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define functions for the assistant to call</span><span>
</span><span>tools </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;get_stock_price&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Get the current stock price for a given ticker symbol&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;symbol&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The stock ticker symbol (e.g., AAPL for Apple)&quot;</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;symbol&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create an assistant with function calling</span><span>
</span><span>function_assistant </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    name</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Financial Assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a financial advisor assistant. Help users with investment questions and provide stock information when requested.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>tools
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a thread with a question about stocks</span><span>
</span><span>thread </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    role</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    content</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What&#x27;s the current price of Apple stock?&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Run the assistant</span><span>
</span><span>run </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>runs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    assistant_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>function_assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real application, you would need to handle the function call</span><span>
</span><span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For example:</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_function_calls</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>thread_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> run_id</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    run_status </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>runs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>retrieve</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        run_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>run_id
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> run_status</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>status </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requires_action&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        tool_calls </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> run_status</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>required_action</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>submit_tool_outputs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>tool_calls
</span><span>        tool_outputs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> tool_call </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> tool_calls</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>function</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>name </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;get_stock_price&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real application, you would call an actual stock API</span><span>
</span><span>                symbol </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>function</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>arguments</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;symbol&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                price </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;150.25&quot;</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Mock price</span><span>
</span>                
<span>                tool_outputs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tool_call_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> tool_call</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> price</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;currency&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;USD&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Submit the outputs back to the assistant</span><span>
</span><span>        client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>threads</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>runs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>submit_tool_outputs</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            thread_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>thread_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            run_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>run_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            tool_outputs</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>tool_outputs
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Implementation Examples</h3>
<h4>Building a Customer Support Assistant</h4>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">create_customer_support_assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Upload knowledge base documents</span><span>
</span><span>    faq_file </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>files</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;product_faq.pdf&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rb&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        purpose</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistants&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    manual_file </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>files</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_manual.pdf&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rb&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        purpose</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistants&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define functions for the assistant</span><span>
</span><span>    tools </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;check_order_status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Check the status of a customer&#x27;s order&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;order_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The order ID to check&quot;</span><span>
</span><span>                        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;order_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;function&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;create_return_request&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a return request for a product&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;parameters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;object&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;properties&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;order_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The order ID&quot;</span><span>
</span><span>                        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;product_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The product ID to return&quot;</span><span>
</span><span>                        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;reason&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;string&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Reason for the return&quot;</span><span>
</span><span>                        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;order_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;product_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;reason&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the assistant</span><span>
</span><span>    assistant </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>beta</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>assistants</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        name</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Product Support Assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        instructions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;You are a customer support assistant for our electronics company.
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">        Help customers with product questions, order issues, and return requests.
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">        Use the knowledge base to answer product-specific questions.
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">        Be friendly, concise, and helpful.&quot;&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        tools</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>tools </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;retrieval&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        file_ids</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>faq_file</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> manual_file</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> assistant</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Function implementations for the assistant to call</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">check_order_status</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>order_id</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real application, this would query an order database</span><span>
</span><span>    statuses </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;ORD12345&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Shipped - Expected delivery on April 5, 2025&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;ORD12346&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Processing - Will ship within 24 hours&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;ORD12347&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Delivered on March 30, 2025&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;order_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> order_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> statuses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>order_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Order not found&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;last_updated&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;2025-04-03T12:00:00Z&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">create_return_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>order_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> product_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> reason</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real application, this would create a return in your system</span><span>
</span><span>    return_id </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;RET&quot;</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>random</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>randint</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">10000</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">99999</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;return_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> return_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;order_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> order_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;product_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> product_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Created&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;instructions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Please print the return label and ship the product back within 14 days.&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Fine-tuning</h2>
<p class="my-4 leading-relaxed">Fine-tuning allows you to customize OpenAI&#x27;s models for specific use cases by training them on your own data.</p>
<h3 class="text-2xl font-semibold my-4">When and Why to Fine-tune Models</h3>
<p class="my-4 leading-relaxed">Fine-tuning is beneficial when:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Consistent Formatting</strong>: You need responses in a specific, consistent format</li>
<li class="pl-2"><strong>Domain Adaptation</strong>: You want the model to excel in a specialized domain</li>
<li class="pl-2"><strong>Custom Tone or Style</strong>: You need responses in a particular voice or style</li>
<li class="pl-2"><strong>Improved Performance</strong>: You want better results on specific tasks than prompting alone can achieve</li>
<li class="pl-2"><strong>Reduced Token Usage</strong>: You want to achieve better results with shorter prompts</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Preparing Training Data</h3>
<p class="my-4 leading-relaxed">Training data for fine-tuning should be formatted as a list of conversation examples:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example training data for a customer support assistant</span><span>
</span><span>training_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a customer support agent for Acme Electronics.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;My laptop won&#x27;t turn on.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I&#x27;m sorry to hear that your Acme laptop is not turning on. Let&#x27;s troubleshoot this issue together. First, please try these steps:\n\n1. Make sure the laptop is charged by connecting it to power. Look for a light indicator showing it&#x27;s receiving power.\n2. Press and hold the power button for 10 seconds, then release and try turning it on again.\n3. If possible, remove the battery, wait 30 seconds, reinsert it, and try again.\n\nCould you let me know if any of these steps help or if you notice any lights or sounds when attempting to power on?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a customer support agent for Acme Electronics.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;How do I connect my Acme Smart TV to WiFi?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Connecting your Acme Smart TV to WiFi is a straightforward process. Here&#x27;s how to do it:\n\n1. Press the Home button on your remote control\n2. Navigate to Settings (usually a gear icon)\n3. Select Network &amp; Internet or Network Settings\n4. Choose WiFi and turn it on if it isn&#x27;t already\n5. Select your WiFi network from the list\n6. Enter your WiFi password using the on-screen keyboard\n7. Select Connect or OK\n\nYour TV should connect within a few moments. If you encounter any issues, make sure your WiFi password is correct and that your router is functioning properly. Is there anything specific about this process you&#x27;re having trouble with?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Save the training data to a JSONL file</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;support_training_data.jsonl&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> example </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> training_data</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        f</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>write</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>example</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;\n&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Creating and Managing Fine-tuning Jobs</h3>
<p class="my-4 leading-relaxed">Once your training data is prepared, you can create a fine-tuning job:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Upload the training file</span><span>
</span><span>training_file </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>files</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;support_training_data.jsonl&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rb&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    purpose</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;fine-tuning&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a fine-tuning job</span><span>
</span><span>fine_tuning_job </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fine_tuning</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>jobs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    training_file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>training_file</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Base model to fine-tune</span><span>
</span><span>    suffix</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;acme-support&quot;</span><span>   </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Custom suffix for your fine-tuned model</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Fine-tuning job created: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">fine_tuning_job</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">id</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check the status of the fine-tuning job</span><span>
</span><span>job_status </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fine_tuning</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>jobs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>retrieve</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>fine_tuning_job</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Status: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">job_status</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">status</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># List all fine-tuning jobs</span><span>
</span><span>jobs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fine_tuning</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>jobs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">list</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> job </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> jobs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Job ID: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">job</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">id</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">, Model: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">job</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">, Status: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">job</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">status</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Using Fine-tuned Models</h3>
<p class="my-4 leading-relaxed">Once your fine-tuning job is complete, you can use your custom model:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get the fine-tuned model name from the job</span><span>
</span><span>job </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fine_tuning</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>jobs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>retrieve</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>fine_tuning_job</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">id</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>fine_tuned_model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> job</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fine_tuned_model
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Use the fine-tuned model</span><span>
</span><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>fine_tuned_model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a customer support agent for Acme Electronics.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;My Acme headphones won&#x27;t connect to my phone.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Cost Considerations</h3>
<p class="my-4 leading-relaxed">Fine-tuning involves both upfront training costs and usage costs:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Training Costs</strong>: Based on the number of tokens in your training data</li>
<li class="pl-2"><strong>Usage Costs</strong>: Typically higher per token than base models</li>
<li class="pl-2"><strong>Model Hosting</strong>: Fine-tuned models are hosted until you delete them</li>
</ol>
<p class="my-4 leading-relaxed">To optimize costs:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> tiktoken
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">estimate_fine_tuning_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>file_path</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Estimate the cost of fine-tuning based on token count&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Approximate costs (check OpenAI&#x27;s pricing page for current rates)</span><span>
</span><span>    training_cost_per_1k_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.008</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># for gpt-3.5-turbo</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        training_cost_per_1k_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span>
</span>    
<span>    encoding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tiktoken</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encoding_for_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>file_path</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> line </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            example </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>line</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> message </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> example</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add 4 tokens for message metadata</span><span>
</span><span>                total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add 2 tokens for conversation metadata</span><span>
</span><span>            total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span>
</span>    
<span>    estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> training_cost_per_1k_tokens
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost_usd&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> estimated_cost
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>cost_estimate </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> estimate_fine_tuning_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;support_training_data.jsonl&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Estimated fine-tuning cost: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">cost_estimate</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;estimated_cost_usd&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Moderation API</h2>
<p class="my-4 leading-relaxed">The Moderation API helps identify potentially harmful or inappropriate content to ensure responsible AI use.</p>
<h3 class="text-2xl font-semibold my-4">Content Filtering Capabilities</h3>
<p class="my-4 leading-relaxed">The Moderation API classifies text across several harm categories:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Hate</strong>: Content expressing hatred or discrimination</li>
<li class="pl-2"><strong>Harassment</strong>: Content intended to harass, intimidate, or bully</li>
<li class="pl-2"><strong>Self-harm</strong>: Content promoting self-harm or suicide</li>
<li class="pl-2"><strong>Sexual</strong>: Sexually explicit content</li>
<li class="pl-2"><strong>Violence</strong>: Content depicting or promoting violence</li>
<li class="pl-2"><strong>Violent/hate</strong>: Content that is both violent and hateful</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Implementation in Production Applications</h3>
<p class="my-4 leading-relaxed">Here&#x27;s how to integrate the Moderation API into your applications:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">check_content_moderation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Check if content violates content policy&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderations</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>results</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if the content is flagged</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>flagged</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            flagged_categories </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> flagged </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>categories</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> flagged</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    score </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">getattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>category_scores</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                    flagged_categories</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">category</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> (</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">score</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.4f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;categories&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> flagged_categories
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">moderate_user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Content Moderation Demo (type &#x27;exit&#x27; to quit)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        user_input </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;\nEnter text to check: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;exit&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check content before processing</span><span>
</span><span>        moderation_result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> check_content_moderation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">moderation_result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;error&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;â ï¸ Content flagged for the following categories:&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;categories&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;- </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">category</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;This content may violate our content policy.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;â Content passed moderation checks.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process the content with the OpenAI API</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;\nResponse: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">response</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">choices</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">0</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">message</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">content</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Handling Flagged Content</h3>
<p class="my-4 leading-relaxed">When content is flagged, you have several options:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_flagged_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Handle content that has been flagged by the moderation API&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Content is safe, process normally</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> process_safe_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get the flagged categories</span><span>
</span><span>    categories </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;categories&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Different handling strategies based on category and severity</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">any</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;hate&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rejected&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;We cannot process content that contains hateful language.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">any</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sexual&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rejected&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;We cannot process content that contains explicit sexual content.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">any</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;violence&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rejected&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;We cannot process content that contains violent content.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">any</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;self-harm&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;referred&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;If you&#x27;re experiencing thoughts of self-harm, please contact a mental health professional or call a crisis helpline.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For other categories or lower severity, you might warn but still process</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;warned&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Some aspects of your content may be inappropriate. We&#x27;ve processed your request, but please review our content guidelines.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> process_safe_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_safe_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process content that has passed moderation checks&quot;&quot;&quot;</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;processed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Pre-emptive Moderation System</h3>
<p class="my-4 leading-relaxed">For a more robust approach, implement pre-emptive moderation:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">ContentModerationSystem</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> openai_client</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> openai_client
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderation_log </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">moderate_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> user_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Moderate content and log the result&quot;&quot;&quot;</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderations</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>results</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log the moderation result</span><span>
</span><span>        log_entry </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content_preview&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> content</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span class="token" style="color:hsl(29, 54%, 61%)">50</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;...&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">50</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>flagged</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;categories&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>k</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> v </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> k</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> v </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>categories</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> v</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;category_scores&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>k</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">getattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>category_scores</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> k</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> k </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>categories</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>__dict__ </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">getattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>categories</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> k</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderation_log</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_entry</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> result
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_user_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> user_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a user request with moderation&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># First, check the content</span><span>
</span><span>        moderation_result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderate_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> user_id</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>flagged</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Content is flagged, determine how to handle it</span><span>
</span><span>            high_severity </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">any</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">getattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>category_scores</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.8</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>categories</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>__dict__
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">getattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>moderation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>categories</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> high_severity</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rejected&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Your request contains content that violates our usage policies.&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;warning&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Your request contains potentially inappropriate content. Please review our content guidelines.&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Content passed moderation, process the request</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> content</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Also moderate the response to ensure it&#x27;s appropriate</span><span>
</span><span>            response_text </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>            response_moderation </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderate_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response_text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> response_moderation</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>flagged</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># The AI generated inappropriate content</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;We couldn&#x27;t generate an appropriate response. Please try rephrasing your request.&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;success&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;response&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response_text
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;An error occurred: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_moderation_stats</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get statistics about moderation results&quot;&quot;&quot;</span><span>
</span><span>        total_requests </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderation_log</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        flagged_requests </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> entry </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderation_log </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> entry</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        category_counts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> entry </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>moderation_log</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> entry</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> category </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> entry</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;categories&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    category_counts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>category</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> category_counts</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>category</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_requests</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged_requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> flagged_requests</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;flagged_percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>flagged_requests </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> total_requests </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> total_requests </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;category_breakdown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> category_counts
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore error handling and best practices for working with the OpenAI API.</p>
<h1 class="text-4xl font-bold my-6">Error Handling and Best Practices</h1>
<h2 class="text-3xl font-semibold my-5">Common API Errors and How to Handle Them</h2>
<p class="my-4 leading-relaxed">When working with the OpenAI API, you&#x27;ll inevitably encounter errors. Understanding these errors and implementing proper handling strategies is crucial for building robust applications.</p>
<h3 class="text-2xl font-semibold my-4">Authentication Errors</h3>
<p class="my-4 leading-relaxed">Authentication errors occur when there are issues with your API key:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> AuthenticationError
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_authentication_error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Intentionally use an invalid API key</span><span>
</span><span>        client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;invalid_key&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> AuthenticationError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Authentication Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Please check your API key and ensure it&#x27;s valid.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a production application, you might:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 1. Log the error</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 2. Alert administrators</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 3. Prompt the user to re-enter credentials</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 4. Fall back to a non-API solution</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Rate Limit Errors</h3>
<p class="my-4 leading-relaxed">Rate limit errors occur when you exceed OpenAI&#x27;s request limits:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> RateLimitError
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_rate_limit_error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>max_retries</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    retries </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>    backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Start with 1 second backoff</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> RateLimitError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Rate limit exceeded. Retrying in </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">backoff_time</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> seconds... (Attempt </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Maximum retry attempts reached. Please try again later.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> e
</span>            
<span>            time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>backoff_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">*=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Exponential backoff</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Invalid Request Errors</h3>
<p class="my-4 leading-relaxed">Invalid request errors occur when your request parameters are incorrect:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> BadRequestError
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_invalid_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Intentionally use an invalid model name</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;non-existent-model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> BadRequestError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Invalid Request Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract error details</span><span>
</span><span>        error_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> error_message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The specified model does not exist or is not available.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Fall back to a known working model</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Fallback to a reliable model</span><span>
</span><span>                    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Successfully used fallback model.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> fallback_error</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Fallback also failed: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">fallback_error</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Server Errors</h3>
<p class="my-4 leading-relaxed">Server errors occur when there&#x27;s an issue on OpenAI&#x27;s end:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> APIError
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_server_error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>max_retries</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    retries </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Hello&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> APIError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            wait_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span> retries  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Exponential backoff</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Retrying in </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">wait_time</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> seconds... (Attempt </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Maximum retry attempts reached.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> e
</span>            
<span>            time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>wait_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Timeout Errors</h3>
<p class="my-4 leading-relaxed">Timeout errors occur when a request takes too long to complete:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> APITimeoutError
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_timeout_error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>max_retries</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    retries </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Set a shorter timeout for demonstration</span><span>
</span><span>            client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                timeout</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5.0</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 5 second timeout</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a detailed essay on quantum physics&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> APITimeoutError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Timeout Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Retrying... (Attempt </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Maximum retry attempts reached.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Consider simplifying the request or using a different approach</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> e</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Comprehensive Error Handling</h3>
<p class="my-4 leading-relaxed">Here&#x27;s a comprehensive approach to handling various API errors:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> logging
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> AuthenticationError</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> RateLimitError</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> APIError</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> BadRequestError</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> APITimeoutError</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> APIConnectionError
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Configure logging</span><span>
</span><span>logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>basicConfig</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    level</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>INFO</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">format</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    handlers</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>FileHandler</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai_api.log&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>StreamHandler</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>logger </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>getLogger</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai_api&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">create_openai_client</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Create an OpenAI client with proper error handling&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> client
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Failed to initialize OpenAI client: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">make_api_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_retries</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> initial_backoff</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Make an API request with comprehensive error handling and retries&quot;&quot;&quot;</span><span>
</span><span>    retries </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>    backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> initial_backoff
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> AuthenticationError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Authentication Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Authentication errors should not be retried</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> RateLimitError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>warning</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Rate Limit Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">. Attempt </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;=</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Maximum retry attempts reached for rate limit error.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Exponential backoff with jitter</span><span>
</span><span>            jitter </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> random</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>uniform</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.1</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> backoff_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            sleep_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> jitter
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>info</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Retrying in </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">sleep_time</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> seconds...&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>sleep_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">*=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> APITimeoutError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>warning</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Timeout Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">. Attempt </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;=</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Maximum retry attempts reached for timeout error.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span>
</span>            
<span>            time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>backoff_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">*=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.5</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Slightly gentler backoff for timeouts</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> APIConnectionError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>warning</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Connection Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">. Attempt </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;=</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Maximum retry attempts reached for connection error.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span>
</span>            
<span>            time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>backoff_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">*=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> BadRequestError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Bad Request Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if it&#x27;s a model error and try to fall back</span><span>
</span><span>            error_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> error_message </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> model </span><span class="token" style="color:hsl(207, 82%, 66%)">!=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>info</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Attempting to fall back to gpt-3.5-turbo model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> make_api_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_retries</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Other bad requests should not be retried</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> APIError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>warning</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">. Attempt </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;=</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Maximum retry attempts reached for API error.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span>
</span>            
<span>            time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>backoff_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            backoff_time </span><span class="token" style="color:hsl(207, 82%, 66%)">*=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Unexpected error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Rate Limits and How to Work Within Them</h2>
<p class="my-4 leading-relaxed">OpenAI imposes rate limits to ensure fair usage and system stability. Understanding and working within these limits is essential for reliable applications.</p>
<h3 class="text-2xl font-semibold my-4">Understanding Rate Limits</h3>
<p class="my-4 leading-relaxed">Rate limits are applied at several levels:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Requests per Minute (RPM)</strong>: Limits the number of API requests you can make per minute</li>
<li class="pl-2"><strong>Tokens per Minute (TPM)</strong>: Limits the total number of tokens (input + output) processed per minute</li>
<li class="pl-2"><strong>Tier-Based Limits</strong>: Different account tiers have different rate limits</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Implementing Retry Mechanisms</h3>
<p class="my-4 leading-relaxed">A robust retry mechanism is essential for handling rate limit errors:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> random
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> RateLimitError
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">retry_with_exponential_backoff</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    func</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    initial_delay</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    exponential_base</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    jitter</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    max_retries</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Retry a function with exponential backoff.&quot;&quot;&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">wrapper</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>args</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>kwargs</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Initialize variables</span><span>
</span><span>        num_retries </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>        delay </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> initial_delay
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Loop until a successful response or max_retries is hit</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> func</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>args</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>kwargs</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Retry on rate limit errors</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> RateLimitError </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Increment retries</span><span>
</span><span>                num_retries </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if max retries has been reached</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> num_retries </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> max_retries</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> Exception</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Maximum number of retries (</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">max_retries</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">) exceeded.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Increment the delay</span><span>
</span><span>                delay </span><span class="token" style="color:hsl(207, 82%, 66%)">*=</span><span> exponential_base </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> jitter </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> random</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>random</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Sleep for the delay</span><span>
</span><span>                time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>delay</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Raise other errors</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> e
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> wrapper
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">@retry_with_exponential_backoff</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">make_openai_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Batching Requests Efficiently</h3>
<p class="my-4 leading-relaxed">Batching requests can help you stay within rate limits while maximizing throughput:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> asyncio
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> AsyncOpenAI
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_batch</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batch_size</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> delay_between_batches</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a large number of prompts in batches&quot;&quot;&quot;</span><span>
</span><span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AsyncOpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process prompts in batches</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batch_size</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        batch </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>i</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>i</span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span>batch_size</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        batch_results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create tasks for concurrent processing</span><span>
</span><span>        tasks </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            process_single_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> prompt </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> batch
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Execute batch concurrently</span><span>
</span><span>        batch_results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>gather</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>tasks</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> return_exceptions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>extend</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>batch_results</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Delay between batches to avoid rate limits</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> i </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> batch_size </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Processed batch </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">//</span><span class="token string-interpolation interpolation">batch_size </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">len</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">prompts</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation"> batch_size </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">-</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">//</span><span class="token string-interpolation interpolation">batch_size</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">. Waiting...&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>delay_between_batches</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_single_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a single prompt with error handling&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">main</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    prompts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a haiku about mountains&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Explain quantum computing&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a short story about a robot&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># ... more prompts</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> process_batch</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batch_size</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> delay_between_batches</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> result </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>results</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Result </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Run the async function</span><span>
</span><span>asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>run</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>main</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Caching Strategies</h3>
<p class="my-4 leading-relaxed">Implementing caching can significantly reduce API calls for repeated or similar requests:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> hashlib
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> redis
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">OpenAICache</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> redis_url</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;redis://localhost:6379/0&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> expire_time</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">86400</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize cache with Redis backend&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>redis_client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> redis</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_url</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>redis_url</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>expire_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> expire_time  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Cache expiration in seconds (default: 24 hours)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">_generate_cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a unique cache key based on request parameters&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a dictionary of the parameters that affect the response</span><span>
</span><span>        cache_dict </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;temperature&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> temperature
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Convert to a stable string representation and hash it</span><span>
</span><span>        cache_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_dict</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> sort_keys</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;openai:cache:</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">hashlib</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">md5</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">cache_str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">encode</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">hexdigest</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get a cached response if available&quot;&quot;&quot;</span><span>
</span><span>        cache_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_generate_cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        cached_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>redis_client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> cached_data</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cached_data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">cache_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Cache a response&quot;&quot;&quot;</span><span>
</span><span>        cache_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_generate_cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Store only the necessary parts of the response</span><span>
</span><span>        cache_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;choices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>redis_client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>setex</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>expire_time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_completion_with_cache</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cache</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get a completion with caching&quot;&quot;&quot;</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check cache first</span><span>
</span><span>    cached_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cache</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Using cached response&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;choices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If not in cache, make API call</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Making API call&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>temperature
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Cache the response</span><span>
</span><span>    cache</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cache_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Logging and Monitoring API Usage</h2>
<p class="my-4 leading-relaxed">Proper logging and monitoring are essential for tracking API usage, debugging issues, and optimizing costs.</p>
<h3 class="text-2xl font-semibold my-4">Setting Up Comprehensive Logging</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> logging
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> uuid
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> datetime </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> datetime
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APILogger</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> log_file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai_api.log&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API logger&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Configure logging</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logger </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>getLogger</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai_api&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>setLevel</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>INFO</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># File handler</span><span>
</span><span>        file_handler </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>FileHandler</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        file_handler</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>setLevel</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>INFO</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Console handler</span><span>
</span><span>        console_handler </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>StreamHandler</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        console_handler</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>setLevel</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>WARNING</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Formatter</span><span>
</span><span>        formatter </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> logging</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>Formatter</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        file_handler</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>setFormatter</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>formatter</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        console_handler</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>setFormatter</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>formatter</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add handlers</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>addHandler</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>file_handler</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>addHandler</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>console_handler</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">log_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Log an API request&quot;&quot;&quot;</span><span>
</span><span>        request_id </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>uuid</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>uuid4</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        request_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate input tokens (approximate)</span><span>
</span><span>        input_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>m</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>split</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.3</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> m </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        log_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> request_time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;temperature&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;max_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> max_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_tokens_approx&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">int</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>input_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages_count&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>info</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API Request: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">json</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">dumps</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">log_data</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> request_id
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">log_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> elapsed_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Log an API response&quot;&quot;&quot;</span><span>
</span><span>        response_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract relevant information from the response</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">hasattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            usage </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>total_tokens
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            usage </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        log_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response_time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;elapsed_time_ms&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">int</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>elapsed_time </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> usage
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>info</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API Response: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">json</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">dumps</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">log_data</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">log_error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> error</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> elapsed_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Log an API error&quot;&quot;&quot;</span><span>
</span><span>        error_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        log_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> error_time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;elapsed_time_ms&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">int</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>elapsed_time </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error_type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">type</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>__name__</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error_message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">json</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">dumps</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">log_data</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">make_api_call_with_logging</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Make an API call with comprehensive logging&quot;&quot;&quot;</span><span>
</span><span>    api_logger </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> APILogger</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log the request</span><span>
</span><span>    request_id </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> api_logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    start_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>time</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate elapsed time</span><span>
</span><span>        elapsed_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>time</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> start_time
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log the response</span><span>
</span><span>        api_logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> elapsed_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate elapsed time</span><span>
</span><span>        elapsed_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>time</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> start_time
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log the error</span><span>
</span><span>        api_logger</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_error</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> elapsed_time</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Re-raise the exception</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Monitoring API Usage</h3>
<p class="my-4 leading-relaxed">Implementing a dashboard for monitoring API usage can help you track costs and optimize usage:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> pandas </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> pd
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> matplotlib</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>pyplot </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> plt
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> datetime </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> timedelta
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIUsageMonitor</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> log_file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai_api.log&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API usage monitor&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> log_file
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">parse_logs</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Parse the log file and extract API usage data&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate the cutoff date</span><span>
</span><span>        cutoff_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> timedelta</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>days</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        requests </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        responses </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        errors </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> line </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Parse the log line</span><span>
</span><span>                    parts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> line</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>strip</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>split</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot; - &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                    timestamp_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> parts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                    log_type </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> parts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                    log_data_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot; - &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>parts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                    
<span>                    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Parse the timestamp</span><span>
</span><span>                    timestamp </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fromisoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>timestamp_str</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>split</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;,&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                    
<span>                    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Skip entries before the cutoff date</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> timestamp </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> cutoff_date</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                        </span><span class="token" style="color:hsl(286, 60%, 67%)">continue</span><span>
</span>                    
<span>                    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract the JSON data</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;API Request&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> log_data_str</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                        data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_data_str</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>replace</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;API Request: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                        requests</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;API Response&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> log_data_str</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                        data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_data_str</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>replace</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;API Response: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                        responses</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;API Error&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> log_data_str</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                        data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_data_str</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>replace</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;API Error: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                        errors</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Skip malformed log lines</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">continue</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> requests</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;responses&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> responses</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;errors&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> errors
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_usage_report</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a usage report for the specified number of days&quot;&quot;&quot;</span><span>
</span><span>        data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>parse_logs</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create DataFrames</span><span>
</span><span>        requests_df </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> pd</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DataFrame</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        responses_df </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> pd</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DataFrame</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;responses&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        errors_df </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> pd</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DataFrame</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;errors&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Merge request and response data</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> responses_df</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>empty </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> requests_df</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>empty</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            merged_df </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> pd</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>merge</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                requests_df</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                responses_df</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                on</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                suffixes</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;_req&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;_resp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate daily token usage</span><span>
</span><span>            merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> pd</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>to_datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp_req&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>date
</span><span>            daily_usage </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>groupby</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>agg</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage.total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sum&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;count&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>rename</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>columns</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage.total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_count&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate model usage</span><span>
</span><span>            model_usage </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>groupby</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_req&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>agg</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage.total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sum&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;count&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>rename</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>columns</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage.total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_count&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate error rate</span><span>
</span><span>            total_requests </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>requests_df</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            total_errors </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>errors_df</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            error_rate </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> total_errors </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> total_requests </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> total_requests </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate average response time</span><span>
</span><span>            avg_response_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;elapsed_time_ms&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>mean</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;elapsed_time_ms&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>columns </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Estimate cost (approximate)</span><span>
</span><span>            cost_per_1k_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># $10 per 1M tokens</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>   </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># $30 per 1M tokens</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.001</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># $1 per 1M tokens</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>            
<span>            merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">apply</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">lambda</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage.total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> cost_per_1k_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_req&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                axis</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            total_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> daily_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_requests</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_errors&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_errors</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error_rate&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> error_rate</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;avg_response_time&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> avg_response_time</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> merged_df</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage.total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_cost
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;No data available for the specified period&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">plot_usage_trends</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Plot usage trends for the specified number of days&quot;&quot;&quot;</span><span>
</span><span>        report </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>generate_usage_report</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a figure with subplots</span><span>
</span><span>        fig</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> axs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> plt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>subplots</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> figsize</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">15</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Plot daily token usage</span><span>
</span><span>        report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>plot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            kind</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;bar&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            ax</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            title</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Daily Token Usage&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>set_ylabel</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>set_xlabel</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Plot daily request count</span><span>
</span><span>        report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_count&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>plot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            kind</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;bar&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            ax</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            title</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Daily Request Count&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>set_ylabel</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>set_xlabel</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Plot model usage (tokens)</span><span>
</span><span>        report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>plot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            kind</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;pie&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            ax</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            title</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Token Usage by Model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            autopct</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;%1.1f%%&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Plot model usage (requests)</span><span>
</span><span>        report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_count&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>plot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            kind</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;pie&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            ax</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>axs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            title</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Request Count by Model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            autopct</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;%1.1f%%&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add a title to the figure</span><span>
</span><span>        fig</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>suptitle</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;OpenAI API Usage Report (Last </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">days</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> Days)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> fontsize</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">16</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Adjust layout</span><span>
</span><span>        plt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>tight_layout</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        plt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>subplots_adjust</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>top</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.9</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Save the figure</span><span>
</span><span>        plt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>savefig</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;api_usage_report.png&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Print summary statistics</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Summary Statistics (Last </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">days</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> Days):&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Total Requests: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">report</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;total_requests&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Total Tokens: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">report</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;total_tokens&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error Rate: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">report</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;error_rate&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">*</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">100</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">%&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Average Response Time: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">report</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;avg_response_time&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> ms&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Estimated Cost: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">report</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;estimated_cost&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;api_usage_report.png&quot;</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Security Best Practices</h2>
<p class="my-4 leading-relaxed">Implementing proper security measures is crucial when working with the OpenAI API.</p>
<h3 class="text-2xl font-semibold my-4">API Key Management</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> dotenv </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> load_dotenv
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> keyring
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIKeyManager</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> service_name</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai-api&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API key manager&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>service_name </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> service_name
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">store_api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> key</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> username</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;default&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Store the API key securely&quot;&quot;&quot;</span><span>
</span><span>        keyring</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>set_password</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>service_name</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> username</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API key stored securely for user &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">username</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&#x27;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> username</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;default&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Retrieve the API key&quot;&quot;&quot;</span><span>
</span><span>        key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> keyring</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_password</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>service_name</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> username</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> key</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> ValueError</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;No API key found for user &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">username</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&#x27;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> key
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">delete_api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> username</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;default&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Delete the stored API key&quot;&quot;&quot;</span><span>
</span><span>        keyring</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>delete_password</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>service_name</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> username</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API key deleted for user &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">username</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&#x27;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">setup_secure_client</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Set up a secure OpenAI client&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Try to get the API key from environment variables first</span><span>
</span><span>    api_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If not found, try to get it from the secure storage</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            key_manager </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> APIKeyManager</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            api_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> key_manager</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error retrieving API key: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Prompt the user for the API key</span><span>
</span><span>            api_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Please enter your OpenAI API key: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Ask if they want to store it securely</span><span>
</span><span>            store_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Do you want to store this key securely? (y/n): &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> store_key </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;y&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                key_manager </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> APIKeyManager</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                key_manager</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>store_api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the client with the API key</span><span>
</span><span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>api_key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> client</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Request Validation</h3>
<p class="my-4 leading-relaxed">Implementing request validation can prevent security issues and improve reliability:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> re
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">RequestValidator</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the request validator&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define validation rules</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>max_prompt_length </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4000</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>allowed_models </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sensitive_pattern </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">compile</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">r&#x27;(password|api[_\s]?key|secret|token|credential|auth[_\s]?token)&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>IGNORECASE
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">validate_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Validate a prompt for security and quality issues&quot;&quot;&quot;</span><span>
</span><span>        issues </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check length</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>max_prompt_length</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            issues</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Prompt exceeds maximum length of </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">max_prompt_length</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> characters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check for sensitive information</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sensitive_pattern</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            issues</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Prompt may contain sensitive information (passwords, API keys, etc.)&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check for excessive special characters (potential injection)</span><span>
</span><span>        special_char_count </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> c </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> prompt </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> c</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isalnum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> c</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isspace</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> special_char_count </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.3</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            issues</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Prompt contains an unusually high number of special characters&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>issues</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> issues
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">validate_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Validate that the requested model is allowed&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>allowed_models</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Model &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&#x27; is not in the list of allowed models&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">validate_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Validate a complete API request&quot;&quot;&quot;</span><span>
</span><span>        issues </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate model</span><span>
</span><span>        model_validation </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>validate_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> model_validation</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            issues</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>extend</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model_validation</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate each message</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> message </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> message </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                prompt_validation </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>validate_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> prompt_validation</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> issue </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> prompt_validation</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                        issues</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Message </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">issue</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate temperature</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> temperature </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>temperature </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> temperature </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            issues</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Temperature must be between 0 and 2&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate max_tokens</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> max_tokens </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> max_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            issues</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;max_tokens must be at least 1&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>issues</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> issues
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">make_validated_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Make a validated API request&quot;&quot;&quot;</span><span>
</span><span>    validator </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> RequestValidator</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate the request</span><span>
</span><span>    validation_result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> validator</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>validate_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> validation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Request validation failed:&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> issue </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> validation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;- </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">issue</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>temperature
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API request failed: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Secure Proxy Implementation</h3>
<p class="my-4 leading-relaxed">For applications where clients need to access the API, implementing a secure proxy is recommended:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> flask </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> Flask</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> jsonify
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> jwt
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> datetime
</span>
<span>app </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> Flask</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>__name__</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>app</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>config</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;SECRET_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;your-secret-key&quot;</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Use a secure random key in production</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># OpenAI client</span><span>
</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># User authentication (simplified for example)</span><span>
</span><span></span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">@app</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">.</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">route</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;/api/login&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> methods</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;POST&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">login</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real application, validate credentials against a database</span><span>
</span><span>    username </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;username&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    password </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;password&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Simplified authentication</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> username </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;demo&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> password </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;password&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Generate JWT token</span><span>
</span><span>        token </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> jwt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> username</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;exp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>utcnow</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>timedelta</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>hours</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            app</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>config</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;SECRET_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            algorithm</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;HS256&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;token&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> token</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Invalid credentials&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">401</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Middleware to verify JWT token</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">token_required</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">decorated</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>args</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>kwargs</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        token </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>headers</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Authorization&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> token</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Token is missing&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">401</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Remove &quot;Bearer &quot; prefix if present</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> token</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>startswith</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Bearer &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                token </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> token</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">7</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Decode the token</span><span>
</span><span>            data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> jwt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>decode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>token</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> app</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>config</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;SECRET_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> algorithms</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;HS256&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Invalid token&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">401</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>args</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>kwargs</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> decorated
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># OpenAI API proxy endpoint</span><span>
</span><span></span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">@app</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">.</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">route</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;/api/openai/chat&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> methods</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;POST&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">@token_required</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">openai_chat_proxy</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get request data</span><span>
</span><span>    data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>json
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate required fields</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Messages are required&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">400</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Set default values for optional parameters</span><span>
</span><span>    model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    temperature </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;temperature&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    max_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;max_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Validate the request</span><span>
</span><span>    validator </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> RequestValidator</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    validation_result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> validator</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>validate_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_tokens
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> validation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;valid&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Validation failed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> validation_result</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;issues&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">400</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>max_tokens
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Return the response</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>total_tokens
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> __name__ </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;__main__&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    app</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>run</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>debug</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore performance optimization techniques for working with the OpenAI API.</p>
<h1 class="text-4xl font-bold my-6">Performance Optimization Techniques</h1>
<h2 class="text-3xl font-semibold my-5">Prompt Engineering for Efficiency</h2>
<p class="my-4 leading-relaxed">Effective prompt engineering can significantly improve the performance and efficiency of your OpenAI API usage.</p>
<h3 class="text-2xl font-semibold my-4">Designing Clear and Concise Prompts</h3>
<p class="my-4 leading-relaxed">Well-designed prompts lead to better responses while using fewer tokens:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Less efficient prompt</span><span>
</span><span>inefficient_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">I need you to summarize a text about climate change. The text is quite long and contains a lot of information about global warming, rising sea levels, and the impact on ecosystems. I want you to make sure you capture all the key points while keeping the summary concise. Please make sure to mention the causes of climate change, the effects, and potential solutions. The text is as follows:
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">[Long text about climate change...]
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># More efficient prompt</span><span>
</span><span>efficient_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">Summarize the following text about climate change, covering causes, effects, and solutions:
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">[Long text about climate change...]
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># The efficient prompt communicates the same requirements with fewer tokens</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Using System Messages Effectively</h3>
<p class="my-4 leading-relaxed">System messages can set the stage for the entire conversation, reducing the need for repetitive instructions:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example of effective system message usage</span><span>
</span><span>response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> 
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a technical documentation writer. Provide concise, accurate explanations with code examples when relevant. Use markdown formatting.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> 
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Explain how to implement pagination in a REST API.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Structuring Multi-turn Conversations</h3>
<p class="my-4 leading-relaxed">For multi-turn conversations, maintain context efficiently:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">efficient_conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Initialize with a clear system message</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful assistant that provides concise, accurate information.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        user_input </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;exit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;quit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;bye&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add user message</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get response</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        assistant_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Assistant: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">assistant_message</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add assistant message to history</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> assistant_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Manage context window by summarizing or truncating when needed</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Summarize the conversation so far</span><span>
</span><span>            summary_request </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Summarize the key points of this conversation concisely.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Exclude system message and recent exchanges</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>            
<span>            summary_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>summary_request
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            summary </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> summary_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Reset the conversation with the summary</span><span>
</span><span>            messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Keep the original system message</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Previous conversation summary: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">summary</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Keep the last user message</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>   </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Keep the last assistant message</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Token Optimization Strategies</h2>
<p class="my-4 leading-relaxed">Optimizing token usage can significantly reduce costs and improve performance.</p>
<h3 class="text-2xl font-semibold my-4">Token Counting and Budgeting</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> tiktoken
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">count_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Count the number of tokens in a text string.&quot;&quot;&quot;</span><span>
</span><span>    encoding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tiktoken</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encoding_for_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">count_message_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Count the number of tokens in a list of messages.&quot;&quot;&quot;</span><span>
</span><span>    encoding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tiktoken</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encoding_for_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># From OpenAI&#x27;s documentation on token counting</span><span>
</span><span>    tokens_per_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Every message follows &lt;im_start&gt;{role/name}\n{content}&lt;im_end&gt;\n</span><span>
</span><span>    tokens_per_name </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>     </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If there&#x27;s a name, the role is omitted</span><span>
</span>    
<span>    total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> message </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> tokens_per_message
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> key</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> value </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>value</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> key </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> tokens_per_name
</span>    
<span>    total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Every reply is primed with &lt;im_start&gt;assistant</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> total_tokens
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">optimize_within_token_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">4000</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Optimize messages to fit within a token budget.&quot;&quot;&quot;</span><span>
</span><span>    current_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> count_message_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> current_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;=</span><span> max_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> messages
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># We need to reduce the token count</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Strategy: Keep system message, recent messages, and summarize older messages</span><span>
</span>    
<span>    system_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>m </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> m </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> m</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    non_system_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>m </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> m </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> m</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">!=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If we have too many messages, summarize the older ones</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>non_system_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Keep the most recent messages</span><span>
</span><span>        recent_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> non_system_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        older_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> non_system_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a summary of older messages</span><span>
</span><span>        older_content </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;\n&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">m</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;role&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">m</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;content&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> m </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> older_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        summary_request </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Summarize the following conversation extremely concisely:&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> older_content</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        summary_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Use a cheaper model for summarization</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>summary_request</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">200</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Limit the summary size</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        summary </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> summary_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Replace older messages with a summary</span><span>
</span><span>        optimized_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> system_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Previous conversation summary: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">summary</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> recent_messages
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if we&#x27;re now within budget</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> count_message_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>optimized_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;=</span><span> max_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> optimized_messages
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If we&#x27;re still over budget, truncate content</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Start with the oldest non-system messages</span><span>
</span><span>    optimized_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> system_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>copy</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    remaining_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> max_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> count_message_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>optimized_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> message </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> non_system_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        message_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> count_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 4 tokens for message metadata</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> message_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;=</span><span> remaining_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Message fits within budget</span><span>
</span><span>            optimized_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            remaining_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">-=</span><span> message_tokens
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Message needs truncation</span><span>
</span><span>            encoding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tiktoken</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encoding_for_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            truncated_content </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>decode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>remaining_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            truncated_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> truncated_content </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;...&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            optimized_messages</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>truncated_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> optimized_messages</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Chunking Large Documents</h3>
<p class="my-4 leading-relaxed">When working with large documents, chunking can help manage token limits:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_large_document</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>document</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> chunk_size</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">2000</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> overlap</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">200</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a large document by breaking it into overlapping chunks.&quot;&quot;&quot;</span><span>
</span><span>    encoding </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tiktoken</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encoding_for_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>document</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process document in chunks</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> chunk_size </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> overlap</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get chunk with overlap</span><span>
</span><span>        chunk_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>i</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>i </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> chunk_size</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        chunk_text </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> encoding</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>decode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>chunk_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process the chunk</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are processing part of a larger document. Focus on extracting key information.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Process the following text (chunk </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">//</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">chunk_size </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">-</span><span class="token string-interpolation interpolation"> overlap</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">):\n\n</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">chunk_text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Combine results</span><span>
</span><span>    combined_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are combining information from multiple document chunks. Create a coherent synthesis.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Combine these document processing results into a coherent whole:\n\n</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">results</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> combined_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Compression Techniques</h3>
<p class="my-4 leading-relaxed">For applications that need to maintain long conversation histories, compression can help:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">compress_conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Compress a conversation history to reduce token usage.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract system messages</span><span>
</span><span>    system_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>m </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> m </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> m</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get non-system messages</span><span>
</span><span>    conversation </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>m </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> m </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> messages </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> m</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">!=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If conversation is short, no need to compress</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> messages
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Prepare conversation for compression</span><span>
</span><span>    conversation_text </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;\n\n&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">m</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;role&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">upper</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">m</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;content&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> m </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> conversation
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Compress the conversation</span><span>
</span><span>    compression_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> 
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Compress the following conversation into a minimal form that preserves all important information and context. Focus on key points, decisions, and information shared.&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> conversation_text</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    compressed_conversation </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> compression_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a new message list with the compressed history</span><span>
</span><span>    compressed_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> system_messages </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Compressed conversation history: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">compressed_conversation</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Keep the most recent user message for context</span><span>
</span><span>        conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> compressed_messages</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Parallel Processing and Batching</h2>
<p class="my-4 leading-relaxed">For applications that need to process multiple requests, parallel processing and batching can improve throughput.</p>
<h3 class="text-2xl font-semibold my-4">Asynchronous Processing</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> asyncio
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> AsyncOpenAI
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_multiple_prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process multiple prompts in parallel using async.&quot;&quot;&quot;</span><span>
</span><span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AsyncOpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_single_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create tasks for all prompts</span><span>
</span><span>    tasks </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>process_single_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> prompt </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Execute all tasks concurrently</span><span>
</span><span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>gather</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>tasks</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">main</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    prompts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Explain quantum computing in simple terms.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Write a short poem about the ocean.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What are the key features of Python?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Describe the process of photosynthesis.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;What is the capital of France and some interesting facts about it?&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> process_multiple_prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> result </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>results</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Result </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">:\n</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Run the async function</span><span>
</span><span>asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>run</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>main</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Controlled Concurrency</h3>
<p class="my-4 leading-relaxed">To avoid rate limits, implement controlled concurrency:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> asyncio
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> openai </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> AsyncOpenAI
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_with_controlled_concurrency</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_concurrency</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process prompts with controlled concurrency to avoid rate limits.&quot;&quot;&quot;</span><span>
</span><span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AsyncOpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Semaphore to control concurrency</span><span>
</span><span>    semaphore </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>Semaphore</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>max_concurrency</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_with_semaphore</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> semaphore</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">finally</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add a small delay to avoid hitting rate limits</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">0.1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create tasks for all prompts</span><span>
</span><span>    tasks </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>process_with_semaphore</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> prompt </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Execute tasks with controlled concurrency</span><span>
</span><span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>gather</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>tasks</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Batch Processing with Progress Tracking</h3>
<p class="my-4 leading-relaxed">For large batches, implement progress tracking:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> asyncio
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> tqdm </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> tqdm
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">batch_process_with_progress</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batch_size</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_concurrency</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a large batch of prompts with progress tracking.&quot;&quot;&quot;</span><span>
</span><span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AsyncOpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Semaphore to control concurrency</span><span>
</span><span>    semaphore </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>Semaphore</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>max_concurrency</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Results container</span><span>
</span><span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Progress bar</span><span>
</span><span>    pbar </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tqdm</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>total</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> desc</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Processing prompts&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>index</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">async</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> semaphore</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                results</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>index</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                results</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>index</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">finally</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                pbar</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>update</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add a small delay to avoid hitting rate limits</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">0.1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process in batches</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batch_size</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        batch </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>i</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>i </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> batch_size</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create tasks for the current batch</span><span>
</span><span>        tasks </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            process_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>i </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> j</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> j</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>batch</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Execute batch</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>gather</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span>tasks</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add a delay between batches</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> i </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> batch_size </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">await</span><span> asyncio</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    pbar</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>close</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Implementing Fallback Mechanisms</h2>
<p class="my-4 leading-relaxed">Robust applications need fallback mechanisms to handle various failure scenarios.</p>
<h3 class="text-2xl font-semibold my-4">Model Fallback Chain</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">model_fallback_chain</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> models</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Try multiple models in sequence until one succeeds.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> models </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        models </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    last_error </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> models</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If successful, return the result and the model used</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;success&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            last_error </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error with model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">last_error</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">continue</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If all models fail, return the error</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;success&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> last_error
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Content Fallback Strategies</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">content_fallback_strategy</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_attempts</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Try different prompt formulations if initial attempts fail.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Original attempt</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> original_error</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Original attempt failed: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">original_error</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Fallback 1: Simplify the prompt</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        simplified_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Please answer this question simply: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">prompt</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> simplified_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> fallback1_error</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Simplified prompt failed: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">fallback1_error</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Fallback 2: Break into smaller parts</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># This is a simplified example; in practice, you would use NLP to break the prompt</span><span>
</span><span>        parts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>split</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;. &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> part </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> parts</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> part</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> part</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Combine the results</span><span>
</span><span>        combined_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Combine these responses into a coherent answer: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">results</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> combined_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> fallback2_error</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Breaking into parts failed: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">fallback2_error</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Final fallback: Return a generic response</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I&#x27;m sorry, I couldn&#x27;t process your request at this time. Please try again later or rephrase your question.&quot;</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Hybrid Approaches</h3>
<p class="my-4 leading-relaxed">For critical applications, consider hybrid approaches that combine AI with traditional methods:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">hybrid_question_answering</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> knowledge_base</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Hybrid approach combining retrieval and generation.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Step 1: Try to find an answer in the knowledge base</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        kb_answer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> search_knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> kb_answer</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;answer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> kb_answer</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;source&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;knowledge_base&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;confidence&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Step 2: Try the OpenAI API</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;answer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;source&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai_api&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;confidence&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;API error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Step 3: Fall back to a rule-based system</span><span>
</span><span>    rule_based_answer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> rule_based_qa_system</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> rule_based_answer</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;answer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> rule_based_answer</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;source&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;rule_based&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;confidence&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Step 4: Final fallback</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;answer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I don&#x27;t have enough information to answer that question at this time.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;source&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;fallback&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;confidence&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">search_knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Search a knowledge base for an answer (simplified example).&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real implementation, this would use vector search or another retrieval method</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> entry </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> entry</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;question&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> entry</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;answer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">rule_based_qa_system</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Simple rule-based QA system as a fallback.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Simplified example with a few rules</span><span>
</span><span>    question_lower </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;hours&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question_lower </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;open&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question_lower</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Our hours of operation are Monday to Friday, 9 AM to 5 PM.&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;contact&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question_lower </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;support&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question_lower</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You can contact our support team at support@example.com or call 1-800-555-1234.&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question_lower </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question_lower</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Our pricing information can be found on our website at example.com/pricing.&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Cost Optimization Strategies</h2>
<p class="my-4 leading-relaxed">Implementing cost optimization strategies can help manage your OpenAI API expenses.</p>
<h3 class="text-2xl font-semibold my-4">Tiered Model Selection</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">tiered_model_selection</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> complexity_threshold</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.5</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Select the appropriate model based on prompt complexity.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Analyze prompt complexity (simplified example)</span><span>
</span><span>    words </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>split</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    avg_word_length </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>word</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> word </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> words</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>words</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> words </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>    sentence_count </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>count</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>count</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;!&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>count</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    avg_sentence_length </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>words</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> sentence_count </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> sentence_count </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>words</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate complexity score (simplified)</span><span>
</span><span>    complexity_score </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>avg_word_length </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>avg_sentence_length </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">20</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Select model based on complexity</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> complexity_score </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> complexity_threshold</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># More complex prompts get the more capable model</span><span>
</span><span>        model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Simpler prompts get the more economical model</span><span>
</span><span>        model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Prompt complexity: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">complexity_score</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">, using model: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call with the selected model</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Usage Monitoring and Budgeting</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIBudgetManager</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> daily_budget</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">10.0</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the budget manager with a daily budget in USD.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>daily_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> daily_budget
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_log </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>today </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>date</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Approximate costs per 1K tokens (check OpenAI&#x27;s pricing page for current rates)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cost_per_1k_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># $10 per 1M tokens</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>   </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># $30 per 1M tokens</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.001</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># $1 per 1M tokens</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">log_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Log API usage.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Reset if it&#x27;s a new day</span><span>
</span><span>        current_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>date</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> current_date </span><span class="token" style="color:hsl(207, 82%, 66%)">!=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>today</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>today </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> current_date
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_log </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate cost</span><span>
</span><span>        total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompt_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> completion_tokens
</span><span>        cost_per_1k </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cost_per_1k_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Default to gpt-4o pricing if unknown</span><span>
</span><span>        cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> cost_per_1k
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log the usage</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_log</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> cost
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_daily_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get the total usage for today.&quot;&quot;&quot;</span><span>
</span><span>        total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>entry</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> entry </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_log</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        total_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">sum</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>entry</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> entry </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_log</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>today</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>daily_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> total_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>total_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>daily_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>daily_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">check_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> estimated_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Check if a request would exceed the daily budget.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get current usage</span><span>
</span><span>        usage </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_daily_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Estimate cost of the new request</span><span>
</span><span>        cost_per_1k </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cost_per_1k_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>estimated_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> cost_per_1k
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if it would exceed the budget</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> usage</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>daily_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;within_budget&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> usage</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;This request would exceed your daily budget of $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">daily_budget</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;within_budget&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> usage</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Request is within budget. Estimated cost: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">estimated_cost</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.4f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">make_budgeted_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Make an API request while respecting the budget.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Estimate token usage</span><span>
</span><span>        estimated_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> count_message_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add buffer for completion</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check budget</span><span>
</span><span>        budget_check </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>check_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> estimated_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> budget_check</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;within_budget&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>budget_check</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Try with a cheaper model if available</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> model </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Trying with gpt-3.5-turbo instead...&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>make_budgeted_request</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Budget exceeded&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> budget_check</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log the actual usage</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completion_tokens
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cost_per_1k_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;API request failed&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore practical use cases and real-world applications of the OpenAI API.</p>
<h1 class="text-4xl font-bold my-6">Practical Use Cases and Applications</h1>
<h2 class="text-3xl font-semibold my-5">Content Generation and Summarization</h2>
<p class="my-4 leading-relaxed">The OpenAI API excels at generating and transforming content for various applications.</p>
<h3 class="text-2xl font-semibold my-4">Automated Content Creation</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_blog_post</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>topic</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> tone</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;professional&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> length</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a complete blog post on a given topic.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define length parameters</span><span>
</span><span>    length_params </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;short&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;approximately 500 words&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;approximately 1000 words&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;long&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;approximately 1500-2000 words&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define tone descriptions</span><span>
</span><span>    tone_descriptions </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;professional&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;formal and authoritative&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;conversational&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;friendly and approachable&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;technical&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;detailed and precise&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;humorous&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;light-hearted and entertaining&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the prompt</span><span>
</span><span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Write a </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">tone_descriptions</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">get</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">tone</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;well-written&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> blog post about </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">topic</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">. 
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    The post should be </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">length_params</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">get</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">length</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;approximately 1000 words&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> and include:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    1. An engaging introduction that hooks the reader
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    2. Well-structured body paragraphs with subheadings
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    3. Practical insights or actionable takeaways
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    4. A conclusion that summarizes key points
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Format the post in Markdown.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a professional content writer who specializes in creating engaging, well-researched blog posts.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>blog_post </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> generate_blog_post</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    topic</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;How Artificial Intelligence is Transforming Healthcare&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    tone</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;conversational&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    length</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Save the blog post to a file</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;ai_healthcare_blog.md&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    f</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>write</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>blog_post</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Document Summarization</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">summarize_document</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>document</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> summary_type</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;executive&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Summarize a document with different summary types.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define summary types</span><span>
</span><span>    summary_types </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;executive&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a concise executive summary highlighting the most important points and conclusions.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;bullet&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a bullet-point summary of the key points.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;detailed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a detailed summary that captures all main points and supporting details.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;eli5&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Summarize this document as if explaining to a 10-year-old.&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the prompt</span><span>
</span><span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">summary_types</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">get</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">summary_type</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> summary_types</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&quot;executive&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Document:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">document</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Content Transformation</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">transform_content</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> transformation_type</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Transform content from one format or style to another.&quot;&quot;&quot;</span><span>
</span><span>    transformations </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;academic_to_blog&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Transform this academic text into an engaging blog post while preserving the key information.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;technical_to_simple&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Rewrite this technical content in simple, easy-to-understand language.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;bullet_to_narrative&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Convert these bullet points into a flowing narrative text.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;long_to_short&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Condense this content into a much shorter version while preserving the key points.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;formal_to_casual&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Rewrite this formal content in a more casual, conversational tone.&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">transformations</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">get</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">transformation_type</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&quot;Transform this content appropriately.&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Content:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">content</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Conversational AI and Chatbots</h2>
<p class="my-4 leading-relaxed">The OpenAI API is particularly well-suited for building conversational applications.</p>
<h3 class="text-2xl font-semibold my-4">Building a Customer Support Chatbot</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">CustomerSupportChatbot</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> product_knowledge_base</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the customer support chatbot.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>product_knowledge_base </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> product_knowledge_base
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">            You are a helpful customer support assistant for our technology company.
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">            Be friendly, concise, and solution-oriented.
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">            If you don&#x27;t know the answer to a question, don&#x27;t make up information - instead, offer to escalate to a human agent.
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">            &quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_product_info</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> product_query</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Retrieve product information from the knowledge base.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>product_knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Simple keyword matching (in a real system, use vector search)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> product </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>product_knowledge_base</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> product_query</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> product</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">any</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>keyword </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> product_query</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> keyword </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> product</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;keywords&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> product
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">handle_message</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> user_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a user message and generate a response.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the user message to the conversation history</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if this is a product query</span><span>
</span><span>        product_info </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_product_info</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>user_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> product_info</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add product information to the context</span><span>
</span><span>            product_context </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">            Relevant product information:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">            Name: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">product_info</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;name&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">            Description: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">product_info</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;description&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">            Price: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">product_info</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;price&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">            Features: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;, &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">join</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">product_info</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;features&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">            &quot;&quot;&quot;</span><span>
</span>            
<span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> product_context</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Prepare the messages for the API call</span><span>
</span><span>        messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Using a cost-effective model for customer support</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract the assistant&#x27;s response</span><span>
</span><span>        assistant_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the response to the conversation history</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> assistant_response</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Manage conversation history length</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Keep only the most recent messages</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> assistant_response
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example product knowledge base</span><span>
</span><span>product_kb </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;TechPro Laptop X1&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;A high-performance laptop for professionals&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$1,299&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;features&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;14-inch 4K display&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;16GB RAM&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;512GB SSD&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Intel Core i7&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;12-hour battery life&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;keywords&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;laptop&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;computer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;techpro&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;x1&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;name&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;SmartHome Hub&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Central control for all your smart home devices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;price&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;$199&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;features&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Voice control&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Compatible with 100+ devices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Energy monitoring&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Automated routines&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;keywords&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;smart home&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;hub&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;automation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;iot&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Initialize the chatbot</span><span>
</span><span>chatbot </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> CustomerSupportChatbot</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>product_kb</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example conversation</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Customer Support Bot: Hello! How can I help you today?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">while</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    user_input </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">input</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You: &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>lower</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;exit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;quit&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;bye&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Customer Support Bot: Thank you for contacting us. Have a great day!&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">break</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> chatbot</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>handle_message</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>user_input</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Customer Support Bot: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">response</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Multi-turn Conversation Management</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">ConversationManager</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> persona</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the conversation manager with a specific persona.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>personas </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful, friendly assistant.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tutor&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a patient, knowledgeable tutor who helps explain concepts clearly.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;therapist&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are an empathetic listener who helps people process their thoughts and feelings.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;coach&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a motivational coach who helps people set and achieve goals.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>personas</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>persona</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>personas</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">add_context</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> context</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Add additional context to the conversation.&quot;&quot;&quot;</span><span>
</span><span>        context_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> context
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>context_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">process_message</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> user_message</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a user message and generate a response.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the user message to the conversation history</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Prepare the messages for the API call</span><span>
</span><span>        messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract the assistant&#x27;s response</span><span>
</span><span>        assistant_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the response to the conversation history</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> assistant_response</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> assistant_response
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">summarize_conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a summary of the conversation so far.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The conversation has just started.&quot;</span><span>
</span>        
<span>        summary_request </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Summarize the key points of this conversation concisely.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>summary_request
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">save_conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> filename</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;conversation.json&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Save the conversation history to a file.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>filename</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dump</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system_message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;conversation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> indent</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Conversation saved to </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">filename</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">load_conversation</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> filename</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;conversation.json&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Load a conversation history from a file.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>filename</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>load</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system_message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;conversation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Conversation loaded from </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">filename</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error loading conversation: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">e</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Data Analysis and Processing</h2>
<p class="my-4 leading-relaxed">The OpenAI API can be used for various data analysis and processing tasks.</p>
<h3 class="text-2xl font-semibold my-4">Text Classification and Categorization</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">classify_text</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Classify text into one of the provided categories.&quot;&quot;&quot;</span><span>
</span><span>    categories_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;, &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Classify the following text into exactly one of these categories: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">categories_str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Text: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Category:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.3</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Lower temperature for more deterministic results</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>strip</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">batch_classify_texts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>texts</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Classify multiple texts in batch.&quot;&quot;&quot;</span><span>
</span><span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> text </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> texts</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        category </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> classify_text</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;category&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> category
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>customer_feedback </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The product was amazing and exceeded my expectations!&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I&#x27;ve been waiting for a refund for two weeks now.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;How do I reset my password?&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;The checkout process was confusing and I couldn&#x27;t complete my order.&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>
<span>categories </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Positive Feedback&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Complaint&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Question&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Bug Report&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>
<span>classification_results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> batch_classify_texts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>customer_feedback</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> categories</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> result </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> classification_results</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Text: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;text&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Category: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">result</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;category&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Named Entity Recognition</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">extract_entities</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> entity_types</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Extract named entities from text.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> entity_types </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        entity_types </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Person&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Organization&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Location&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Product&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    entity_types_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;, &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>entity_types</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Extract all </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">entity_types_str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> entities from the following text.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Format the output as a JSON object with entity types as keys and lists of extracted entities as values.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Text: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract the JSON from the response</span><span>
</span><span>    result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Find JSON in the response</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> re
</span><span>    json_match </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">r&#x27;```json\n(.*?)\n```&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DOTALL</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>group</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>JSONDecodeError</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If JSON parsing fails, return the raw text</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Failed to parse JSON&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;raw_result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Sentiment Analysis</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_sentiment</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> detailed</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Analyze the sentiment of a text.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> detailed</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Perform a detailed sentiment analysis of the following text.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Include:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        1. Overall sentiment (positive, negative, or neutral)
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        2. Sentiment score (-1 to 1, where -1 is very negative and 1 is very positive)
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        3. Key emotional tones detected
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        4. Specific positive and negative aspects mentioned
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Format the output as JSON.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Text: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        &quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Analyze the sentiment of the following text as positive, negative, or neutral.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Include a score from -1 to 1, where -1 is very negative and 1 is very positive.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Text: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Format the output as JSON with &quot;sentiment&quot; and &quot;score&quot; fields.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Find JSON in the response</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> re
</span><span>    json_match </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">r&#x27;```json\n(.*?)\n```&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DOTALL</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>group</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>JSONDecodeError</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If JSON parsing fails, return the raw text</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Failed to parse JSON&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;raw_result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">batch_sentiment_analysis</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>texts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Analyze sentiment for multiple texts in batch.&quot;&quot;&quot;</span><span>
</span><span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> text </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> texts</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        sentiment </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> analyze_sentiment</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sentiment&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> sentiment
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Educational Applications</h2>
<p class="my-4 leading-relaxed">The OpenAI API can be used to create powerful educational tools and resources.</p>
<h3 class="text-2xl font-semibold my-4">Automated Tutoring System</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">TutoringSystem</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> subject</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;general&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the tutoring system for a specific subject.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define subject-specific system messages</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>subjects </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;math&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a patient and helpful math tutor. Explain concepts step by step, provide examples, and guide students to the answer rather than giving it directly.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;science&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a knowledgeable science tutor. Explain scientific concepts clearly, relate them to real-world examples, and correct misconceptions gently.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;programming&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a programming tutor. Explain coding concepts clearly, provide code examples, and help debug issues by guiding students through the troubleshooting process.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;history&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a history tutor. Provide accurate historical information, explain cause and effect relationships, and help students understand different perspectives on historical events.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;general&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful tutor. Explain concepts clearly, provide examples, and guide students to deeper understanding through thoughtful questions.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>subjects</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>subject</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>subjects</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;general&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">ask_question</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Ask a question to the tutoring system.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the question to the conversation history</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Prepare the messages for the API call</span><span>
</span><span>        messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Make the API call</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract the tutor&#x27;s response</span><span>
</span><span>        tutor_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add the response to the conversation history</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conversation_history</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;assistant&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> tutor_response</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> tutor_response
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_practice_problems</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> topic</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> difficulty</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> number</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate practice problems on a specific topic.&quot;&quot;&quot;</span><span>
</span><span>        difficulties </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;easy&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic, introductory level&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;intermediate level with some complexity&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;hard&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;challenging, requiring deep understanding&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        difficulty_desc </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> difficulties</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>difficulty</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> difficulties</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Generate </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">number</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">difficulty_desc</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> practice problems about </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">topic</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        For each problem:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        1. Provide a clear problem statement
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        2. Include the correct answer
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        3. Provide a step-by-step solution
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Format each problem with clear separation between the problem, answer, and solution.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        &quot;&quot;&quot;</span><span>
</span>        
<span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">explain_concept</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> concept</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> detail_level</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Provide an explanation of a concept at the specified detail level.&quot;&quot;&quot;</span><span>
</span><span>        detail_levels </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;simple terms a beginner would understand&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;moderate detail appropriate for someone with some background knowledge&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;in-depth detail for someone with substantial background knowledge&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        detail_desc </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> detail_levels</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>detail_level</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> detail_levels</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Explain the concept of </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">concept</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> in </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">detail_desc</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Include:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        1. A clear definition
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        2. Key principles or components
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        3. Real-world examples or applications
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        4. Common misconceptions, if any
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        &quot;&quot;&quot;</span><span>
</span>        
<span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>system_message</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Quiz and Assessment Generation</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_quiz</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>topic</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> num_questions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> question_types</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a quiz on a specific topic.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> question_types </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        question_types </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;multiple_choice&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;true_false&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;short_answer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    question_types_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;, &quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question_types</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Create a quiz about </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">topic</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> with </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">num_questions</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> questions.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Include a mix of </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">question_types_str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> questions.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    For each question:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    1. Provide a clear question
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    2. For multiple choice, provide 4 options labeled A, B, C, D
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    3. Include the correct answer
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    4. Add a brief explanation of why the answer is correct
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Format the output as a JSON object with an array of question objects.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Find JSON in the response</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> re
</span><span>    json_match </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">r&#x27;```json\n(.*?)\n```&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DOTALL</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>group</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>JSONDecodeError</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If JSON parsing fails, return the raw text</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Failed to parse JSON&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;raw_result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">format_quiz_for_display</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>quiz_data</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Format quiz data for display.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> quiz_data</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">quiz_data</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;error&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n\n</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">quiz_data</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;raw_result&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>    
<span>    formatted_quiz </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;# Quiz\n\n&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> question </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>quiz_data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;questions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        formatted_quiz </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;## Question </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">question</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;question&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n\n&quot;</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;options&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> option_key</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> option_value </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;options&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                formatted_quiz </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">option_key</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">. </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">option_value</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n&quot;</span><span>
</span><span>            formatted_quiz </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;\n&quot;</span><span>
</span>        
<span>        formatted_quiz </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;**Correct Answer:** </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">question</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;correct_answer&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n\n&quot;</span><span>
</span><span>        formatted_quiz </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;**Explanation:** </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">question</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;explanation&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n\n&quot;</span><span>
</span><span>        formatted_quiz </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;---\n\n&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> formatted_quiz</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Creative Applications</h2>
<p class="my-4 leading-relaxed">The OpenAI API can be used for various creative applications.</p>
<h3 class="text-2xl font-semibold my-4">Story Generation</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_story</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> genre</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> length</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> style</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a creative story based on a prompt.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define length parameters</span><span>
</span><span>    length_params </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;short&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;approximately 500 words&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;approximately 1000 words&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;long&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;approximately 2000 words&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the system message</span><span>
</span><span>    system_content </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a creative storyteller who writes engaging, imaginative stories.&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> genre</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        system_content </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot; You specialize in </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">genre</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> stories.&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> style</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        system_content </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot; Your writing style is </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">style</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">.&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the user prompt</span><span>
</span><span>    user_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Write a </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">length_params</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">get</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">length</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">,</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;medium-length&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> story based on the following prompt:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">prompt</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> system_content</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> user_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>story </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> generate_story</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    prompt</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;A scientist discovers a way to communicate with plants and learns they have been watching us all along.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    genre</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;science fiction&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    length</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;short&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    style</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;suspenseful with a touch of humor&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Save the story to a file</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;plant_communication_story.md&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    f</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>write</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>story</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Art and Image Prompt Generation</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_image_prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>concept</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> num_prompts</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> style</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate detailed prompts for image generation based on a concept.&quot;&quot;&quot;</span><span>
</span><span>    styles_desc </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;in </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">style</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> style&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> style </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;in various artistic styles&quot;</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Create </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">num_prompts</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> detailed image generation prompts based on the concept: &quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">concept</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Each prompt should:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    1. Be highly descriptive and visual
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    2. Include details about composition, lighting, mood, and colors
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    3. Be </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">styles_desc</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    4. Be optimized for text-to-image AI systems
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Format each prompt separately and make each one unique and creative.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>image_prompts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> generate_image_prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    concept</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;A futuristic city where nature and technology have merged harmoniously&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    num_prompts</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    style</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cyberpunk meets solarpunk&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>image_prompts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Business Applications</h2>
<p class="my-4 leading-relaxed">The OpenAI API can be used for various business applications to improve efficiency and decision-making.</p>
<h3 class="text-2xl font-semibold my-4">Automated Email Response System</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">categorize_email</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>email_body</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Categorize an email into predefined categories.&quot;&quot;&quot;</span><span>
</span><span>    categories </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Customer Support&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Sales Inquiry&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Partnership Opportunity&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Job Application&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Feedback&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Complaint&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Other&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Categorize the following email into one of these categories: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;, &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">join</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">categories</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Email:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">email_body</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Category:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.3</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>strip</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_email_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>email_body</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> sender_name</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> company_name</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate an appropriate response to an email.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># First, categorize the email</span><span>
</span><span>    category </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> categorize_email</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>email_body</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define response templates based on category</span><span>
</span><span>    templates </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Customer Support&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful customer support representative. Address the customer&#x27;s issue professionally and provide a solution or next steps.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Sales Inquiry&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a sales representative. Be helpful and informative about our products/services without being pushy.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Partnership Opportunity&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a business development manager. Express interest in potential partnerships while requesting more specific information.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Job Application&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are an HR representative. Acknowledge receipt of the application and explain the next steps in the hiring process.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Feedback&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a customer experience manager. Thank the sender for their feedback and explain how it will be used to improve.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Complaint&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a customer relations specialist. Apologize for the inconvenience, show empathy, and offer a solution or escalation path.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Other&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;You are a helpful company representative. Respond appropriately to the email content.&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    system_content </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> templates</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>category</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> templates</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Other&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Write a professional email response to the following email from </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">sender_name</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Original Email:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">email_body</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Sign the email as &quot;Customer Relations Team, </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">company_name</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> system_content</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;category&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> category</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;response&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Meeting Summarization</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">summarize_meeting</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>transcript</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> format_type</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;detailed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Summarize a meeting transcript.&quot;&quot;&quot;</span><span>
</span><span>    formats </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;brief&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a brief summary (2-3 paragraphs) of the key points discussed in the meeting.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;detailed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Create a detailed summary of the meeting including all main topics, decisions, and action items.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;action_items&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Extract only the action items from the meeting, including who is responsible and deadlines if mentioned.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;decisions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Extract only the decisions made during the meeting.&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    format_instruction </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> formats</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>format_type</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> formats</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;detailed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">format_instruction</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Meeting Transcript:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">transcript</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">format_meeting_summary_for_email</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>summary</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> meeting_title</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> meeting_date</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Format a meeting summary for email distribution.&quot;&quot;&quot;</span><span>
</span><span>    prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Format the following meeting summary as a professional email to send to meeting participants.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Include a clear subject line, greeting, the summary content, and a professional closing.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Meeting Title: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">meeting_title</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Meeting Date: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">meeting_date</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Summary:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">summary</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Integrating with Other Technologies</h2>
<p class="my-4 leading-relaxed">The OpenAI API can be integrated with various other technologies to create powerful applications.</p>
<h3 class="text-2xl font-semibold my-4">Integration with Database Systems</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> sqlite3
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">AIDataAnalyst</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> database_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the AI data analyst with a database connection.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conn </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> sqlite3</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>connect</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>database_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>conn</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get database schema</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>execute</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;SELECT name FROM sqlite_master WHERE type=&#x27;table&#x27;;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        tables </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fetchall</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>schema </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> table </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> tables</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            table_name </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> table</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>execute</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;PRAGMA table_info(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">table_name</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">);&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            columns </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fetchall</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>schema</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>table_name</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>column</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> column </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> columns</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate an SQL query based on a natural language question.&quot;&quot;&quot;</span><span>
</span><span>        schema_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> table</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> columns </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>schema</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            schema_str </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Table: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">table</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n&quot;</span><span>
</span><span>            schema_str </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Columns: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;, &#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">join</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">columns</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">\n\n&quot;</span><span>
</span>        
<span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Based on the following database schema, write an SQL query to answer the question.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Database Schema:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">schema_str</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Question: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">question</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        SQL Query:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        &quot;&quot;&quot;</span><span>
</span>        
<span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract the SQL query from the response</span><span>
</span><span>        sql_query </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>strip</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Remove markdown code blocks if present</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> re
</span><span>        sql_match </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">r&#x27;```sql\n(.*?)\n```&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DOTALL</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> sql_match</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            sql_query </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> sql_match</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>group</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> sql_query
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">execute_query</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Execute an SQL query and return the results.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>execute</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            columns </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>description</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> description </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>description</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cursor</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fetchall</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;columns&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> columns</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;results&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> results
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_data</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Answer a question about the data by generating and executing an SQL query.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Generate the SQL query</span><span>
</span><span>        sql_query </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>generate_sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>question</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Execute the query</span><span>
</span><span>        query_results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>execute_query</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> query_results</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;question&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sql_query&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> query_results</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Format the results</span><span>
</span><span>        formatted_results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> row </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> query_results</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;results&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            formatted_row </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> column </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">enumerate</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>query_results</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;columns&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                formatted_row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>column</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>i</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            formatted_results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>formatted_row</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Generate analysis of the results</span><span>
</span><span>        analysis_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Analyze the following data to answer the question: &quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">question</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        SQL Query:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">sql_query</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Query Results:
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">formatted_results</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        Provide a clear, concise analysis of what the data shows in relation to the question.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">        &quot;&quot;&quot;</span><span>
</span>        
<span>        analysis_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> analysis_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;question&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> question</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;sql_query&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> sql_query</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;results&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> formatted_results</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;analysis&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> analysis_response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Integration with Web Applications</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> flask </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> Flask</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> render_template
</span>
<span>app </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> Flask</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>__name__</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">@app</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">.</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">route</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;/&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">index</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> render_template</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;index.html&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">@app</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">.</span><span class="token decorator annotation" style="color:hsl(220, 14%, 71%)">route</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;/api/analyze&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> methods</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;POST&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">analyze_text</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> request</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>json
</span><span>    text </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;text&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    analysis_type </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> data</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;analysis_type&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;sentiment&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;No text provided&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">400</span><span>
</span>    
<span>    client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> analysis_type </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;sentiment&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Perform sentiment analysis on the following text. Return a JSON object with &#x27;sentiment&#x27; (positive, negative, or neutral) and &#x27;score&#x27; (-1 to 1) fields.\n\nText: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> analysis_type </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;summary&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Summarize the following text in a concise paragraph.\n\nText: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> analysis_type </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;keywords&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Extract the top 5 keywords or key phrases from the following text. Return them as a JSON array.\n\nText: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Invalid analysis type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">400</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For sentiment and keywords, try to parse JSON</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> analysis_type </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;sentiment&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;keywords&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> re
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Try to extract JSON if it&#x27;s in a code block</span><span>
</span><span>                json_match </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">r&#x27;```json\n(.*?)\n```&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DOTALL</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json_match</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>group</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Parse the JSON</span><span>
</span><span>                result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>loads</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>JSONDecodeError</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If JSON parsing fails, return the raw text</span><span>
</span><span>                result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> result</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> jsonify</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> __name__ </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;__main__&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    app</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>run</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>debug</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore pricing and cost management strategies for the OpenAI API.</p>
<h1 class="text-4xl font-bold my-6">Pricing and Cost Management</h1>
<h2 class="text-3xl font-semibold my-5">Understanding OpenAI API Pricing</h2>
<p class="my-4 leading-relaxed">The OpenAI API uses a pay-as-you-go pricing model based on token usage. Understanding this pricing structure is essential for managing costs effectively.</p>
<h3 class="text-2xl font-semibold my-4">Token-Based Pricing Model</h3>
<p class="my-4 leading-relaxed">OpenAI&#x27;s pricing is based on tokens, which are the basic units of text that the models process:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Input Tokens</strong>: Text sent to the model (your prompts)</li>
<li class="pl-2"><strong>Output Tokens</strong>: Text generated by the model (the responses)</li>
<li class="pl-2"><strong>Total Tokens</strong>: The sum of input and output tokens</li>
</ol>
<p class="my-4 leading-relaxed">Pricing varies by model, with more capable models costing more per token:</p>
<div class="overflow-x-auto my-4"><table class="min-w-full divide-y divide-gray-200 dark:divide-gray-700"><thead class="bg-gray-100 dark:bg-gray-800"><tr><th class="px-4 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-400 uppercase tracking-wider">Model</th><th class="px-4 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-400 uppercase tracking-wider">Input Price (per 1M tokens)</th><th class="px-4 py-3 text-left text-xs font-medium text-gray-500 dark:text-gray-400 uppercase tracking-wider">Output Price (per 1M tokens)</th></tr></thead><tbody class="divide-y divide-gray-200 dark:divide-gray-700"><tr><td class="px-4 py-3 whitespace-nowrap">GPT-4o</td><td class="px-4 py-3 whitespace-nowrap">$10</td><td class="px-4 py-3 whitespace-nowrap">$30</td></tr><tr><td class="px-4 py-3 whitespace-nowrap">GPT-4</td><td class="px-4 py-3 whitespace-nowrap">$30</td><td class="px-4 py-3 whitespace-nowrap">$60</td></tr><tr><td class="px-4 py-3 whitespace-nowrap">GPT-3.5 Turbo</td><td class="px-4 py-3 whitespace-nowrap">$1</td><td class="px-4 py-3 whitespace-nowrap">$2</td></tr><tr><td class="px-4 py-3 whitespace-nowrap">Text Embedding Models</td><td class="px-4 py-3 whitespace-nowrap">$0.10 - $1.00</td><td class="px-4 py-3 whitespace-nowrap">N/A</td></tr></tbody></table></div>
<h3 class="text-2xl font-semibold my-4">Calculating Costs</h3>
<p class="my-4 leading-relaxed">To estimate costs for your application, you need to:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">Estimate the number of tokens in your inputs and outputs</li>
<li class="pl-2">Multiply by the per-token cost for your chosen model</li>
<li class="pl-2">Factor in your expected usage volume</li>
</ol>
<p class="my-4 leading-relaxed">Here&#x27;s a simple Python function to estimate costs:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">estimate_api_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    input_tokens_per_request</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    output_tokens_per_request</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    requests_per_day</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Estimate monthly OpenAI API costs based on usage patterns.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Model pricing (per 1M tokens as of 2025)</span><span>
</span><span>    pricing </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">10.0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">30.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">30.0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">60.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-small&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-large&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> pricing</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> ValueError</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Unknown model: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate daily token usage</span><span>
</span><span>    daily_input_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> input_tokens_per_request </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> requests_per_day
</span><span>    daily_output_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> output_tokens_per_request </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> requests_per_day
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate monthly token usage</span><span>
</span><span>    monthly_input_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> daily_input_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> days
</span><span>    monthly_output_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> daily_output_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> days
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate costs</span><span>
</span><span>    input_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>monthly_input_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1_000_000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> pricing</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    output_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>monthly_output_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1_000_000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> pricing</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    total_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> input_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> output_cost
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;monthly_input_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> monthly_input_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;monthly_output_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> monthly_output_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;monthly_total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> monthly_input_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> monthly_output_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> input_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> output_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_cost
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>cost_estimate </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> estimate_api_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    input_tokens_per_request</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">200</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    output_tokens_per_request</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">800</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    requests_per_day</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Estimated monthly cost: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">cost_estimate</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;total_cost&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Input cost: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">cost_estimate</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;input_cost&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Output cost: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">cost_estimate</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;output_cost&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Total tokens: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">cost_estimate</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">[</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;monthly_total_tokens&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">]</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">,</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Cost Optimization Strategies</h2>
<p class="my-4 leading-relaxed">Implementing cost optimization strategies can help you manage your OpenAI API expenses effectively.</p>
<h3 class="text-2xl font-semibold my-4">Model Selection Optimization</h3>
<p class="my-4 leading-relaxed">Choosing the right model for each task can significantly impact costs:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">select_optimal_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>task_type</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> complexity</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> budget_sensitivity</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Select the optimal model based on task requirements and budget constraints.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define task types and their minimum required capabilities</span><span>
</span><span>    task_requirements </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;simple_generation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;complex_reasoning&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;creative_writing&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;intermediate&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;code_generation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;summarization&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;classification&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;embeddings&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;embeddings&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define model capabilities</span><span>
</span><span>    model_capabilities </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;very_high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;intermediate&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-large&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;embeddings&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-small&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;embeddings&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;very_low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get the minimum required capability for the task</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> task_type </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> task_requirements</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">raise</span><span> ValueError</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Unknown task type: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">task_type</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    min_capability </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> task_requirements</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>task_type</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;min_capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Filter models by minimum capability</span><span>
</span><span>    suitable_models </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> attributes </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> model_capabilities</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> min_capability </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;embeddings&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> attributes</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;embeddings&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> min_capability </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> attributes</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> min_capability </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;intermediate&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> attributes</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;intermediate&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> min_capability </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> attributes</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;intermediate&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Adjust based on complexity</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> complexity </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        suitable_models </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> suitable_models </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> complexity </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        suitable_models </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Adjust based on budget sensitivity</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> budget_sensitivity </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Sort by cost (ascending)</span><span>
</span><span>        cost_ranking </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;very_low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;very_high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sort</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(286, 60%, 67%)">lambda</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> cost_ranking</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model_capabilities</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Return the cheapest suitable model</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For low budget sensitivity, prefer capability over cost</span><span>
</span><span>        capability_ranking </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;basic&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;intermediate&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;advanced&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">3</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;embeddings&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sort</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(286, 60%, 67%)">lambda</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span>capability_ranking</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model_capabilities</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;capability&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> suitable_models</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Return the most capable suitable model</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span>recommended_model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> select_optimal_model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    task_type</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;summarization&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    complexity</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    budget_sensitivity</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Recommended model: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">recommended_model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Prompt Engineering for Cost Efficiency</h3>
<p class="my-4 leading-relaxed">Optimizing your prompts can reduce token usage and costs:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">optimize_prompt_for_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>original_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Optimize a prompt to reduce token usage while maintaining effectiveness.&quot;&quot;&quot;</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate original token count</span><span>
</span><span>    original_token_count </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> count_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>original_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a system message that instructs the model to optimize the prompt</span><span>
</span><span>    system_message </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    You are a prompt optimization assistant. Your task is to rewrite prompts to be more token-efficient while maintaining their effectiveness.
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    Guidelines for optimization:
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    1. Remove unnecessary words and phrases
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    2. Use concise language
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    3. Maintain all key instructions and context
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    4. Preserve the original intent and requirements
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    5. Ensure the optimized prompt will produce the same quality of response
</span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the optimization request</span><span>
</span><span>    optimization_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;&quot;
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Original prompt (</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">original_token_count</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> tokens):
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">original_prompt</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    Please optimize this prompt to use fewer tokens while maintaining its effectiveness.
</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">    &quot;&quot;&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get the optimized prompt</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Using a cheaper model for optimization</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> system_message</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> optimization_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    optimized_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Clean up the response to extract just the optimized prompt</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> re
</span><span>    clean_prompt_match </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>search</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">r&#x27;Optimized prompt:(.*?)(?:\n\n|$)&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> optimized_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> re</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DOTALL</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> clean_prompt_match</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        optimized_prompt </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> clean_prompt_match</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>group</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>strip</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate new token count</span><span>
</span><span>    optimized_token_count </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> count_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>optimized_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;original_prompt&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> original_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;optimized_prompt&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> optimized_prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;original_token_count&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> original_token_count</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;optimized_token_count&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> optimized_token_count</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;token_reduction&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> original_token_count </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> optimized_token_count</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;reduction_percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>original_token_count </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> optimized_token_count</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> original_token_count</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> original_token_count </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Caching Strategies</h3>
<p class="my-4 leading-relaxed">Implementing caching can significantly reduce API calls for repeated or similar requests:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> hashlib
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> time
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">SimpleFileCache</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cache_dir</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;./cache&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> expire_time</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">86400</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize a simple file-based cache.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cache_dir </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cache_dir
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>expire_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> expire_time  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Cache expiration in seconds (default: 24 hours)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create cache directory if it doesn&#x27;t exist</span><span>
</span><span>        os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>makedirs</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> exist_ok</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">_generate_cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a unique cache key based on request parameters.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a dictionary of the parameters that affect the response</span><span>
</span><span>        cache_dict </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;messages&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;temperature&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> temperature
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Convert to a stable string representation and hash it</span><span>
</span><span>        cache_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dumps</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_dict</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> sort_keys</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> hashlib</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>md5</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_str</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>encode</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>hexdigest</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">_get_cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get the file path for a cache key.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cache_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">cache_key</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">.json&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get a cached response if available and not expired.&quot;&quot;&quot;</span><span>
</span><span>        cache_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_generate_cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        cache_path </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_get_cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>exists</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if cache is expired</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>time</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>getmtime</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>expire_time</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Cache is expired, remove it</span><span>
</span><span>                os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>remove</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Cache is valid, return it</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>load</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">cache_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Cache a response.&quot;&quot;&quot;</span><span>
</span><span>        cache_key </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_generate_cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        cache_path </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_get_cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_key</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Convert response to a serializable format</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">hasattr</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_dump&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            response_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model_dump</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For older versions of the API</span><span>
</span><span>            response_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;choices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>total_tokens
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Save to cache file</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_path</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dump</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>response_data</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_completion_with_cache</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cache</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get a completion with caching to reduce API calls.&quot;&quot;&quot;</span><span>
</span><span>    messages </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> prompt</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check cache first</span><span>
</span><span>    cached_response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cache</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Using cached response&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> cached_response</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;choices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If not in cache, make API call</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Making API call&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>temperature
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Cache the response</span><span>
</span><span>    cache</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cache_response</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Batch Processing</h3>
<p class="my-4 leading-relaxed">Processing requests in batches can optimize token usage and reduce costs:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">batch_process_texts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>texts</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> processor_function</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batch_size</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">10</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> delay_between_batches</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Process a large number of texts in batches to manage API usage.&quot;&quot;&quot;</span><span>
</span><span>    results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process texts in batches</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> i </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>texts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batch_size</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        batch </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> texts</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>i</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>i</span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span>batch_size</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        batch_results </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Processing batch </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">i</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">//</span><span class="token string-interpolation interpolation">batch_size </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">/</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">len</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">texts</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">+</span><span class="token string-interpolation interpolation"> batch_size </span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">-</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">1</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(207, 82%, 66%)">//</span><span class="token string-interpolation interpolation">batch_size</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process each text in the batch</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> text </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> batch</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> processor_function</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            batch_results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>result</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        results</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>extend</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>batch_results</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Delay between batches to avoid rate limits</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> i </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> batch_size </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">len</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>texts</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Waiting </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">delay_between_batches</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> seconds before next batch...&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            time</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>sleep</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>delay_between_batches</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> results
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Example usage</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">summarize_text</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Summarize a text using the OpenAI API.&quot;&quot;&quot;</span><span>
</span><span>    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;system&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Summarize the following text in one paragraph.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;role&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;original_text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;summary&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Process a list of texts in batches</span><span>
</span><span>articles </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Long article text 1...&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Long article text 2...&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># ... more articles</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>
<span>summaries </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> batch_process_texts</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    texts</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>articles</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    processor_function</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>summarize_text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    batch_size</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    delay_between_batches</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Monitoring and Budgeting</h2>
<p class="my-4 leading-relaxed">Implementing robust monitoring and budgeting systems is essential for managing API costs.</p>
<h3 class="text-2xl font-semibold my-4">Usage Tracking System</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> csv
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> datetime
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIUsageTracker</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> log_file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;api_usage_log.csv&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API usage tracker.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> log_file
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create log file with headers if it doesn&#x27;t exist</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>exists</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                writer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writerow</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> 
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">log_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> endpoint</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;chat.completions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> request_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Log API usage to the CSV file.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate total tokens</span><span>
</span><span>        total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompt_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> completion_tokens
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate estimated cost</span><span>
</span><span>        cost_per_1k_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.06</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.001</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.002</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-small&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.0001</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-large&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.001</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        model_costs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cost_per_1k_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        input_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> model_costs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        output_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>completion_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> model_costs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> input_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> output_cost
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Generate request ID if not provided</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> request_id </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            request_id </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;req_</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">int</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">time</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">time</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">_</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">os</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">urandom</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">4</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">hex</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log to CSV</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;a&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            writer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writerow</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                total_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span>                endpoint
<span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_tokens
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_usage_summary</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get a summary of API usage for the specified number of days.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate the cutoff date</span><span>
</span><span>        cutoff_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>timedelta</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>days</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        cutoff_date_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cutoff_date</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Initialize summary data</span><span>
</span><span>        summary </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Read the log file</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            reader </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DictReader</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> row </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> reader</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Skip entries before the cutoff date</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> cutoff_date_str</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">continue</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract data</span><span>
</span><span>                model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">int</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">float</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                endpoint </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>                date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>split</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;T&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>  </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract date part</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update summary</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> total_tokens
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update model usage</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> total_tokens
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update daily usage</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> date </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>date</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>date</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>date</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> total_tokens
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;daily_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>date</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update endpoint usage</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> endpoint </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>endpoint</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>endpoint</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;requests&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>endpoint</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> total_tokens
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>endpoint</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> summary</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Budget Alerts and Limits</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIBudgetManager</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> monthly_budget</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">100.0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> alert_thresholds</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> usage_tracker</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API budget manager.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> monthly_budget
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>alert_thresholds </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> alert_thresholds </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0.5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.8</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.9</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.95</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>alerted_thresholds </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">set</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_tracker </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> usage_tracker </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> APIUsageTracker</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Reset alerts at the beginning of each month</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_last_reset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>replace</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>day</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> hour</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> minute</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> second</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> microsecond</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">check_budget_status</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Check the current budget status and trigger alerts if necessary.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if we need to reset alerts (new month)</span><span>
</span><span>        now </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> now</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>month </span><span class="token" style="color:hsl(207, 82%, 66%)">!=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_last_reset</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>month </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> now</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>year </span><span class="token" style="color:hsl(207, 82%, 66%)">!=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_last_reset</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>year</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>alerted_thresholds </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">set</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_last_reset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> now</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>replace</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>day</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> hour</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> minute</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> second</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> microsecond</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get current usage</span><span>
</span><span>        usage_summary </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_tracker</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_usage_summary</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        current_spend </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> usage_summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate percentage of budget used</span><span>
</span><span>        budget_used_percentage </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>current_spend </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check thresholds</span><span>
</span><span>        alerts </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> threshold </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>alert_thresholds</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            threshold_percentage </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> threshold </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> budget_used_percentage </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;=</span><span> threshold_percentage </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> threshold </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>alerted_thresholds</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                alerts</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;threshold&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> threshold</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;threshold_percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> threshold_percentage</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;current_spend&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> current_spend</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_used_percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> budget_used_percentage</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Budget alert: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">budget_used_percentage</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.1f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">% of monthly budget used ($</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">current_spend</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> of $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">monthly_budget</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">)&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>alerted_thresholds</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>add</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>threshold</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;current_spend&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> current_spend</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;monthly_budget&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_used_percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> budget_used_percentage</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> current_spend</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;alerts&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> alerts
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">enforce_budget_limit</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Check if a request would exceed the budget limit.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Get current usage</span><span>
</span><span>        usage_summary </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_tracker</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_usage_summary</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        current_spend </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> usage_summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if the request would exceed the budget</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> current_spend </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;allowed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;reason&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Budget limit reached. Current spend: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">current_spend</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">, Budget: $</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">monthly_budget</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;current_spend&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> current_spend</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> current_spend</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> estimated_cost
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;allowed&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;current_spend&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> current_spend</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_remaining&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>monthly_budget </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> current_spend</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> estimated_cost
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">log_and_check</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> endpoint</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;chat.completions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Log usage and check budget status in one operation.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log the usage</span><span>
</span><span>        log_result </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>usage_tracker</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            prompt_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            completion_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            endpoint</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>endpoint
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check budget status</span><span>
</span><span>        budget_status </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>check_budget_status</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;log_result&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> log_result</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;budget_status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> budget_status</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;alerts&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> budget_status</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;alerts&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Enterprise Considerations</h2>
<p class="my-4 leading-relaxed">For enterprise users, there are additional considerations for managing OpenAI API usage.</p>
<h3 class="text-2xl font-semibold my-4">Volume Discounts</h3>
<p class="my-4 leading-relaxed">OpenAI offers volume discounts for enterprise customers with high usage. These discounts can significantly reduce per-token costs for large-scale applications.</p>
<h3 class="text-2xl font-semibold my-4">Enterprise Agreements</h3>
<p class="my-4 leading-relaxed">Enterprise agreements with OpenAI can provide:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2"><strong>Custom Rate Limits</strong>: Higher rate limits to accommodate enterprise-scale applications</li>
<li class="pl-2"><strong>SLAs</strong>: Service Level Agreements for reliability and uptime</li>
<li class="pl-2"><strong>Dedicated Support</strong>: Priority support channels for enterprise customers</li>
<li class="pl-2"><strong>Custom Features</strong>: Access to custom features or model configurations</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Cost Allocation and Chargeback</h3>
<p class="my-4 leading-relaxed">For enterprises using the OpenAI API across multiple teams or projects, implementing cost allocation and chargeback mechanisms is important:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">EnterpriseUsageTracker</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>APIUsageTracker</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> log_file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;enterprise_api_usage_log.csv&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the enterprise API usage tracker with team/project tracking.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(95, 38%, 62%)">super</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create log file with extended headers if it doesn&#x27;t exist</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>exists</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                writer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writerow</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;prompt_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;completion_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> 
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;endpoint&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;purpose&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">log_usage</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> endpoint</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;chat.completions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> 
</span><span>                  request_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> team</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> project</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> user_id</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> purpose</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Log API usage with team/project information for cost allocation.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate costs as in the parent class</span><span>
</span><span>        total_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> prompt_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> completion_tokens
</span>        
<span>        cost_per_1k_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.06</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.001</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.002</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-small&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.0001</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text-embedding-3-large&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.001</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        model_costs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cost_per_1k_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.01</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.03</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        input_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>prompt_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> model_costs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;input&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        output_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>completion_tokens </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1000</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> model_costs</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;output&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> input_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> output_cost
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Generate request ID if not provided</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> request_id </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            request_id </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;req_</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">int</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation">time</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">time</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">_</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">os</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">urandom</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(29, 54%, 61%)">4</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">hex</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Log to CSV with extended information</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;a&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            writer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            writer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>writerow</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>                datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                prompt_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                completion_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                total_tokens</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                endpoint</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                team </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                project </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                user_id </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                purpose </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;request_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> request_id</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> estimated_cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_tokens&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> total_tokens
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_team_usage_summary</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get a summary of API usage by team for the specified number of days.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate the cutoff date</span><span>
</span><span>        cutoff_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>timedelta</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>days</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        cutoff_date_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cutoff_date</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Initialize summary data</span><span>
</span><span>        summary </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Read the log file</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            reader </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DictReader</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> row </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> reader</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Skip entries before the cutoff date</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> cutoff_date_str</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">continue</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract data</span><span>
</span><span>                estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">float</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                team </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                project </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                user_id </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update summary</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update team usage</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> team </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>team</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>team</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update project usage</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> project </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>project</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>project</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update user usage</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> user_id </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>user_id</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                summary</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_usage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>user_id</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> summary
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">generate_cost_allocation_report</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> month</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> year</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Generate a cost allocation report for a specific month.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Default to current month if not specified</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> month </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> year </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            now </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            month </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> month </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> now</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>month
</span><span>            year </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> year </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> now</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>year
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate start and end dates for the month</span><span>
</span><span>        start_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>year</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> month</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> month </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">12</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            end_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>year </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            end_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>year</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> month </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        start_date_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> start_date</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        end_date_str </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> end_date</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Initialize report data</span><span>
</span><span>        report </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;period&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">year</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">-</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">month</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">:</span><span class="token string-interpolation interpolation format-spec">02d</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Read the log file</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>log_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> newline</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            reader </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> csv</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>DictReader</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> row </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> reader</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Only include entries for the specified month</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> start_date_str </span><span class="token" style="color:hsl(286, 60%, 67%)">or</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;timestamp&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;=</span><span> end_date_str</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">continue</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Extract data</span><span>
</span><span>                estimated_cost </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">float</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>row</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;estimated_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                team </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                project </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                user_id </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> row</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update report</span><span>
</span><span>                report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update team allocation</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> team </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>team</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>team</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update project allocation</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> project </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>project</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>project</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>                
<span>                </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update user allocation</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> user_id </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>user_id</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span>
</span><span>                report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>user_id</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+=</span><span> estimated_cost
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate percentages</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> team</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cost </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;team_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>team</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cost </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> project</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cost </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;project_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>project</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cost </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> user</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cost </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>items</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;user_allocation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>user</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> cost</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;percentage&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cost </span><span class="token" style="color:hsl(207, 82%, 66%)">/</span><span> report</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;total_cost&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">*</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> report</span></code></pre></div></pre>
<p class="my-4 leading-relaxed">In the next section, we&#x27;ll explore future trends and developments in the OpenAI API ecosystem.</p>
<h1 class="text-4xl font-bold my-6">Future Trends and Developments</h1>
<h2 class="text-3xl font-semibold my-5">Emerging Capabilities and Features</h2>
<p class="my-4 leading-relaxed">The OpenAI API ecosystem continues to evolve rapidly, with new capabilities and features being developed to enhance its utility and accessibility.</p>
<h3 class="text-2xl font-semibold my-4">Multimodal Advancements</h3>
<p class="my-4 leading-relaxed">Multimodal AI, which can process and generate multiple types of media, represents one of the most significant trends in AI development:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Enhanced Image Understanding</strong>: Future models will likely have improved capabilities for understanding complex visual scenes, diagrams, and charts.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Video Processing</strong>: The ability to analyze and understand video content is a natural extension of current image capabilities.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Audio Integration</strong>: Voice input and output capabilities may be integrated more deeply into the API, enabling more natural conversational interfaces.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Cross-modal Reasoning</strong>: Future models will excel at reasoning across different modalities, such as answering questions about images or generating images based on text descriptions.</p>
</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Tool Use and Function Calling</h3>
<p class="my-4 leading-relaxed">The function calling capability is likely to expand in several ways:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>More Complex Tool Interactions</strong>: Models may gain the ability to use tools in more sophisticated ways, including chaining multiple tools together.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Autonomous Agents</strong>: Future developments may enable the creation of more autonomous AI agents that can plan and execute complex tasks with minimal human intervention.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Specialized Tool Libraries</strong>: We may see the emergence of specialized tool libraries for different domains, such as data analysis, creative writing, or scientific research.</p>
</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Fine-tuning and Customization</h3>
<p class="my-4 leading-relaxed">Customization capabilities are expected to become more powerful and accessible:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Simplified Fine-tuning</strong>: The process of fine-tuning models may become more streamlined and require less technical expertise.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Domain-Specific Optimization</strong>: Models optimized for specific domains or industries may become more common.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Personalization</strong>: Models may gain the ability to adapt to individual users&#x27; preferences and communication styles over time.</p>
</li>
</ol>
<h2 class="text-3xl font-semibold my-5">Preparing for Future API Changes</h2>
<p class="my-4 leading-relaxed">As the OpenAI API continues to evolve, developers should prepare for future changes to ensure their applications remain compatible and take advantage of new capabilities.</p>
<h3 class="text-2xl font-semibold my-4">Versioning and Compatibility</h3>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIVersionManager</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API version manager.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> OpenAI</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>            api_key</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>environ</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;OPENAI_API_KEY&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define known model versions and their end-of-life dates</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model_eol_dates </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo-0301&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">2024</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">6</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">13</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4-0314&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">2024</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">7</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add more models and their EOL dates as announced</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">check_model_status</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Check if a model is deprecated or approaching EOL.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check if the model has a known EOL date</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model_eol_dates</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            eol_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>model_eol_dates</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>            today </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Calculate days until EOL</span><span>
</span><span>            days_until_eol </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>eol_date </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> today</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>days
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> days_until_eol </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;deprecated&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> has been deprecated since </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">eol_date</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">strftime</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;%Y-%m-%d&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;recommendation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Upgrade to a newer model version immediately.&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> days_until_eol </span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;warning&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> will be deprecated in </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">days_until_eol</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> days&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;recommendation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Plan to upgrade to a newer model version soon.&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">else</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;active&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> is active but has a scheduled EOL date of </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">eol_date</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">.</span><span class="token string-interpolation interpolation">strftime</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation interpolation" style="color:hsl(95, 38%, 62%)">&#x27;%Y-%m-%d&#x27;</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">)</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;recommendation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Consider planning for an upgrade before the EOL date.&quot;</span><span>
</span><span>                </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For models without known EOL dates, check if they&#x27;re latest pointers</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;active_pointer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> is a pointer to the latest version&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;recommendation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;This model will automatically use the latest version, but behavior may change over time.&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For specific dated versions without known EOL</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;-&quot;</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">any</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>char</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isdigit</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> char </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;specific_version&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> is a specific version&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;recommendation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Monitor OpenAI announcements for deprecation notices.&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For unknown models</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;message&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)"> status is unknown&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;recommendation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;Verify this is a valid model identifier.&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_recommended_upgrade_path</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> current_model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get the recommended upgrade path for a model.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Define upgrade paths for known models</span><span>
</span><span>        upgrade_paths </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo-0301&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4-0314&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Add more upgrade paths as needed</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> current_model </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> upgrade_paths</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> upgrade_paths</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>current_model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For models without specific upgrade paths, recommend the latest in the same family</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> current_model</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>startswith</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">elif</span><span> current_model</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>startswith</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Default recommendation</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">create_version_resilient_client</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> preferred_model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> fallback_models</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Create a client that handles model versioning gracefully.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> preferred_model </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            preferred_model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4o&quot;</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> fallback_models </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            fallback_models </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-4&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;gpt-3.5-turbo&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Check the status of the preferred model</span><span>
</span><span>        model_status </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>check_model_status</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>preferred_model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> model_status</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;status&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">==</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;deprecated&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If deprecated, use the recommended upgrade</span><span>
</span><span>            preferred_model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>get_recommended_upgrade_path</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>preferred_model</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a wrapper function for chat completions</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">create_chat_completion</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">0.7</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            models_to_try </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>preferred_model</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">+</span><span> fallback_models
</span><span>            last_error </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> model </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> models_to_try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">try</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    response </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>client</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>chat</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>completions</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>create</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>                        model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        messages</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>messages</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        temperature</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>temperature</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        max_tokens</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>max_tokens
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>                    
<span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;success&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;model_used&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;response&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                        </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;content&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> response</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>choices</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>message</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>content
</span><span>                    </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>                </span><span class="token" style="color:hsl(286, 60%, 67%)">except</span><span> Exception </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> e</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                    last_error </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">str</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>e</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;Error with model </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">: </span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">{</span><span class="token string-interpolation interpolation">last_error</span><span class="token string-interpolation interpolation" style="color:hsl(220, 14%, 71%)">}</span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                    </span><span class="token" style="color:hsl(286, 60%, 67%)">continue</span><span>
</span>            
<span>            </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># If all models fail</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;success&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">False</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;error&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> last_error
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> create_chat_completion</span></code></pre></div></pre>
<h3 class="text-2xl font-semibold my-4">Staying Informed About API Changes</h3>
<p class="my-4 leading-relaxed">To stay informed about API changes and new features:</p>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Subscribe to the OpenAI Newsletter</strong>: The official newsletter provides updates on new features, model releases, and deprecation notices.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Follow the OpenAI Blog</strong>: The blog often contains detailed information about new capabilities and best practices.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Join the Developer Community</strong>: Participating in forums and community discussions can provide early insights into changes and workarounds.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Monitor the OpenAI Status Page</strong>: The status page provides information about service disruptions and planned maintenance.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Set Up Automated Monitoring</strong>: Implement automated monitoring for API changes and deprecation notices:</p>
</li>
</ol>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> requests
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> json
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> datetime
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> os
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIChangeMonitor</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> cache_file</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;api_changes_cache.json&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API change monitor.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cache_file </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cache_file
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>last_check </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>known_changes </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Load cache if it exists</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>exists</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_file</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;r&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                cache_data </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>load</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>f</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>last_check </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fromisoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>cache_data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;last_check&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>                self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>known_changes </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> cache_data</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;known_changes&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">check_for_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Check for API changes and updates.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real implementation, this would call an API or scrape the OpenAI website</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For demonstration purposes, we&#x27;ll simulate checking for changes</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Record the check time</span><span>
</span><span>        current_time </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Simulate fetching changes</span><span>
</span><span>        new_changes </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_fetch_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Filter out already known changes</span><span>
</span><span>        known_change_ids </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>change</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> change </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>known_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        truly_new_changes </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>change </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> change </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> new_changes </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> change</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">not</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> known_change_ids</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Update the cache</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>known_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>extend</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>truly_new_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>last_check </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> current_time
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Save the updated cache</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">with</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">open</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>cache_file</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;w&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            json</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>dump</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;last_check&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>last_check</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>isoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;known_changes&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>known_changes
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> f</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> indent</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> truly_new_changes
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">_fetch_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Simulate fetching changes from the OpenAI API or website.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># In a real implementation, this would make HTTP requests</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># For demonstration, we&#x27;ll return simulated changes</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;change-001&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;2025-03-15&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;title&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;GPT-4o Now Available&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;GPT-4o is now available through the API, offering improved performance and multimodal capabilities.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;impact&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;low&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;new_feature&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;id&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;change-002&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;2025-04-01&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;title&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;GPT-3.5-turbo-0301 Deprecation&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;description&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;GPT-3.5-turbo-0301 will be deprecated on June 13, 2025. Please migrate to the latest GPT-3.5-turbo model.&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;impact&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>                </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;type&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;deprecation&quot;</span><span>
</span><span>            </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">get_high_impact_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">30</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Get high-impact changes from the last N days.&quot;&quot;&quot;</span><span>
</span><span>        cutoff_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>now</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>timedelta</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>days</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>days</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        high_impact_changes </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> change </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>known_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            change_date </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>datetime</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>fromisoformat</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>change</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;date&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>            </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> change_date </span><span class="token" style="color:hsl(207, 82%, 66%)">&gt;=</span><span> cutoff_date </span><span class="token" style="color:hsl(286, 60%, 67%)">and</span><span> change</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;impact&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;medium&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;high&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>                high_impact_changes</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>append</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>change</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> high_impact_changes</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Community Resources and Support</h2>
<p class="my-4 leading-relaxed">The OpenAI API has a vibrant community of developers and resources that can help you stay up-to-date and solve problems.</p>
<h3 class="text-2xl font-semibold my-4">Official Resources</h3>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>OpenAI Documentation</strong>: The official documentation is the primary source of information about the API.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>OpenAI Cookbook</strong>: The cookbook contains practical examples and guides for common use cases.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>OpenAI Help Center</strong>: The help center provides answers to frequently asked questions and troubleshooting guides.</p>
</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Community Resources</h3>
<ol class="list-decimal pl-6 my-4 space-y-2">
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>GitHub Repositories</strong>: Many developers share their projects and examples on GitHub.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Stack Overflow</strong>: Stack Overflow has a growing number of questions and answers related to the OpenAI API.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Reddit Communities</strong>: Subreddits like r/OpenAI and r/MachineLearning often discuss API-related topics.</p>
</li>
<li class="pl-2">
<p class="my-4 leading-relaxed"><strong>Discord Servers</strong>: Several Discord servers are dedicated to AI development and the OpenAI API.</p>
</li>
</ol>
<h3 class="text-2xl font-semibold my-4">Building Your Own Knowledge Base</h3>
<p class="my-4 leading-relaxed">Creating your own knowledge base of API information and examples can be valuable:</p>
<pre class="my-4 bg-transparent"><div class="my-4 rounded-md overflow-auto max-w-full"><pre style="background:#1e1e1e;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0;overflow:auto;border-radius:0.375rem"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">class</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">APIKnowledgeBase</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">__init__</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> base_dir</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;openai_api_knowledge&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Initialize the API knowledge base.&quot;&quot;&quot;</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>base_dir </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> base_dir
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the base directory if it doesn&#x27;t exist</span><span>
</span><span>        os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>makedirs</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>base_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> exist_ok</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create subdirectories for different types of information</span><span>
</span><span>        self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>directories </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;examples&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>base_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;examples&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;errors&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>base_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;errors&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;solutions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>base_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;solutions&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>            </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;best_practices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>base_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;best_practices&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        </span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">for</span><span> directory </span><span class="token" style="color:hsl(286, 60%, 67%)">in</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>directories</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>values</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>makedirs</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>directory</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> exist_ok</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>    
<span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">add_example</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> title</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> code</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> description</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> tags</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>        </span><span class="token triple-quoted-string" style="color:hsl(95, 38%, 62%)">&quot;&quot;&quot;Add a code example to the knowledge base.&quot;&quot;&quot;</span><span>
</span><span>        </span><span class="token" style="color:hsl(286, 60%, 67%)">if</span><span> tags </span><span class="token" style="color:hsl(286, 60%, 67%)">is</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">None</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>            tags </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create a filename from the title</span><span>
</span><span>        filename </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>_create_filename</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>title</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>        filepath </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> os</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>path</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>self</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>directories</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;examples&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> filename</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>        
<span>        </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># Create the example content</span><span>
</span><span>        content </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token string-interpolation" style="color:hsl(95, 38%, 62%)">f&quot;&quot;</span><span>&quot;</span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># {title}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic">## Description</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>description</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic">## Tags</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;, &#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>join</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tags</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic">## Code</span><span>
</span>```python
<span></span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span>code</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span></code></pre></div></pre>
<h2 class="text-3xl font-semibold my-5">Date Added</h2>
<p class="my-4 leading-relaxed">{datetime.datetime.now().strftime(&#x27;%Y-%m-%d&#x27;)}
&quot;&quot;&quot;</p>
<pre class="my-4 bg-transparent"><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">    # Save the example
    with open(filepath, &quot;w&quot;) as f:
        f.write(content)
    
    return filepath

def add_error_solution(self, error_message, solution, context=None, tags=None):
    &quot;&quot;&quot;Add an error solution to the knowledge base.&quot;&quot;&quot;
    if tags is None:
        tags = []
    
    if context is None:
        context = &quot;&quot;
    
    # Create a filename from the error message
    filename = self._create_filename(error_message[:50])
    filepath = os.path.join(self.directories[&quot;errors&quot;], filename)
    
    # Create the error solution content
    content = f&quot;&quot;&quot;# Error: {error_message}
</code></pre>
<h2 class="text-3xl font-semibold my-5">Context</h2>
<p class="my-4 leading-relaxed">{context}</p>
<h2 class="text-3xl font-semibold my-5">Solution</h2>
<p class="my-4 leading-relaxed">{solution}</p>
<h2 class="text-3xl font-semibold my-5">Tags</h2>
<p class="my-4 leading-relaxed">{&#x27;, &#x27;.join(tags)}</p>
<h2 class="text-3xl font-semibold my-5">Date Added</h2>
<p class="my-4 leading-relaxed">{datetime.datetime.now().strftime(&#x27;%Y-%m-%d&#x27;)}
&quot;&quot;&quot;</p>
<pre class="my-4 bg-transparent"><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">    # Save the error solution
    with open(filepath, &quot;w&quot;) as f:
        f.write(content)
    
    return filepath

def add_best_practice(self, title, content, category=None, tags=None):
    &quot;&quot;&quot;Add a best practice to the knowledge base.&quot;&quot;&quot;
    if tags is None:
        tags = []
    
    if category is None:
        category = &quot;General&quot;
    
    # Create a filename from the title
    filename = self._create_filename(title)
    filepath = os.path.join(self.directories[&quot;best_practices&quot;], filename)
    
    # Create the best practice content
    formatted_content = f&quot;&quot;&quot;# {title}
</code></pre>
<h2 class="text-3xl font-semibold my-5">Category</h2>
<p class="my-4 leading-relaxed">{category}</p>
<h2 class="text-3xl font-semibold my-5">Best Practice</h2>
<p class="my-4 leading-relaxed">{content}</p>
<h2 class="text-3xl font-semibold my-5">Tags</h2>
<p class="my-4 leading-relaxed">{&#x27;, &#x27;.join(tags)}</p>
<h2 class="text-3xl font-semibold my-5">Date Added</h2>
<p class="my-4 leading-relaxed">{datetime.datetime.now().strftime(&#x27;%Y-%m-%d&#x27;)}
&quot;&quot;&quot;</p>
<pre class="my-4 bg-transparent"><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">    # Save the best practice
    with open(filepath, &quot;w&quot;) as f:
        f.write(formatted_content)
    
    return filepath

def search(self, query, categories=None):
    &quot;&quot;&quot;Search the knowledge base for entries matching the query.&quot;&quot;&quot;
    if categories is None:
        categories = list(self.directories.keys())
    
    results = []
    
    for category in categories:
        if category not in self.directories:
            continue
        
        directory = self.directories[category]
        
        for filename in os.listdir(directory):
            filepath = os.path.join(directory, filename)
            
            with open(filepath, &quot;r&quot;) as f:
                content = f.read()
            
            if query.lower() in content.lower():
                # Extract the title from the first line
                title = content.split(&quot;\n&quot;)[0].strip(&quot;# &quot;)
                
                results.append({
                    &quot;category&quot;: category,
                    &quot;title&quot;: title,
                    &quot;filepath&quot;: filepath,
                    &quot;preview&quot;: content[:200] + &quot;...&quot; if len(content) &gt; 200 else content
                })
    
    return results

def _create_filename(self, title):
    &quot;&quot;&quot;Create a filename from a title.&quot;&quot;&quot;
    # Replace spaces with underscores and remove special characters
    filename = &quot;&quot;.join(c if c.isalnum() or c == &quot; &quot; else &quot;_&quot; for c in title)
    filename = filename.replace(&quot; &quot;, &quot;_&quot;).lower()
    
    # Add .md extension
    return f&quot;{filename}.md&quot;
</code></pre>
<pre class="my-4 bg-transparent"><code class="bg-gray-800 text-gray-200 rounded px-1 py-0.5">
## Conclusion and Next Steps

The OpenAI API represents a powerful tool for developers looking to integrate advanced AI capabilities into their applications. By understanding its features, best practices, and future trends, you can leverage its full potential while managing costs and ensuring reliability.

### Key Takeaways

1. **Understand the API Structure**: Familiarize yourself with the different components of the API, including the Chat Completions API, Responses API, and specialized services.

2. **Choose the Right Model**: Select the appropriate model for your use case based on capability requirements, context length needs, and budget constraints.

3. **Implement Best Practices**: Follow best practices for error handling, rate limiting, and security to build robust applications.

4. **Optimize for Cost**: Use techniques like caching, batching, and prompt optimization to manage API costs effectively.

5. **Stay Informed**: Keep up with API changes and new features to ensure your applications remain compatible and take advantage of new capabilities.

### Getting Started

If you&#x27;re new to the OpenAI API, here are some recommended next steps:

1. **Create an OpenAI Account**: Sign up at [platform.openai.com](https://platform.openai.com) to get your API key.

2. **Explore the Documentation**: Review the official documentation to understand the API&#x27;s capabilities and limitations.

3. **Start with Simple Examples**: Begin with basic examples to familiarize yourself with the API before building more complex applications.

4. **Join the Community**: Engage with the developer community to learn from others&#x27; experiences and share your own.

5. **Experiment and Iterate**: The best way to learn is by doing. Start building, experiment with different approaches, and iterate based on results.

By following these guidelines and leveraging the information in this guide, you&#x27;ll be well-equipped to build powerful, cost-effective applications with the OpenAI API.

Happy building!
</code></pre></div><div class="mt-12"><h3 class="text-2xl font-semibold mb-4 text-gray-900 dark:text-white">Tags</h3><div class="flex flex-wrap gap-2 mb-12"><span class="bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium">AI</span><span class="bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium">OpenAI</span><span class="bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium">API</span><span class="bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium">Web Development</span><span class="bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium">AI Agents</span><span class="bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium">AI Tools</span></div><div class="mt-8"><h2 class="text-2xl font-bold mb-4">Related Posts</h2><div class="grid grid-cols-1 md:grid-cols-2 gap-4"><a class="block rounded-lg shadow-md hover:shadow-lg transition-all duration-300 border border-gray-200 dark:border-gray-700 p-6" href="/blog/building-ai-agents-nextjs-langchain"><h3 class="text-lg font-semibold text-gray-900 dark:text-white">Building AI Agents with Next.js and LangChain: A Comprehensive Guide</h3><p class="text-gray-600 dark:text-gray-400 leading-relaxed">Explore the fascinating world of AI agents and learn how to build them using Next.js and LangChain. This guide covers everything from the basics to advanced techniques.</p></a></div></div></div><div class="mt-16 pt-8 border-t border-gray-200 dark:border-gray-700"><h3 class="text-2xl font-semibold mb-6 text-gray-900 dark:text-white">About the Author</h3><div class="flex items-center bg-gray-100 dark:bg-gray-800 p-6 rounded-lg"><img alt="Hung Pham" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="rounded-full mr-6" style="color:transparent" src="/_next/static/media/LowkeyDev.9bd0d6a3.png"/><div><h4 class="text-xl font-semibold mb-2 text-gray-900 dark:text-white">Hung Pham</h4><p class="text-gray-600 dark:text-gray-400 leading-relaxed">A passionate Software Developer and technologist exploring the intersections of code and creativity.</p></div></div></div></article></div><aside class="hidden lg:block"><div class="sticky top-24"></div></aside></div></div><!--$--><!--/$--></main><footer class="fixed bottom-0 left-0 w-full bg-white"><button class="fixed bottom-4 right-4 z-40 bg-gradient-to-r from-purple-600 to-blue-500 text-white rounded-full p-4 shadow-lg hover:shadow-xl transition-all duration-300 transform hover:scale-110"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bot animate-pulse" aria-hidden="true"><path d="M12 8V4H8"></path><rect width="16" height="12" x="4" y="8" rx="2"></rect><path d="M2 14h2"></path><path d="M20 14h2"></path><path d="M15 13v2"></path><path d="M9 13v2"></path></svg></button><div class="fixed bottom-16 right-4 z-50 w-full max-w-[500px] p-4 xl:right-22 hidden"><div class="flex h-[600px] flex-col border bg-background shadow-xl rounded-lg  overflow-hidden"><div class="flex items-center justify-between bg-black bg-opacity-30 p-4"><h2 class="text-white font-bold">AI Assistant</h2><button class="text-white hover:text-gray-300 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-circle-x" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><path d="m15 9-6 6"></path><path d="m9 9 6 6"></path></svg></button></div><div class="mt-3 h-full overflow-y-auto px-3"><div class="flex flex-col items-center justify-center h-full text-center"><svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bot text-purple-500 mb-4 animate-bounce" aria-hidden="true"><path d="M12 8V4H8"></path><rect width="16" height="12" x="4" y="8" rx="2"></rect><path d="M2 14h2"></path><path d="M20 14h2"></path><path d="M15 13v2"></path><path d="M9 13v2"></path></svg><p class="text-lg font-medium mb-2">Hello! How can I assist you today?</p><p class="text-sm ">Feel free to ask me anything about this website.</p></div></div><form class="m-3 flex gap-1"><button type="button" class="flex w-10 flex-none items-center justify-center hover:text-red-500 transition-colors duration-300" title="Clear chat"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-trash" aria-hidden="true"><path d="M3 6h18"></path><path d="M19 6v14c0 1-1 2-2 2H7c-1 0-2-1-2-2V6"></path><path d="M8 6V4c0-1 1-2 2-2h4c1 0 2 1 2 2v2"></path></svg></button><input placeholder="Say something..." class="flex-grow rounded-full border border-gray-300 dark:border-gray-700 bg-white dark:bg-gray-800 px-4 py-2 focus:outline-none focus:ring-2 focus:ring-purple-500" value=""/><button type="submit" class="flex w-10 flex-none items-center justify-center disabled:opacity-50 hover:text-blue-400 transition-colors duration-300" disabled="" title="Submit message"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-send-horizontal" aria-hidden="true"><path d="M3.714 3.048a.498.498 0 0 0-.683.627l2.843 7.627a2 2 0 0 1 0 1.396l-2.842 7.627a.498.498 0 0 0 .682.627l18-8.5a.5.5 0 0 0 0-.904z"></path><path d="M6 12h16"></path></svg></button></form></div></div></footer></div></div><script src="/_next/static/chunks/webpack-ca26d2052b029d27.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[63479,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"552\",\"static/chunks/552-7a1a7c42975f72da.js\",\"298\",\"static/chunks/298-4e2d45a58d8b8e81.js\",\"177\",\"static/chunks/app/layout-aa3aaf2a5ede1856.js\"],\"ThemeProvider\"]\n3:I[94559,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"552\",\"static/chunks/552-7a1a7c42975f72da.js\",\"298\",\"static/chunks/298-4e2d45a58d8b8e81.js\",\"177\",\"static/chunks/app/layout-aa3aaf2a5ede1856.js\"],\"NextUIProvider\"]\n4:I[38822,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"552\",\"static/chunks/552-7a1a7c42975f72da.js\",\"298\",\"static/chunks/298-4e2d45a58d8b8e81.js\",\"177\",\"static/chunks/app/layout-aa3aaf2a5ede1856.js\"],\"default\"]\n5:I[9766,[],\"\"]\n6:I[98924,[],\"\"]\n7:I[95249,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"552\",\"static/chunks/552-7a1a7c42975f72da.js\",\"298\",\"static/chunks/298-4e2d45a58d8b8e81.js\",\"177\",\"static/chunks/app/layout-aa3aaf2a5ede1856.js\"],\"default\"]\n9:I[24431,[],\"OutletBoundary\"]\nb:I[15278,[],\"AsyncMetadataOutlet\"]\nd:I[24431,[],\"ViewportBoundary\"]\nf:I[24431,[],\"MetadataBoundary\"]\n10:\"$Sreact.suspense\"\n12:I[57150,[],\"\"]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/aea965b6eab027a3.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"N-0l2p-6kjCD7mOd-93Pj\",\"p\":\"\",\"c\":[\"\",\"blog\",\"complete_openai_api_guide\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"id\",\"complete_openai_api_guide\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/aea965b6eab027a3.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"__className_f367f3 antialiased\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"dark\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background text-foreground\",\"children\":[[\"$\",\"$L4\",null,{}],[\"$\",\"main\",null,{\"className\":\"py-8 px-4 md:px-6 mx-auto max-w-7xl\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"fixed bottom-0 left-0 w-full bg-white\",\"children\":[\"$\",\"$L7\",null,{}]}]]}]}]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"id\",\"complete_openai_api_guide\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L8\",null,[\"$\",\"$L9\",null,{\"children\":[\"$La\",[\"$\",\"$Lb\",null,{\"promise\":\"$@c\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$Lf\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$10\",null,{\"fallback\":null,\"children\":\"$L11\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$12\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"13:I[52619,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"356\",\"static/chunks/356-47b75043c8e7fd96.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"242\",\"static/chunks/242-225df27543a9ab2e.js\",\"567\",\"static/chunks/app/blog/%5Bid%5D/page-8e144e2fb57494e5.js\"],\"\"]\n14:I[81356,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"356\",\"static/chunks/356-47b75043c8e7fd96.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"242\",\"static/chunks/242-225df27543a9ab2e.js\",\"567\",\"static/chunks/app/blog/%5Bid%5D/page-8e144e2fb57494e5.js\"],\"Image\"]\n15:I[90286,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"356\",\"static/chunks/356-47b75043c8e7fd96.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"242\",\"static/chunks/242-225df27543a9ab2e.js\",\"567\",\"static/chunks/app/blog/%5Bid%5D/page-8e144e2fb57494e5.js\"],\"default\"]\n16:I[8085,[\"335\",\"static/chunks/335-ebaa30ec5d8be766.js\",\"356\",\"static/chunks/356-47b75043c8e7fd96.js\",\"619\",\"static/chunks/619-1108b4c084a63a2d.js\",\"26\",\"static/chunks/26-c8312ff7df085f9c.js\",\"242\",\"static/chunks/242-225df27543a9ab2e.js\",\"567\",\"static/chunks/app/blog/%5Bid%5D/page-8e144e2fb57494e5.js\"],\"default\"]\n17:T3cac1,"])</script><script>self.__next_f.push([1,"\nIn the rapidly evolving landscape of artificial intelligence, few technologies have made as significant an impact as OpenAI's suite of powerful language models. At the forefront of this revolution is the OpenAI API, a versatile interface that grants developers access to some of the most sophisticated AI models ever created. Whether you're building a conversational assistant, automating content generation, or implementing advanced natural language processing capabilities, the OpenAI API offers unprecedented opportunities to integrate cutting-edge AI into your applications.\n\nThe journey of OpenAI's API offerings has been nothing short of remarkable. What began with GPT-3 has evolved into a comprehensive ecosystem of models and services, each designed to address specific use cases and requirements. From the versatile GPT-4o to specialized tools for embeddings, moderation, and fine-tuning, the OpenAI API has expanded to meet the growing demands of developers and businesses worldwide.\n\nThis comprehensive guide is crafted for developers, data scientists, product managers, and businesses looking to harness the full potential of OpenAI's technology. Whether you're taking your first steps into the world of AI or seeking to optimize your existing implementations, this resource aims to provide you with the knowledge, best practices, and practical examples needed to succeed.\n\n## Who This Guide Is For\n\nThis guide is designed to serve a diverse audience with varying levels of expertise:\n\n- **Developers** seeking to integrate AI capabilities into their applications\n- **Data scientists** looking to leverage language models for analysis and insights\n- **Product managers** exploring AI features for their product roadmaps\n- **Businesses** evaluating the potential of AI to transform their operations\n- **AI enthusiasts** wanting to deepen their understanding of large language models\n\nNo matter where you fall on this spectrum, you'll find valuable insights tailored to your needs and experience level.\n\n## What You'll Learn\n\nBy the end of this comprehensive guide, you will have gained:\n\n- A thorough understanding of the OpenAI API architecture and capabilities\n- Practical knowledge of how to authenticate, make requests, and process responses\n- Insights into choosing the right models for specific use cases\n- Hands-on experience with code examples covering various API features\n- Strategies for optimizing performance and managing costs\n- Best practices for error handling, security, and responsible AI implementation\n- Awareness of ethical considerations and limitations of AI models\n\n## The Evolution of OpenAI's API\n\nThe OpenAI API has undergone significant evolution since its initial release. What started as access to a single model has expanded into a comprehensive platform offering multiple specialized services:\n\n- **2020**: Initial release of the GPT-3 API with text completion capabilities\n- **2021**: Introduction of Codex models for code generation and understanding\n- **2022**: Launch of DALL-E for image generation and GPT-3.5 series models\n- **2023**: Release of GPT-4, function calling capabilities, and the Assistants API\n- **2024**: Introduction of GPT-4o, multimodal capabilities, and the Responses API\n\nEach iteration has brought improvements in capabilities, performance, and usability, making the API more powerful and accessible to developers worldwide.\n\n## Why OpenAI API Matters\n\nThe significance of the OpenAI API extends beyond its technical capabilities. It represents a democratization of advanced AI technology, allowing organizations of all sizes to implement solutions that were previously only available to those with extensive resources and expertise. This accessibility has sparked innovation across industries, from healthcare and education to customer service and content creation.\n\nFor developers, the API offers a way to focus on building valuable applications without needing to train and maintain complex AI models. For businesses, it provides a competitive edge through enhanced automation, personalization, and data analysis capabilities. And for society at large, it presents both opportunities and challenges as we navigate the implications of increasingly capable AI systems.\n\n## The Current Landscape\n\nAs of 2025, the OpenAI API stands at the intersection of several important trends in AI development:\n\n1. **Multimodal capabilities** that combine text, image, and potentially other forms of data\n2. **Specialized models** optimized for specific tasks and domains\n3. **Enhanced reasoning abilities** that approach human-like problem-solving in certain contexts\n4. **Improved fine-tuning** options for customizing models to specific use cases\n5. **Greater focus on responsible AI** development and deployment\n\nUnderstanding these trends is crucial for developers looking to make the most of the API's capabilities while navigating its limitations and ethical considerations.\n\n## Getting the Most from This Guide\n\nTo maximize the value of this guide, we recommend:\n\n- Following along with the code examples in your own development environment\n- Experimenting with different parameters and inputs to understand their effects\n- Referring to the official OpenAI documentation for the most up-to-date information\n- Joining community forums to share experiences and learn from other developers\n- Approaching AI implementation with both creativity and responsibility\n\nThe field of AI is evolving rapidly, and staying informed about the latest developments will help you make the most of these powerful tools.\n\nIn the following sections, we'll dive deeper into the technical aspects of the OpenAI API, starting with a comprehensive overview of its architecture and components. Whether you're building your first AI-powered application or optimizing an existing one, this guide will provide you with the knowledge and tools you need to succeed.\n\nLet's begin our journey into the world of OpenAI's API.\n# Understanding the OpenAI API\n\n## What is the OpenAI API?\n\nThe OpenAI API provides developers with access to OpenAI's state-of-the-art artificial intelligence models through a simple and consistent interface. At its core, the API serves as a bridge between your applications and OpenAI's powerful language models, allowing you to integrate advanced AI capabilities without needing to train or maintain complex models yourself.\n\nUnlike traditional APIs that might perform specific, limited functions, the OpenAI API offers a versatile set of capabilities that can be applied to virtually any task involving language understanding, generation, or reasoning. This flexibility makes it suitable for a wide range of applications, from conversational agents and content creation to data analysis and code generation.\n\n## Key Features and Capabilities\n\nThe OpenAI API offers a comprehensive set of features designed to meet diverse development needs:\n\n### Natural Language Processing\n- Text generation with human-like quality\n- Summarization of long documents\n- Question answering based on provided context\n- Language translation across numerous languages\n- Sentiment analysis and emotion detection\n- Entity recognition and extraction\n\n### Reasoning and Problem-Solving\n- Step-by-step problem decomposition\n- Logical reasoning through complex scenarios\n- Mathematical calculations and equation solving\n- Decision-making based on provided criteria\n- Structured data extraction from unstructured text\n\n### Creative Content Generation\n- Writing in various styles and formats\n- Story and narrative creation\n- Marketing copy and product descriptions\n- Email drafting and communication assistance\n- Poetry, scripts, and creative writing\n\n### Code and Technical Capabilities\n- Code generation in multiple programming languages\n- Code explanation and documentation\n- Debugging assistance\n- Converting natural language to code\n- API documentation generation\n\n### Multimodal Understanding\n- Processing and analyzing images alongside text\n- Describing visual content\n- Answering questions about images\n- Generating text based on visual inputs\n\n## API Architecture and Components\n\nThe OpenAI API is structured around several key components that work together to provide a comprehensive development platform:\n\n### Core APIs\n\n1. **Chat Completions API**: The traditional interface for interacting with OpenAI's models, structured around conversation-style interactions with role-based messages.\n\n2. **Responses API**: A newer, streamlined interface that simplifies interactions with the models and provides enhanced capabilities for certain use cases.\n\n3. **Embeddings API**: Generates vector representations of text that capture semantic meaning, useful for search, clustering, and recommendations.\n\n4. **Moderation API**: Helps identify potentially harmful or inappropriate content to ensure responsible AI use.\n\n### Specialized Services\n\n1. **Assistants API**: A higher-level interface for building AI assistants with persistent memory and specialized tools.\n\n2. **Fine-tuning API**: Allows customization of models for specific use cases by training on your own data.\n\n3. **Files API**: Manages file uploads for use with various API features.\n\n4. **Batch API**: Enables processing large volumes of requests efficiently.\n\n### Supporting Infrastructure\n\n1. **Authentication System**: Secures API access through API keys and organization IDs.\n\n2. **Rate Limiting**: Manages request volumes to ensure fair usage and system stability.\n\n3. **Monitoring and Logging**: Provides visibility into API usage and performance.\n\n4. **Versioning System**: Ensures compatibility as the API evolves.\n\n## Responses API vs. Chat Completions API\n\nOpenAI offers two primary interfaces for generating text with their models: the newer Responses API and the traditional Chat Completions API. Understanding the differences between these interfaces is crucial for choosing the right approach for your application.\n\n### Responses API\n\nThe Responses API represents OpenAI's latest approach to model interaction, designed to simplify the developer experience while offering enhanced capabilities:\n\n**Key Features:**\n- Streamlined interface with fewer required parameters\n- Built-in support for multimodal inputs (text and images)\n- Simplified handling of conversation context\n- More consistent output formatting\n- Enhanced support for structured outputs\n\n**Example Usage:**\n```python\nresponse = client.responses.create(\n    model=\"gpt-4o\",\n    instructions=\"You are a helpful assistant that provides concise explanations.\",\n    input=\"What is the difference between supervised and unsupervised learning?\"\n)\nprint(response.output_text)\n```\n\n### Chat Completions API\n\nThe Chat Completions API is the traditional interface that has been available since the introduction of ChatGPT models:\n\n**Key Features:**\n- Fine-grained control through numerous parameters\n- Explicit conversation management through message arrays\n- Support for function calling\n- Detailed token usage information\n- Compatibility with a wider range of models\n\n**Example Usage:**\n```python\ncompletion = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides concise explanations.\"},\n        {\"role\": \"user\", \"content\": \"What is the difference between supervised and unsupervised learning?\"}\n    ]\n)\nprint(completion.choices[0].message.content)\n```\n\n### When to Use Each API\n\n- **Choose the Responses API when:**\n  - You need a simpler interface with fewer parameters\n  - You're working with multimodal inputs (text + images)\n  - You want more consistent output formatting\n  - You're building new applications from scratch\n\n- **Choose the Chat Completions API when:**\n  - You need maximum control over model parameters\n  - You're implementing complex function calling\n  - You require detailed token usage statistics\n  - You're maintaining existing applications built on this API\n\nBoth APIs access the same underlying models and capabilities, so your choice should be based on your specific development needs and preferences rather than model performance considerations.\n\nIn the following sections, we'll explore how to get started with the OpenAI API, including account setup, authentication, and making your first API calls.\n# Getting Started with OpenAI API\n\n## Creating an OpenAI Account\n\nBefore you can start using the OpenAI API, you'll need to create an account and obtain API credentials. The process is straightforward:\n\n1. **Visit the OpenAI Platform**: Navigate to [platform.openai.com](https://platform.openai.com) and click on the \"Sign Up\" button.\n\n2. **Create Your Account**: You can sign up using an email address and password, or through single sign-on options like Google or Microsoft accounts.\n\n3. **Verify Your Email**: Check your inbox for a verification email from OpenAI and follow the instructions to verify your account.\n\n4. **Complete Your Profile**: Provide the required information about yourself and your intended use case for the API.\n\n5. **Set Up Billing**: To access the full capabilities of the API, you'll need to add a payment method. OpenAI offers a free tier with limited usage, but for production applications, you'll want to set up proper billing.\n\nOnce your account is created and verified, you'll have access to the OpenAI platform dashboard, where you can manage your API keys, monitor usage, and access documentation.\n\n## Obtaining and Managing API Keys\n\nAPI keys are the primary method for authenticating your requests to the OpenAI API. Here's how to obtain and manage them:\n\n1. **Generate an API Key**:\n   - Log in to your OpenAI account\n   - Navigate to the \"API Keys\" section in your account settings\n   - Click \"Create new secret key\"\n   - Give your key a descriptive name (e.g., \"Development Environment\")\n   - Copy and securely store the key immediately, as you won't be able to view it again\n\n2. **API Key Best Practices**:\n   - Treat your API keys like passwords\n   - Never hardcode keys directly in your application code\n   - Don't share keys in public repositories or client-side code\n   - Use different keys for development and production environments\n   - Regularly rotate keys, especially if you suspect they may have been compromised\n\n3. **Revoking Keys**:\n   - If a key is compromised or no longer needed, immediately revoke it from the API Keys dashboard\n   - Create a new key to replace any revoked keys\n\nRemember that your API key provides access to your OpenAI account and billing, so it's crucial to keep it secure.\n\n## Setting Up Your Development Environment\n\nTo start working with the OpenAI API, you'll need to set up your development environment. Here's a step-by-step guide for Python, the most commonly used language for OpenAI API integration:\n\n### Installing the OpenAI Python Library\n\nThe official OpenAI Python library provides a convenient interface for making API calls. Install it using pip:\n\n```bash\npip install openai\n```\n\nFor production environments, it's recommended to pin the version to avoid unexpected changes:\n\n```bash\npip install openai==1.70.0  # Replace with the latest version\n```\n\n### Environment Configuration\n\nBest practice is to store your API key in environment variables rather than in your code:\n\n1. **Create a `.env` file** in your project root (make sure to add it to `.gitignore`):\n\n```\nOPENAI_API_KEY=your-api-key-here\n```\n\n2. **Load environment variables** in your application:\n\n```python\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Access the API key\napi_key = os.environ.get(\"OPENAI_API_KEY\")\n```\n\nYou'll need to install the `python-dotenv` package:\n\n```bash\npip install python-dotenv\n```\n\n### Initializing the OpenAI Client\n\nWith your environment set up, you can now initialize the OpenAI client:\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI(\n    # This is the default and can be omitted if OPENAI_API_KEY is set in your environment\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n)\n```\n\nFor applications that need to make asynchronous requests, use the async client:\n\n```python\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync_client = AsyncOpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n)\n\nasync def main():\n    # Use the async client here\n    response = await async_client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n    )\n    print(response.choices[0].message.content)\n\n# Run the async function\nasyncio.run(main())\n```\n\n## Authentication Best Practices\n\nSecuring your OpenAI API integration is crucial for both security and cost management. Here are some best practices for authentication:\n\n### Environment-Based Configuration\n\nAlways use environment variables or secure secret management systems to store API keys:\n\n- In development: Use `.env` files with tools like `python-dotenv`\n- In production: Use your platform's secret management (AWS Secrets Manager, Google Secret Manager, Azure Key Vault, etc.)\n\n### API Key Rotation\n\nImplement a regular schedule for rotating API keys:\n\n```python\n# Example function to check if key rotation is needed\ndef should_rotate_api_key(last_rotation_date, rotation_period_days=90):\n    from datetime import datetime, timedelta\n    \n    rotation_threshold = last_rotation_date + timedelta(days=rotation_period_days)\n    return datetime.now() \u003e rotation_threshold\n```\n\n### Request Signing\n\nFor enterprise applications, consider implementing request signing for additional security:\n\n```python\nimport hmac\nimport hashlib\nimport time\n\ndef sign_request(payload, secret_key):\n    timestamp = int(time.time())\n    message = f\"{timestamp}.{payload}\"\n    signature = hmac.new(\n        secret_key.encode(),\n        message.encode(),\n        hashlib.sha256\n    ).hexdigest()\n    \n    return {\n        \"payload\": payload,\n        \"timestamp\": timestamp,\n        \"signature\": signature\n    }\n```\n\n### Proxy Services\n\nFor applications where the client needs to make API calls, consider using a proxy service to avoid exposing your API key:\n\n```python\n# Server-side code (your proxy API)\n@app.route(\"/api/openai\", methods=[\"POST\"])\ndef proxy_openai_request():\n    # Validate the user's session/authentication\n    if not is_authenticated(request):\n        return jsonify({\"error\": \"Unauthorized\"}), 401\n    \n    # Extract the request parameters\n    request_data = request.json\n    \n    # Make the OpenAI API call using your server's API key\n    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n    \n    try:\n        response = client.chat.completions.create(**request_data)\n        return jsonify(response.model_dump())\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n```\n\n## API Request Structure Basics\n\nUnderstanding the structure of API requests is fundamental to working effectively with the OpenAI API. Let's examine the basic components of a request:\n\n### Common Request Parameters\n\nRegardless of which API endpoint you're using, several parameters are commonly used:\n\n1. **`model`**: Specifies which model to use (e.g., \"gpt-4o\", \"gpt-3.5-turbo\")\n2. **Authentication**: Your API key, typically provided in the request header\n3. **Request Body**: JSON payload containing the parameters specific to the endpoint\n\n### Chat Completions Request Structure\n\n```python\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello, who are you?\"}\n    ],\n    temperature=0.7,\n    max_tokens=150,\n    top_p=1.0,\n    frequency_penalty=0.0,\n    presence_penalty=0.0\n)\n```\n\n### Responses API Request Structure\n\n```python\nresponse = client.responses.create(\n    model=\"gpt-4o\",\n    instructions=\"You are a helpful assistant.\",\n    input=\"Hello, who are you?\",\n    temperature=0.7,\n    max_tokens=150\n)\n```\n\n### Embeddings Request Structure\n\n```python\nresponse = client.embeddings.create(\n    model=\"text-embedding-3-small\",\n    input=\"The food was delicious and the service was excellent.\"\n)\n```\n\n## Making Your First API Call\n\nLet's put everything together and make your first API call. This example demonstrates a simple chat completion request:\n\n```python\nimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Initialize the OpenAI client\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n\n# Make a simple request\ndef get_ai_response(prompt):\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",  # Using a less expensive model for testing\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        return f\"An error occurred: {str(e)}\"\n\n# Test the function\nif __name__ == \"__main__\":\n    user_prompt = \"Explain what an API is in simple terms.\"\n    result = get_ai_response(user_prompt)\n    print(f\"Prompt: {user_prompt}\\n\")\n    print(f\"Response: {result}\")\n```\n\nSave this code to a file (e.g., `first_api_call.py`), ensure your `.env` file contains your API key, and run it:\n\n```bash\npython first_api_call.py\n```\n\nIf everything is set up correctly, you should receive a response explaining what an API is in simple terms.\n\n## Understanding API Responses\n\nWhen you make a request to the OpenAI API, the response contains several important components:\n\n### Chat Completions Response Structure\n\n```json\n{\n  \"id\": \"chatcmpl-123abc\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677858242,\n  \"model\": \"gpt-4o\",\n  \"choices\": [\n    {\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hello! I'm an AI assistant created by OpenAI. How can I help you today?\"\n      },\n      \"index\": 0,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 13,\n    \"completion_tokens\": 16,\n    \"total_tokens\": 29\n  }\n}\n```\n\n### Responses API Response Structure\n\n```json\n{\n  \"id\": \"resp-123abc\",\n  \"object\": \"response\",\n  \"created\": 1677858242,\n  \"model\": \"gpt-4o\",\n  \"output_text\": \"Hello! I'm an AI assistant created by OpenAI. How can I help you today?\",\n  \"usage\": {\n    \"prompt_tokens\": 13,\n    \"completion_tokens\": 16,\n    \"total_tokens\": 29\n  }\n}\n```\n\n### Key Response Fields\n\n- **`id`**: A unique identifier for the response\n- **`created`**: Timestamp of when the response was generated\n- **`model`**: The model used to generate the response\n- **`choices`** or **`output_text`**: The actual content generated by the model\n- **`finish_reason`**: Indicates why the model stopped generating (e.g., \"stop\", \"length\", \"content_filter\")\n- **`usage`**: Token usage information for billing purposes\n\nUnderstanding these response structures will help you effectively integrate the OpenAI API into your applications and handle the responses appropriately.\n\nIn the next section, we'll explore the various models available through the OpenAI API and how to choose the right one for your specific use case.\n# OpenAI Models in Depth\n\n## Available Models Overview\n\nOpenAI offers a diverse range of models through its API, each with unique capabilities, performance characteristics, and pricing. Understanding the differences between these models is crucial for selecting the right one for your specific use case. Here's a comprehensive overview of the main model families available:\n\n### GPT-4 Family\n\nThe GPT-4 family represents OpenAI's most advanced models, offering superior reasoning, creativity, and instruction-following capabilities.\n\n#### GPT-4o\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's flagship multimodal model, capable of processing both text and images with remarkable performance.\n\n**Key Features:**\n- Multimodal capabilities (text and image inputs)\n- Improved reasoning and problem-solving\n- Enhanced instruction following\n- Reduced latency compared to previous GPT-4 models\n- Competitive pricing relative to capabilities\n\n**Best For:**\n- Applications requiring both text and image understanding\n- Complex reasoning tasks\n- Production applications needing balanced performance and cost\n- User-facing applications where response speed is important\n\n#### GPT-4 Turbo\n\nGPT-4 Turbo offers high performance with optimizations for faster response times and lower cost compared to the original GPT-4.\n\n**Key Features:**\n- Large 128K token context window\n- Strong reasoning capabilities\n- Good balance of performance and cost\n- Support for function calling\n\n**Best For:**\n- Applications requiring processing of long documents\n- Complex reasoning tasks with budget considerations\n- Enterprise applications needing reliable performance\n\n#### GPT-4\n\nThe original GPT-4 model, still available for applications that have been optimized for its specific characteristics.\n\n**Key Features:**\n- Consistent, well-tested performance\n- Strong reasoning capabilities\n- Reliable instruction following\n\n**Best For:**\n- Applications already optimized for GPT-4\n- Use cases requiring the most consistent outputs\n\n### GPT-3.5 Family\n\nThe GPT-3.5 family offers a more economical option while still providing strong capabilities for many common use cases.\n\n#### GPT-3.5 Turbo\n\nGPT-3.5 Turbo is OpenAI's most cost-effective model for general-purpose text generation and understanding.\n\n**Key Features:**\n- Fast response times\n- Cost-effective pricing\n- Good performance for straightforward tasks\n- 16K token context window\n\n**Best For:**\n- High-volume applications with budget constraints\n- Simpler conversational agents\n- Content generation where absolute cutting-edge quality isn't required\n- Prototyping and development\n\n### Specialized Models\n\nBeyond the general-purpose GPT models, OpenAI offers specialized models for specific tasks:\n\n#### Text Embedding Models\n\nEmbedding models convert text into numerical vector representations that capture semantic meaning, enabling similarity comparisons and other vector operations.\n\n**Available Models:**\n- **text-embedding-3-small**: Efficient, cost-effective embeddings\n- **text-embedding-3-large**: Higher-quality embeddings with more dimensions\n\n**Best For:**\n- Semantic search implementations\n- Recommendation systems\n- Document clustering\n- Information retrieval\n\n#### Moderation Models\n\nModeration models help identify potentially harmful or inappropriate content.\n\n**Available Model:**\n- **text-moderation-latest**: Classifies text across various harm categories\n\n**Best For:**\n- Content filtering\n- User-generated content moderation\n- Safety systems for AI applications\n\n## Model Capabilities and Limitations\n\nUnderstanding what each model can and cannot do is essential for setting appropriate expectations and designing effective applications.\n\n### Common Capabilities Across Models\n\nAll OpenAI models share certain fundamental capabilities:\n\n- **Natural Language Understanding**: Comprehending user inputs across various topics and domains\n- **Text Generation**: Producing coherent, contextually relevant text\n- **Conversation**: Maintaining context through multi-turn interactions\n- **Instruction Following**: Responding to specific directions about how to complete a task\n\n### Model-Specific Capabilities\n\nDifferent models excel in different areas:\n\n#### GPT-4o and GPT-4 Family\n\n- **Complex Reasoning**: Multi-step problem solving and logical deduction\n- **Nuanced Understanding**: Grasping subtle implications and context\n- **Creative Generation**: Producing high-quality creative content\n- **Code Generation**: Writing and explaining complex code\n- **Multimodal Understanding** (GPT-4o): Processing and reasoning about images\n\n#### GPT-3.5 Family\n\n- **Straightforward Q\u0026A**: Answering factual questions\n- **Basic Content Generation**: Creating simple articles, emails, and summaries\n- **Lightweight Conversation**: Handling straightforward dialogue\n- **Simple Instructions**: Following clear, direct instructions\n\n### Common Limitations\n\nAll current AI models, including OpenAI's, have certain limitations:\n\n- **Knowledge Cutoff**: Models have a training cutoff date and lack knowledge of events after that date\n- **Hallucinations**: Models may occasionally generate plausible-sounding but incorrect information\n- **Reasoning Limitations**: Complex logical or mathematical reasoning may be inconsistent\n- **Context Window Constraints**: Models can only consider a finite amount of text at once\n- **Lack of True Understanding**: Models don't truly \"understand\" content the way humans do\n- **No External Tools**: Models cannot access the internet, run code, or use external tools unless specifically enabled through API features\n\n## Choosing the Right Model for Your Use Case\n\nSelecting the appropriate model involves balancing several factors:\n\n### Decision Factors\n\n1. **Task Complexity**: More complex tasks generally benefit from more capable models\n2. **Budget Constraints**: More capable models typically cost more per token\n3. **Response Speed Requirements**: Some applications prioritize low latency\n4. **Context Length Needs**: Consider how much context your application requires\n5. **Multimodal Requirements**: Whether your application needs to process images\n\n### Use Case Recommendations\n\nHere are some common use cases and recommended models:\n\n#### Customer Support Automation\n- **Recommended**: GPT-3.5 Turbo for most queries, GPT-4o for complex issues\n- **Rationale**: Cost-effective for high-volume, mostly straightforward queries\n\n#### Content Creation\n- **Recommended**: GPT-4o or GPT-4 Turbo\n- **Rationale**: Higher quality output justifies the increased cost\n\n#### Code Generation and Explanation\n- **Recommended**: GPT-4o\n- **Rationale**: Superior code generation capabilities and ability to understand code screenshots\n\n#### Document Analysis\n- **Recommended**: GPT-4 Turbo with 128K context\n- **Rationale**: Can process longer documents in a single request\n\n#### Semantic Search\n- **Recommended**: text-embedding-3-large\n- **Rationale**: Optimized specifically for creating high-quality text embeddings\n\n#### Educational Applications\n- **Recommended**: GPT-4o\n- **Rationale**: Better reasoning and explanation capabilities, plus ability to understand visual materials\n\n### Cost-Efficiency Strategies\n\nTo optimize your model selection for cost efficiency:\n\n1. **Use Tiered Approach**: Start with GPT-3.5 Turbo and escalate to GPT-4 models only when needed\n2. **Implement Caching**: Cache common responses to avoid redundant API calls\n3. **Optimize Prompts**: Well-designed prompts can get better results from less expensive models\n4. **Monitor Token Usage**: Regularly review token consumption to identify optimization opportunities\n\n## Understanding Context Windows and Token Limits\n\nThe context window is a crucial concept in working with language models, as it determines how much information the model can consider at once.\n\n### What Are Tokens?\n\nTokens are the basic units that models process:\n- A token is approximately 4 characters or 3/4 of a word in English\n- Punctuation, spaces, and special characters also count as tokens\n- Code and non-English languages may tokenize differently\n\n### Context Window Sizes\n\nDifferent models have different context window sizes:\n- GPT-4 Turbo: 128,000 tokens\n- GPT-4o: 128,000 tokens\n- GPT-3.5 Turbo: 16,384 tokens\n\n### Managing Long Contexts\n\nWhen working with content that exceeds the context window:\n\n1. **Chunking**: Break long documents into smaller pieces\n2. **Summarization**: Create summaries of previous context\n3. **Retrieval-Augmented Generation (RAG)**: Only include relevant context based on the query\n4. **Fine-tuning**: Train the model to work with specialized formats that convey information more efficiently\n\n### Token Counting Example\n\n```python\nimport tiktoken\n\ndef count_tokens(text, model=\"gpt-4o\"):\n    \"\"\"Count the number of tokens in a text string.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    tokens = encoding.encode(text)\n    return len(tokens)\n\n# Example usage\nsample_text = \"This is a sample text to demonstrate token counting.\"\ntoken_count = count_tokens(sample_text)\nprint(f\"The text contains {token_count} tokens.\")\n```\n\n## Model Versioning and Deprecation Policies\n\nOpenAI regularly updates its models and occasionally deprecates older versions. Understanding their versioning and deprecation policies is important for maintaining stable applications.\n\n### Versioning Approach\n\nOpenAI uses several approaches to versioning:\n\n1. **Named Versions**: Major models get distinct names (e.g., GPT-4, GPT-4o)\n2. **Suffixed Versions**: Variants may have suffixes (e.g., GPT-4 Turbo)\n3. **Date-Based Versions**: Some models include dates (e.g., gpt-3.5-turbo-0125)\n4. **Latest Pointers**: Aliases like \"gpt-4-turbo\" point to the latest version\n\n### Deprecation Timeline\n\nWhen a model is scheduled for deprecation:\n\n1. OpenAI typically announces deprecation 3+ months in advance\n2. The model remains available during this period\n3. After deprecation, requests to that specific model version will fail\n\n### Best Practices for Version Management\n\nTo handle model versioning effectively:\n\n1. **Use Latest Pointers Carefully**: They provide automatic updates but may change behavior\n2. **Monitor Announcements**: Subscribe to OpenAI's developer newsletter and monitor their blog\n3. **Version Testing**: Test new versions before migrating production systems\n4. **Graceful Fallbacks**: Implement fallback mechanisms if a model becomes unavailable\n\n```python\n# Example of version-aware client initialization\ndef get_openai_client(use_latest=False):\n    client = OpenAI(\n        api_key=os.environ.get(\"OPENAI_API_KEY\")\n    )\n    \n    # Choose model version based on preference\n    if use_latest:\n        model = \"gpt-4o\"  # Latest pointer\n    else:\n        model = \"gpt-4-0613\"  # Specific version for stability\n    \n    return client, model\n\n# Usage\nclient, model = get_openai_client(use_latest=False)\nresponse = client.chat.completions.create(\n    model=model,\n    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n)\n```\n\n## Latest Model Innovations\n\nOpenAI continuously improves its models. Here are some of the latest innovations as of 2025:\n\n### Multimodal Capabilities\n\nThe ability to process and reason about both text and images represents a significant advancement in AI capabilities:\n\n- **Vision Understanding**: Models can analyze and describe images\n- **Visual Reasoning**: Models can answer questions about visual content\n- **Combined Inputs**: Processing text and images together for holistic understanding\n\n### Enhanced Reasoning\n\nRecent models show improved abilities in complex reasoning tasks:\n\n- **Step-by-Step Problem Solving**: Breaking down complex problems methodically\n- **Logical Consistency**: Maintaining coherent reasoning across complex scenarios\n- **Self-Correction**: Identifying and fixing errors in reasoning\n\n### Specialized Instruction Following\n\nModels have become better at following specific instructions about how to respond:\n\n- **Format Adherence**: Consistently producing outputs in requested formats\n- **Style Matching**: Adopting specific tones or writing styles\n- **Constraint Satisfaction**: Working within defined limitations\n\nIn the next section, we'll explore the core functionality of the OpenAI API, including detailed examples of how to use the Chat Completions and Responses APIs effectively.\n# Core API Functionality\n\n## Chat Completions API\n\nThe Chat Completions API is one of the primary interfaces for interacting with OpenAI's language models. It's designed around a conversational format, making it ideal for applications that involve dialogue or multi-turn interactions.\n\n### Basic Usage and Parameters\n\nAt its most basic, a Chat Completions request requires a model name and a list of messages:\n\n```python\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, how are you today?\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n```\n\nHowever, the API offers numerous parameters to control the generation process:\n\n#### Essential Parameters\n\n- **`model`** (string, required): Specifies which model to use (e.g., \"gpt-4o\", \"gpt-3.5-turbo\")\n- **`messages`** (array, required): The conversation history formatted as an array of message objects\n- **`temperature`** (number, optional, default 1): Controls randomness. Lower values make responses more deterministic, higher values more creative\n- **`max_tokens`** (integer, optional): The maximum number of tokens to generate\n- **`stream`** (boolean, optional, default false): Whether to stream back partial progress\n\n#### Advanced Parameters\n\n- **`top_p`** (number, optional, default 1): An alternative to temperature, using nucleus sampling\n- **`n`** (integer, optional, default 1): How many chat completion choices to generate\n- **`stop`** (string or array, optional): Sequences where the API will stop generating further tokens\n- **`presence_penalty`** (number, optional, default 0): Penalizes new tokens based on whether they appear in the text so far\n- **`frequency_penalty`** (number, optional, default 0): Penalizes new tokens based on their frequency in the text so far\n- **`logit_bias`** (map, optional): Modifies the likelihood of specified tokens appearing in the completion\n- **`tools`** (array, optional): List of tools the model may call\n- **`tool_choice`** (string or object, optional): Controls how the model calls functions\n\n### System, User, and Assistant Messages\n\nThe Chat Completions API uses a role-based message system to structure conversations:\n\n1. **System Messages**: Set the behavior of the assistant\n2. **User Messages**: Represent user inputs\n3. **Assistant Messages**: Represent previous responses from the assistant\n4. **Tool Messages**: Contain the results of tool calls\n\nHere's an example using multiple message types:\n\n```python\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant that speaks like Shakespeare.\"},\n        {\"role\": \"user\", \"content\": \"Tell me about artificial intelligence.\"},\n        {\"role\": \"assistant\", \"content\": \"Verily, artificial intelligence doth mimic the workings of the human mind, yet 'tis crafted by mortal hands.\"},\n        {\"role\": \"user\", \"content\": \"How does it work?\"}\n    ]\n)\n```\n\n### Temperature and Other Control Parameters\n\nThe generation behavior can be fine-tuned using various parameters:\n\n#### Temperature\n\nTemperature controls randomness in the model's outputs. Lower values make responses more deterministic and focused, while higher values introduce more creativity and variability.\n\n```python\n# More deterministic response\nresponse_deterministic = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Write a tagline for a coffee shop.\"}],\n    temperature=0.2\n)\n\n# More creative response\nresponse_creative = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Write a tagline for a coffee shop.\"}],\n    temperature=0.9\n)\n```\n\n#### Top P (Nucleus Sampling)\n\nAn alternative to temperature, top_p controls diversity by considering only the tokens comprising the top p probability mass.\n\n```python\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Write a short poem about the ocean.\"}],\n    top_p=0.8\n)\n```\n\n#### Presence and Frequency Penalties\n\nThese parameters help control repetition in the generated text:\n\n```python\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Write a paragraph about climate change.\"}],\n    presence_penalty=0.5,  # Discourage repeating the same topics\n    frequency_penalty=0.5   # Discourage repeating the same words\n)\n```\n\n### Streaming Responses\n\nFor applications where you want to show responses as they're being generated (similar to typing), you can use streaming:\n\n```python\nstream = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a robot learning to paint.\"}],\n    stream=True\n)\n\n# Process the stream\nfor chunk in stream:\n    if chunk.choices[0].delta.content is not None:\n        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n```\n\nFor asynchronous applications:\n\n```python\nimport asyncio\n\nasync def stream_response():\n    stream = await client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": \"Write a short story about a robot learning to paint.\"}],\n        stream=True\n    )\n    \n    async for chunk in stream:\n        if chunk.choices[0].delta.content is not None:\n            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n\nasyncio.run(stream_response())\n```\n\n### Code Examples and Use Cases\n\n#### Building a Simple Chatbot\n\n```python\ndef chatbot():\n    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n    \n    print(\"Chatbot: Hello! How can I help you today? (Type 'exit' to quit)\")\n    \n    while True:\n        user_input = input(\"You: \")\n        \n        if user_input.lower() == 'exit':\n            print(\"Chatbot: Goodbye!\")\n            break\n        \n        messages.append({\"role\": \"user\", \"content\": user_input})\n        \n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",  # Using a less expensive model for a chatbot\n            messages=messages\n        )\n        \n        assistant_response = response.choices[0].message.content\n        print(f\"Chatbot: {assistant_response}\")\n        \n        # Add the assistant's response to the conversation history\n        messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n```\n\n#### Content Summarization\n\n```python\ndef summarize_text(text, max_length=\"short\"):\n    length_instructions = {\n        \"short\": \"Summarize this in 2-3 sentences.\",\n        \"medium\": \"Provide a paragraph-length summary.\",\n        \"long\": \"Create a detailed summary with key points.\"\n    }\n    \n    instruction = length_instructions.get(max_length, length_instructions[\"short\"])\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": f\"You are a summarization assistant. {instruction}\"},\n            {\"role\": \"user\", \"content\": text}\n        ],\n        temperature=0.3  # Lower temperature for more focused summaries\n    )\n    \n    return response.choices[0].message.content\n```\n\n#### Language Translation\n\n```python\ndef translate_text(text, source_language=\"auto\", target_language=\"English\"):\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": f\"You are a translation assistant. Translate the following text from {source_language} to {target_language}.\"},\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n    \n    return response.choices[0].message.content\n```\n\n## Responses API\n\nThe Responses API is OpenAI's newer interface for generating text, designed to simplify the developer experience while offering enhanced capabilities.\n\n### When to Use Responses API vs Chat Completions\n\nThe Responses API is generally preferable when:\n- You want a simpler interface with fewer required parameters\n- You need to work with multimodal inputs (text and images)\n- You prefer a more streamlined response format\n- You're building new applications from scratch\n\nThe Chat Completions API remains better when:\n- You need maximum control over generation parameters\n- You're implementing complex function calling\n- You require detailed token usage statistics\n- You're maintaining existing applications built on this API\n\n### Structure and Parameters\n\nThe Responses API has a more straightforward structure compared to Chat Completions:\n\n```python\nresponse = client.responses.create(\n    model=\"gpt-4o\",\n    instructions=\"You are a helpful assistant.\",\n    input=\"What is artificial intelligence?\",\n    temperature=0.7,\n    max_tokens=500\n)\n\nprint(response.output_text)\n```\n\n#### Key Parameters\n\n- **`model`** (string, required): Specifies which model to use\n- **`instructions`** (string, optional): Provides system-level instructions for the model\n- **`input`** (string or array, required): The user's input, which can be text or a structured array for multimodal inputs\n- **`temperature`** (number, optional): Controls randomness in generation\n- **`max_tokens`** (integer, optional): Maximum number of tokens to generate\n- **`stream`** (boolean, optional): Whether to stream back partial progress\n\n### Practical Examples\n\n#### Basic Text Generation\n\n```python\ndef get_response(prompt, instructions=None):\n    response = client.responses.create(\n        model=\"gpt-4o\",\n        instructions=instructions,\n        input=prompt\n    )\n    \n    return response.output_text\n```\n\n#### Multimodal Input (Text + Image)\n\n```python\ndef analyze_image(image_url, prompt):\n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"input_text\", \"text\": prompt},\n                    {\"type\": \"input_image\", \"image_url\": image_url}\n                ]\n            }\n        ]\n    )\n    \n    return response.output_text\n```\n\n#### Streaming with the Responses API\n\n```python\nstream = client.responses.create(\n    model=\"gpt-4o\",\n    input=\"Explain quantum computing to a high school student.\",\n    stream=True\n)\n\nfor event in stream:\n    if hasattr(event, 'delta') and event.delta.output_text:\n        print(event.delta.output_text, end=\"\", flush=True)\n```\n\n#### Structured Conversation\n\n```python\ndef structured_conversation(messages):\n    # Convert chat-style messages to Responses API format\n    if len(messages) == 1:\n        # Single message case\n        input_content = messages[0][\"content\"]\n    else:\n        # Multi-message conversation case\n        input_content = []\n        for msg in messages:\n            input_content.append({\n                \"role\": msg[\"role\"],\n                \"content\": [{\"type\": \"input_text\", \"text\": msg[\"content\"]}]\n            })\n    \n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=input_content\n    )\n    \n    return response.output_text\n```\n\n## Comparing API Approaches with Real Examples\n\nTo illustrate the differences between the Chat Completions API and the Responses API, let's implement the same functionality using both approaches:\n\n### Example 1: Simple Question Answering\n\n**Chat Completions API:**\n```python\ndef answer_question_chat(question):\n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides accurate and concise answers.\"},\n            {\"role\": \"user\", \"content\": question}\n        ]\n    )\n    \n    return response.choices[0].message.content\n```\n\n**Responses API:**\n```python\ndef answer_question_responses(question):\n    response = client.responses.create(\n        model=\"gpt-4o\",\n        instructions=\"You are a helpful assistant that provides accurate and concise answers.\",\n        input=question\n    )\n    \n    return response.output_text\n```\n\n### Example 2: Multi-turn Conversation\n\n**Chat Completions API:**\n```python\ndef chat_conversation(conversation_history, new_message):\n    # Add the new message to the history\n    conversation_history.append({\"role\": \"user\", \"content\": new_message})\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=conversation_history\n    )\n    \n    assistant_message = response.choices[0].message.content\n    \n    # Update the conversation history\n    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n    \n    return assistant_message, conversation_history\n```\n\n**Responses API:**\n```python\ndef responses_conversation(conversation_history, new_message):\n    # Format the conversation history for the Responses API\n    formatted_input = []\n    \n    for message in conversation_history:\n        formatted_input.append({\n            \"role\": message[\"role\"],\n            \"content\": [{\"type\": \"input_text\", \"text\": message[\"content\"]}]\n        })\n    \n    # Add the new message\n    formatted_input.append({\n        \"role\": \"user\",\n        \"content\": [{\"type\": \"input_text\", \"text\": new_message}]\n    })\n    \n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=formatted_input\n    )\n    \n    assistant_message = response.output_text\n    \n    # Update the conversation history\n    conversation_history.append({\"role\": \"user\", \"content\": new_message})\n    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n    \n    return assistant_message, conversation_history\n```\n\n### Example 3: Content Generation with Specific Parameters\n\n**Chat Completions API:**\n```python\ndef generate_content_chat(prompt, creativity_level=\"medium\"):\n    # Map creativity level to temperature\n    temperature_map = {\n        \"low\": 0.3,\n        \"medium\": 0.7,\n        \"high\": 1.0\n    }\n    \n    temperature = temperature_map.get(creativity_level, 0.7)\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a creative content generator.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=temperature,\n        max_tokens=500,\n        presence_penalty=0.2,\n        frequency_penalty=0.2\n    )\n    \n    return response.choices[0].message.content\n```\n\n**Responses API:**\n```python\ndef generate_content_responses(prompt, creativity_level=\"medium\"):\n    # Map creativity level to temperature\n    temperature_map = {\n        \"low\": 0.3,\n        \"medium\": 0.7,\n        \"high\": 1.0\n    }\n    \n    temperature = temperature_map.get(creativity_level, 0.7)\n    \n    response = client.responses.create(\n        model=\"gpt-4o\",\n        instructions=\"You are a creative content generator.\",\n        input=prompt,\n        temperature=temperature,\n        max_tokens=500\n    )\n    \n    return response.output_text\n```\n\nIn the next section, we'll explore advanced API features, including function calling, embeddings, and multimodal capabilities.\n# Advanced API Features\n\n## Function Calling\n\nFunction calling is a powerful capability that allows models to generate structured data and invoke external functions. This feature enables developers to create more interactive and capable applications by connecting AI models with external tools and services.\n\n### Defining Functions for the Model to Call\n\nTo use function calling, you first need to define the functions that the model can call. These definitions include the function name, description, and parameter schema:\n\n```python\nimport os\nimport json\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n\n# Define the functions that the model can call\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_weather\",\n            \"description\": \"Get the current weather in a given location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n                    },\n                    \"unit\": {\n                        \"type\": \"string\",\n                        \"enum\": [\"celsius\", \"fahrenheit\"],\n                        \"description\": \"The temperature unit to use\",\n                    },\n                },\n                \"required\": [\"location\"],\n            },\n        }\n    }\n]\n```\n\n### Handling Function Responses\n\nOnce you've defined the functions, you can make a request to the model and process any function calls it generates:\n\n```python\ndef get_weather(location, unit=\"celsius\"):\n    \"\"\"Get the current weather in a location (mock implementation)\"\"\"\n    # In a real application, you would call a weather API here\n    weather_data = {\n        \"location\": location,\n        \"temperature\": \"22\" if unit == \"celsius\" else \"72\",\n        \"unit\": unit,\n        \"forecast\": [\"sunny\", \"windy\"],\n        \"humidity\": \"65%\"\n    }\n    return json.dumps(weather_data)\n\n# Make a request to the model\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}\n    ],\n    tools=tools,\n    tool_choice=\"auto\"  # Let the model decide when to call functions\n)\n\n# Check if the model wants to call a function\nmessage = response.choices[0].message\ntool_calls = message.tool_calls\n\nif tool_calls:\n    # The model wants to call a function\n    available_functions = {\n        \"get_weather\": get_weather,\n    }\n    \n    # Prepare messages for the second request\n    messages = [\n        {\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"},\n        message  # Include the assistant's response with the function call\n    ]\n    \n    # Process each function call\n    for tool_call in tool_calls:\n        function_name = tool_call.function.name\n        function_args = json.loads(tool_call.function.arguments)\n        \n        if function_name in available_functions:\n            function_response = available_functions[function_name](**function_args)\n            \n            # Append the function response to the messages\n            messages.append({\n                \"role\": \"tool\",\n                \"tool_call_id\": tool_call.id,\n                \"name\": function_name,\n                \"content\": function_response\n            })\n    \n    # Make a second request to get the final response\n    second_response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=messages\n    )\n    \n    print(second_response.choices[0].message.content)\nelse:\n    # The model didn't call a function\n    print(message.content)\n```\n\n### Complex Function Calling Patterns\n\nFunction calling can be used in more complex scenarios, such as:\n\n#### Multiple Functions\n\n```python\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_weather\",\n            \"description\": \"Get the current weather in a given location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\"type\": \"string\", \"description\": \"The city and state\"},\n                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n                },\n                \"required\": [\"location\"],\n            },\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_restaurant_recommendations\",\n            \"description\": \"Get restaurant recommendations for a location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\"type\": \"string\", \"description\": \"The city and state\"},\n                    \"cuisine\": {\"type\": \"string\", \"description\": \"Type of cuisine\"},\n                    \"price_range\": {\"type\": \"string\", \"enum\": [\"$\", \"$$\", \"$$$\", \"$$$$\"]},\n                },\n                \"required\": [\"location\"],\n            },\n        }\n    }\n]\n```\n\n#### Forcing Specific Functions\n\nYou can force the model to use a specific function:\n\n```python\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}\n    ],\n    tools=tools,\n    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_weather\"}}\n)\n```\n\n#### Parallel Function Calling\n\nThe model can call multiple functions in a single response:\n\n```python\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the weather like in Miami, and can you recommend some Italian restaurants there?\"}\n    ],\n    tools=tools,\n    tool_choice=\"auto\"\n)\n\n# Process multiple function calls in parallel\nif response.choices[0].message.tool_calls:\n    # Process each function call as shown earlier\n    pass\n```\n\n### Real-World Examples\n\n#### Building a Travel Assistant\n\n```python\ndef travel_assistant():\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search_flights\",\n                \"description\": \"Search for flights between two cities on a specific date\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"origin\": {\"type\": \"string\", \"description\": \"Origin city or airport code\"},\n                        \"destination\": {\"type\": \"string\", \"description\": \"Destination city or airport code\"},\n                        \"date\": {\"type\": \"string\", \"description\": \"Date in YYYY-MM-DD format\"},\n                        \"passengers\": {\"type\": \"integer\", \"description\": \"Number of passengers\"}\n                    },\n                    \"required\": [\"origin\", \"destination\", \"date\"]\n                }\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search_hotels\",\n                \"description\": \"Search for hotels in a city for specific dates\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\"type\": \"string\", \"description\": \"City name\"},\n                        \"check_in\": {\"type\": \"string\", \"description\": \"Check-in date in YYYY-MM-DD format\"},\n                        \"check_out\": {\"type\": \"string\", \"description\": \"Check-out date in YYYY-MM-DD format\"},\n                        \"guests\": {\"type\": \"integer\", \"description\": \"Number of guests\"}\n                    },\n                    \"required\": [\"city\", \"check_in\", \"check_out\"]\n                }\n            }\n        }\n    ]\n    \n    # Mock implementations of the functions\n    def search_flights(origin, destination, date, passengers=1):\n        return json.dumps({\n            \"flights\": [\n                {\"airline\": \"Example Air\", \"departure\": \"10:00\", \"arrival\": \"12:00\", \"price\": \"$350\"},\n                {\"airline\": \"Sample Airlines\", \"departure\": \"14:00\", \"arrival\": \"16:00\", \"price\": \"$310\"}\n            ]\n        })\n    \n    def search_hotels(city, check_in, check_out, guests=1):\n        return json.dumps({\n            \"hotels\": [\n                {\"name\": \"Grand Hotel\", \"rating\": 4.5, \"price_per_night\": \"$200\"},\n                {\"name\": \"City Center Inn\", \"rating\": 4.2, \"price_per_night\": \"$150\"}\n            ]\n        })\n    \n    available_functions = {\n        \"search_flights\": search_flights,\n        \"search_hotels\": search_hotels\n    }\n    \n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful travel assistant.\"}\n    ]\n    \n    print(\"Travel Assistant: Hello! I can help you plan your trip. What are your travel plans?\")\n    \n    while True:\n        user_input = input(\"You: \")\n        \n        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n            print(\"Travel Assistant: Goodbye! Have a great trip!\")\n            break\n        \n        messages.append({\"role\": \"user\", \"content\": user_input})\n        \n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages,\n            tools=tools,\n            tool_choice=\"auto\"\n        )\n        \n        assistant_message = response.choices[0].message\n        messages.append(assistant_message)\n        \n        # Process any function calls\n        if assistant_message.tool_calls:\n            for tool_call in assistant_message.tool_calls:\n                function_name = tool_call.function.name\n                function_args = json.loads(tool_call.function.arguments)\n                \n                function_response = available_functions[function_name](**function_args)\n                \n                messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"name\": function_name,\n                    \"content\": function_response\n                })\n            \n            # Get the final response after function calls\n            final_response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=messages\n            )\n            \n            final_message = final_response.choices[0].message.content\n            messages.append({\"role\": \"assistant\", \"content\": final_message})\n            print(f\"Travel Assistant: {final_message}\")\n        else:\n            print(f\"Travel Assistant: {assistant_message.content}\")\n```\n\n## Embeddings\n\nEmbeddings are numerical representations of text that capture semantic meaning, allowing for operations like similarity comparison, clustering, and search.\n\n### Understanding Vector Embeddings\n\nVector embeddings convert text into high-dimensional vectors where:\n- Similar texts have vectors that are close together\n- Different texts have vectors that are far apart\n- The relationships between words and concepts are preserved in the vector space\n\nThis makes embeddings powerful for a wide range of applications:\n- Semantic search\n- Recommendation systems\n- Document clustering\n- Information retrieval\n- Anomaly detection\n\n### Creating and Using Embeddings\n\nThe OpenAI API provides dedicated embedding models that generate these vector representations:\n\n```python\nimport os\nimport numpy as np\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n\ndef get_embedding(text, model=\"text-embedding-3-small\"):\n    \"\"\"Get the embedding for a given text\"\"\"\n    response = client.embeddings.create(\n        model=model,\n        input=text\n    )\n    return response.data[0].embedding\n\n# Example usage\ntext1 = \"The cat sat on the mat.\"\ntext2 = \"The feline rested on the rug.\"\ntext3 = \"Quantum physics explores subatomic particles.\"\n\nembedding1 = get_embedding(text1)\nembedding2 = get_embedding(text2)\nembedding3 = get_embedding(text3)\n\n# Calculate cosine similarity between embeddings\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\nsimilarity_1_2 = cosine_similarity(embedding1, embedding2)\nsimilarity_1_3 = cosine_similarity(embedding1, embedding3)\n\nprint(f\"Similarity between text1 and text2: {similarity_1_2}\")\nprint(f\"Similarity between text1 and text3: {similarity_1_3}\")\n```\n\n### Semantic Search Implementation\n\nOne of the most common applications of embeddings is semantic search:\n\n```python\ndef create_document_embeddings(documents, model=\"text-embedding-3-small\"):\n    \"\"\"Create embeddings for a list of documents\"\"\"\n    document_embeddings = {}\n    \n    for i, doc in enumerate(documents):\n        embedding = get_embedding(doc, model)\n        document_embeddings[i] = embedding\n    \n    return document_embeddings\n\ndef semantic_search(query, document_embeddings, documents, top_n=3):\n    \"\"\"Search for documents most similar to the query\"\"\"\n    query_embedding = get_embedding(query)\n    \n    # Calculate similarities\n    similarities = {}\n    for idx, doc_embedding in document_embeddings.items():\n        similarities[idx] = cosine_similarity(query_embedding, doc_embedding)\n    \n    # Sort by similarity\n    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n    \n    # Return top results\n    results = []\n    for idx, score in sorted_similarities[:top_n]:\n        results.append({\n            \"document\": documents[idx],\n            \"similarity_score\": score\n        })\n    \n    return results\n\n# Example usage\ndocuments = [\n    \"OpenAI was founded in December 2015.\",\n    \"GPT stands for Generative Pre-trained Transformer.\",\n    \"Python is a popular programming language for AI development.\",\n    \"Machine learning models require large amounts of data for training.\",\n    \"The transformer architecture revolutionized natural language processing.\"\n]\n\ndocument_embeddings = create_document_embeddings(documents)\n\nquery = \"What is GPT?\"\nsearch_results = semantic_search(query, document_embeddings, documents)\n\nfor i, result in enumerate(search_results):\n    print(f\"Result {i+1}: {result['document']} (Score: {result['similarity_score']:.4f})\")\n```\n\n### Similarity Comparison Techniques\n\nBeyond cosine similarity, there are other techniques for comparing embeddings:\n\n```python\ndef euclidean_distance(a, b):\n    \"\"\"Calculate Euclidean distance between two vectors\"\"\"\n    return np.linalg.norm(np.array(a) - np.array(b))\n\ndef dot_product(a, b):\n    \"\"\"Calculate dot product between two vectors\"\"\"\n    return np.dot(a, b)\n\n# Example comparison\nembedding_a = get_embedding(\"I love programming\")\nembedding_b = get_embedding(\"Coding is my passion\")\n\nprint(f\"Cosine similarity: {cosine_similarity(embedding_a, embedding_b)}\")\nprint(f\"Euclidean distance: {euclidean_distance(embedding_a, embedding_b)}\")\nprint(f\"Dot product: {dot_product(embedding_a, embedding_b)}\")\n```\n\n## Image and Multimodal Capabilities\n\nOpenAI's models have evolved to handle both text and images, enabling powerful multimodal applications.\n\n### Processing Images with the API\n\nThe Responses API allows you to include images alongside text in your requests:\n\n```python\nimport base64\n\ndef analyze_image_from_url(image_url, prompt):\n    \"\"\"Analyze an image from a URL\"\"\"\n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"input_text\", \"text\": prompt},\n                    {\"type\": \"input_image\", \"image_url\": image_url}\n                ]\n            }\n        ]\n    )\n    \n    return response.output_text\n\ndef analyze_image_from_file(image_path, prompt):\n    \"\"\"Analyze an image from a local file\"\"\"\n    # Read and encode the image\n    with open(image_path, \"rb\") as image_file:\n        base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n    \n    # Format as a data URL\n    data_url = f\"data:image/jpeg;base64,{base64_image}\"\n    \n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"input_text\", \"text\": prompt},\n                    {\"type\": \"input_image\", \"image_url\": data_url}\n                ]\n            }\n        ]\n    )\n    \n    return response.output_text\n```\n\n### Combined Text and Image Inputs\n\nYou can create more complex interactions by combining multiple images and text:\n\n```python\ndef compare_images(image_url1, image_url2, prompt):\n    \"\"\"Compare two images based on a prompt\"\"\"\n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"input_text\", \"text\": prompt},\n                    {\"type\": \"input_image\", \"image_url\": image_url1},\n                    {\"type\": \"input_image\", \"image_url\": image_url2}\n                ]\n            }\n        ]\n    )\n    \n    return response.output_text\n```\n\n### Implementation Examples\n\n#### Visual Question Answering\n\n```python\ndef visual_qa_system():\n    print(\"Visual Question Answering System\")\n    print(\"Enter 'exit' to quit\")\n    \n    while True:\n        image_url = input(\"\\nEnter image URL (or path to local image): \")\n        \n        if image_url.lower() == 'exit':\n            break\n        \n        question = input(\"Enter your question about the image: \")\n        \n        if question.lower() == 'exit':\n            break\n        \n        # Determine if it's a URL or local path\n        if image_url.startswith(('http://', 'https://')):\n            result = analyze_image_from_url(image_url, question)\n        else:\n            try:\n                result = analyze_image_from_file(image_url, question)\n            except Exception as e:\n                result = f\"Error processing image: {str(e)}\"\n        \n        print(f\"\\nAnswer: {result}\")\n```\n\n#### Image-Based Content Generation\n\n```python\ndef generate_content_from_image(image_url, content_type):\n    \"\"\"Generate content based on an image\"\"\"\n    prompts = {\n        \"description\": \"Describe this image in detail.\",\n        \"story\": \"Create a short story inspired by this image.\",\n        \"social_post\": \"Write a social media post caption for this image.\",\n        \"analysis\": \"Analyze the composition and elements of this image.\"\n    }\n    \n    prompt = prompts.get(content_type, prompts[\"description\"])\n    \n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"input_text\", \"text\": prompt},\n                    {\"type\": \"input_image\", \"image_url\": image_url}\n                ]\n            }\n        ]\n    )\n    \n    return response.output_text\n```\n\n#### Document Analysis System\n\n```python\ndef analyze_document(document_image_url):\n    \"\"\"Extract and analyze information from a document image\"\"\"\n    response = client.responses.create(\n        model=\"gpt-4o\",\n        input=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"input_text\", \"text\": \"Extract all text from this document. Then identify key information such as names, dates, amounts, and summarize the main content.\"},\n                    {\"type\": \"input_image\", \"image_url\": document_image_url}\n                ]\n            }\n        ]\n    )\n    \n    return response.output_text\n```\n\nIn the next section, we'll explore specialized API services, including the Assistants API, fine-tuning, and the Moderation API.\n# Specialized API Services\n\n## Assistants API\n\nThe Assistants API provides a higher-level interface for building AI assistants with persistent memory and specialized tools. It's designed to simplify the development of complex, stateful AI applications.\n\n### Creating and Managing Assistants\n\nAn Assistant is a persistent entity with specific instructions, capabilities, and tools:\n\n```python\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n\n# Create an assistant\nassistant = client.beta.assistants.create(\n    name=\"Math Tutor\",\n    instructions=\"You are a personal math tutor. Explain concepts in simple terms and provide step-by-step guidance for solving problems.\",\n    model=\"gpt-4o\",\n    tools=[{\"type\": \"code_interpreter\"}]\n)\n\nprint(f\"Created assistant with ID: {assistant.id}\")\n\n# Retrieve an assistant\nretrieved_assistant = client.beta.assistants.retrieve(assistant.id)\n\n# Update an assistant\nupdated_assistant = client.beta.assistants.update(\n    assistant.id,\n    instructions=\"You are a personal math tutor. Explain concepts in simple terms, provide step-by-step guidance, and use examples to illustrate mathematical principles.\",\n    model=\"gpt-4o\"\n)\n\n# List assistants\nassistants = client.beta.assistants.list(\n    order=\"desc\",\n    limit=10\n)\n\nfor assistant in assistants.data:\n    print(f\"Assistant: {assistant.name}, ID: {assistant.id}\")\n\n# Delete an assistant\nclient.beta.assistants.delete(assistant.id)\n```\n\n### Threads and Messages\n\nThreads maintain conversation history and state across multiple interactions:\n\n```python\n# Create a thread\nthread = client.beta.threads.create()\nprint(f\"Created thread with ID: {thread.id}\")\n\n# Add a message to the thread\nmessage = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"I'm having trouble understanding how to solve quadratic equations.\"\n)\n\n# Retrieve messages from a thread\nmessages = client.beta.threads.messages.list(\n    thread_id=thread.id\n)\n\nfor message in messages.data:\n    print(f\"Role: {message.role}, Content: {message.content[0].text.value}\")\n\n# Run the assistant on the thread\nrun = client.beta.threads.runs.create(\n    thread_id=thread.id,\n    assistant_id=assistant.id\n)\n\n# Check the run status\nrun_status = client.beta.threads.runs.retrieve(\n    thread_id=thread.id,\n    run_id=run.id\n)\n\nprint(f\"Run status: {run_status.status}\")\n\n# Once completed, retrieve the assistant's response\nif run_status.status == \"completed\":\n    messages = client.beta.threads.messages.list(\n        thread_id=thread.id\n    )\n    \n    # The latest message will be the assistant's response\n    latest_message = messages.data[0]\n    if latest_message.role == \"assistant\":\n        print(f\"Assistant's response: {latest_message.content[0].text.value}\")\n```\n\n### Tools (Code Interpreter, Retrieval, Function Calling)\n\nAssistants can be equipped with various tools to enhance their capabilities:\n\n#### Code Interpreter\n\n```python\n# Create an assistant with code interpreter\ncode_assistant = client.beta.assistants.create(\n    name=\"Python Coding Assistant\",\n    instructions=\"You are a Python programming assistant. Help users write, debug, and optimize Python code.\",\n    model=\"gpt-4o\",\n    tools=[{\"type\": \"code_interpreter\"}]\n)\n\n# Create a thread with a coding question\nthread = client.beta.threads.create()\nclient.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"Can you write a Python function to calculate the Fibonacci sequence up to n terms?\"\n)\n\n# Run the assistant\nrun = client.beta.threads.runs.create(\n    thread_id=thread.id,\n    assistant_id=code_assistant.id\n)\n\n# In a real application, you would poll for completion\n# For demonstration, we assume the run completes successfully\n```\n\n#### Retrieval\n\n```python\n# Upload a file for retrieval\nfile = client.files.create(\n    file=open(\"math_textbook.pdf\", \"rb\"),\n    purpose=\"assistants\"\n)\n\n# Create an assistant with retrieval\nretrieval_assistant = client.beta.assistants.create(\n    name=\"Math Textbook Assistant\",\n    instructions=\"You are a helpful teaching assistant. Use the provided textbook to answer questions about mathematics.\",\n    model=\"gpt-4o\",\n    tools=[{\"type\": \"retrieval\"}],\n    file_ids=[file.id]\n)\n\n# Create a thread with a question about the textbook\nthread = client.beta.threads.create()\nclient.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"What does the textbook say about the quadratic formula?\"\n)\n\n# Run the assistant\nrun = client.beta.threads.runs.create(\n    thread_id=thread.id,\n    assistant_id=retrieval_assistant.id\n)\n```\n\n#### Function Calling\n\n```python\n# Define functions for the assistant to call\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_stock_price\",\n            \"description\": \"Get the current stock price for a given ticker symbol\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"symbol\": {\n                        \"type\": \"string\",\n                        \"description\": \"The stock ticker symbol (e.g., AAPL for Apple)\"\n                    }\n                },\n                \"required\": [\"symbol\"]\n            }\n        }\n    }\n]\n\n# Create an assistant with function calling\nfunction_assistant = client.beta.assistants.create(\n    name=\"Financial Assistant\",\n    instructions=\"You are a financial advisor assistant. Help users with investment questions and provide stock information when requested.\",\n    model=\"gpt-4o\",\n    tools=tools\n)\n\n# Create a thread with a question about stocks\nthread = client.beta.threads.create()\nclient.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"What's the current price of Apple stock?\"\n)\n\n# Run the assistant\nrun = client.beta.threads.runs.create(\n    thread_id=thread.id,\n    assistant_id=function_assistant.id\n)\n\n# In a real application, you would need to handle the function call\n# For example:\ndef handle_function_calls(thread_id, run_id):\n    run_status = client.beta.threads.runs.retrieve(\n        thread_id=thread_id,\n        run_id=run_id\n    )\n    \n    if run_status.status == \"requires_action\":\n        tool_calls = run_status.required_action.submit_tool_outputs.tool_calls\n        tool_outputs = []\n        \n        for tool_call in tool_calls:\n            if tool_call.function.name == \"get_stock_price\":\n                # In a real application, you would call an actual stock API\n                symbol = json.loads(tool_call.function.arguments)[\"symbol\"]\n                price = \"150.25\"  # Mock price\n                \n                tool_outputs.append({\n                    \"tool_call_id\": tool_call.id,\n                    \"output\": json.dumps({\"price\": price, \"currency\": \"USD\"})\n                })\n        \n        # Submit the outputs back to the assistant\n        client.beta.threads.runs.submit_tool_outputs(\n            thread_id=thread_id,\n            run_id=run_id,\n            tool_outputs=tool_outputs\n        )\n```\n\n### Implementation Examples\n\n#### Building a Customer Support Assistant\n\n```python\ndef create_customer_support_assistant():\n    # Upload knowledge base documents\n    faq_file = client.files.create(\n        file=open(\"product_faq.pdf\", \"rb\"),\n        purpose=\"assistants\"\n    )\n    \n    manual_file = client.files.create(\n        file=open(\"user_manual.pdf\", \"rb\"),\n        purpose=\"assistants\"\n    )\n    \n    # Define functions for the assistant\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"check_order_status\",\n                \"description\": \"Check the status of a customer's order\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"order_id\": {\n                            \"type\": \"string\",\n                            \"description\": \"The order ID to check\"\n                        }\n                    },\n                    \"required\": [\"order_id\"]\n                }\n            }\n        },\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"create_return_request\",\n                \"description\": \"Create a return request for a product\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"order_id\": {\n                            \"type\": \"string\",\n                            \"description\": \"The order ID\"\n                        },\n                        \"product_id\": {\n                            \"type\": \"string\",\n                            \"description\": \"The product ID to return\"\n                        },\n                        \"reason\": {\n                            \"type\": \"string\",\n                            \"description\": \"Reason for the return\"\n                        }\n                    },\n                    \"required\": [\"order_id\", \"product_id\", \"reason\"]\n                }\n            }\n        }\n    ]\n    \n    # Create the assistant\n    assistant = client.beta.assistants.create(\n        name=\"Product Support Assistant\",\n        instructions=\"\"\"You are a customer support assistant for our electronics company.\n        Help customers with product questions, order issues, and return requests.\n        Use the knowledge base to answer product-specific questions.\n        Be friendly, concise, and helpful.\"\"\",\n        model=\"gpt-4o\",\n        tools=tools + [{\"type\": \"retrieval\"}],\n        file_ids=[faq_file.id, manual_file.id]\n    )\n    \n    return assistant.id\n\n# Function implementations for the assistant to call\ndef check_order_status(order_id):\n    # In a real application, this would query an order database\n    statuses = {\n        \"ORD12345\": \"Shipped - Expected delivery on April 5, 2025\",\n        \"ORD12346\": \"Processing - Will ship within 24 hours\",\n        \"ORD12347\": \"Delivered on March 30, 2025\"\n    }\n    \n    return json.dumps({\n        \"order_id\": order_id,\n        \"status\": statuses.get(order_id, \"Order not found\"),\n        \"last_updated\": \"2025-04-03T12:00:00Z\"\n    })\n\ndef create_return_request(order_id, product_id, reason):\n    # In a real application, this would create a return in your system\n    return_id = \"RET\" + str(random.randint(10000, 99999))\n    \n    return json.dumps({\n        \"return_id\": return_id,\n        \"order_id\": order_id,\n        \"product_id\": product_id,\n        \"status\": \"Created\",\n        \"instructions\": \"Please print the return label and ship the product back within 14 days.\"\n    })\n```\n\n## Fine-tuning\n\nFine-tuning allows you to customize OpenAI's models for specific use cases by training them on your own data.\n\n### When and Why to Fine-tune Models\n\nFine-tuning is beneficial when:\n\n1. **Consistent Formatting**: You need responses in a specific, consistent format\n2. **Domain Adaptation**: You want the model to excel in a specialized domain\n3. **Custom Tone or Style**: You need responses in a particular voice or style\n4. **Improved Performance**: You want better results on specific tasks than prompting alone can achieve\n5. **Reduced Token Usage**: You want to achieve better results with shorter prompts\n\n### Preparing Training Data\n\nTraining data for fine-tuning should be formatted as a list of conversation examples:\n\n```python\n# Example training data for a customer support assistant\ntraining_data = [\n    {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a customer support agent for Acme Electronics.\"},\n            {\"role\": \"user\", \"content\": \"My laptop won't turn on.\"},\n            {\"role\": \"assistant\", \"content\": \"I'm sorry to hear that your Acme laptop is not turning on. Let's troubleshoot this issue together. First, please try these steps:\\n\\n1. Make sure the laptop is charged by connecting it to power. Look for a light indicator showing it's receiving power.\\n2. Press and hold the power button for 10 seconds, then release and try turning it on again.\\n3. If possible, remove the battery, wait 30 seconds, reinsert it, and try again.\\n\\nCould you let me know if any of these steps help or if you notice any lights or sounds when attempting to power on?\"}\n        ]\n    },\n    {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": \"You are a customer support agent for Acme Electronics.\"},\n            {\"role\": \"user\", \"content\": \"How do I connect my Acme Smart TV to WiFi?\"},\n            {\"role\": \"assistant\", \"content\": \"Connecting your Acme Smart TV to WiFi is a straightforward process. Here's how to do it:\\n\\n1. Press the Home button on your remote control\\n2. Navigate to Settings (usually a gear icon)\\n3. Select Network \u0026 Internet or Network Settings\\n4. Choose WiFi and turn it on if it isn't already\\n5. Select your WiFi network from the list\\n6. Enter your WiFi password using the on-screen keyboard\\n7. Select Connect or OK\\n\\nYour TV should connect within a few moments. If you encounter any issues, make sure your WiFi password is correct and that your router is functioning properly. Is there anything specific about this process you're having trouble with?\"}\n        ]\n    }\n]\n\n# Save the training data to a JSONL file\nimport json\n\nwith open(\"support_training_data.jsonl\", \"w\") as f:\n    for example in training_data:\n        f.write(json.dumps(example) + \"\\n\")\n```\n\n### Creating and Managing Fine-tuning Jobs\n\nOnce your training data is prepared, you can create a fine-tuning job:\n\n```python\n# Upload the training file\ntraining_file = client.files.create(\n    file=open(\"support_training_data.jsonl\", \"rb\"),\n    purpose=\"fine-tuning\"\n)\n\n# Create a fine-tuning job\nfine_tuning_job = client.fine_tuning.jobs.create(\n    training_file=training_file.id,\n    model=\"gpt-3.5-turbo\",  # Base model to fine-tune\n    suffix=\"acme-support\"   # Custom suffix for your fine-tuned model\n)\n\nprint(f\"Fine-tuning job created: {fine_tuning_job.id}\")\n\n# Check the status of the fine-tuning job\njob_status = client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\nprint(f\"Status: {job_status.status}\")\n\n# List all fine-tuning jobs\njobs = client.fine_tuning.jobs.list()\nfor job in jobs.data:\n    print(f\"Job ID: {job.id}, Model: {job.model}, Status: {job.status}\")\n```\n\n### Using Fine-tuned Models\n\nOnce your fine-tuning job is complete, you can use your custom model:\n\n```python\n# Get the fine-tuned model name from the job\njob = client.fine_tuning.jobs.retrieve(fine_tuning_job.id)\nfine_tuned_model = job.fine_tuned_model\n\n# Use the fine-tuned model\nresponse = client.chat.completions.create(\n    model=fine_tuned_model,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a customer support agent for Acme Electronics.\"},\n        {\"role\": \"user\", \"content\": \"My Acme headphones won't connect to my phone.\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n```\n\n### Cost Considerations\n\nFine-tuning involves both upfront training costs and usage costs:\n\n1. **Training Costs**: Based on the number of tokens in your training data\n2. **Usage Costs**: Typically higher per token than base models\n3. **Model Hosting**: Fine-tuned models are hosted until you delete them\n\nTo optimize costs:\n\n```python\nimport tiktoken\n\ndef estimate_fine_tuning_cost(file_path, model=\"gpt-3.5-turbo\"):\n    \"\"\"Estimate the cost of fine-tuning based on token count\"\"\"\n    # Approximate costs (check OpenAI's pricing page for current rates)\n    training_cost_per_1k_tokens = 0.008  # for gpt-3.5-turbo\n    if model == \"gpt-4\":\n        training_cost_per_1k_tokens = 0.03\n    \n    encoding = tiktoken.encoding_for_model(model)\n    total_tokens = 0\n    \n    with open(file_path, \"r\") as f:\n        for line in f:\n            example = json.loads(line)\n            for message in example[\"messages\"]:\n                total_tokens += len(encoding.encode(message[\"content\"]))\n                # Add 4 tokens for message metadata\n                total_tokens += 4\n            # Add 2 tokens for conversation metadata\n            total_tokens += 2\n    \n    estimated_cost = (total_tokens / 1000) * training_cost_per_1k_tokens\n    \n    return {\n        \"total_tokens\": total_tokens,\n        \"estimated_cost_usd\": estimated_cost\n    }\n\n# Example usage\ncost_estimate = estimate_fine_tuning_cost(\"support_training_data.jsonl\")\nprint(f\"Estimated fine-tuning cost: ${cost_estimate['estimated_cost_usd']:.2f}\")\n```\n\n## Moderation API\n\nThe Moderation API helps identify potentially harmful or inappropriate content to ensure responsible AI use.\n\n### Content Filtering Capabilities\n\nThe Moderation API classifies text across several harm categories:\n\n1. **Hate**: Content expressing hatred or discrimination\n2. **Harassment**: Content intended to harass, intimidate, or bully\n3. **Self-harm**: Content promoting self-harm or suicide\n4. **Sexual**: Sexually explicit content\n5. **Violence**: Content depicting or promoting violence\n6. **Violent/hate**: Content that is both violent and hateful\n\n### Implementation in Production Applications\n\nHere's how to integrate the Moderation API into your applications:\n\n```python\ndef check_content_moderation(text):\n    \"\"\"Check if content violates content policy\"\"\"\n    try:\n        response = client.moderations.create(input=text)\n        result = response.results[0]\n        \n        # Check if the content is flagged\n        if result.flagged:\n            flagged_categories = []\n            for category, flagged in result.categories.items():\n                if flagged:\n                    score = getattr(result.category_scores, category)\n                    flagged_categories.append(f\"{category} ({score:.4f})\")\n            \n            return {\n                \"flagged\": True,\n                \"categories\": flagged_categories\n            }\n        else:\n            return {\"flagged\": False}\n    except Exception as e:\n        return {\"error\": str(e)}\n\n# Example usage\ndef moderate_user_input():\n    print(\"Content Moderation Demo (type 'exit' to quit)\")\n    \n    while True:\n        user_input = input(\"\\nEnter text to check: \")\n        \n        if user_input.lower() == 'exit':\n            break\n        \n        # Check content before processing\n        moderation_result = check_content_moderation(user_input)\n        \n        if \"error\" in moderation_result:\n            print(f\"Error: {moderation_result['error']}\")\n        elif moderation_result[\"flagged\"]:\n            print(\"â ï¸ Content flagged for the following categories:\")\n            for category in moderation_result[\"categories\"]:\n                print(f\"- {category}\")\n            print(\"This content may violate our content policy.\")\n        else:\n            print(\"â Content passed moderation checks.\")\n            \n            # Process the content with the OpenAI API\n            response = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[{\"role\": \"user\", \"content\": user_input}]\n            )\n            \n            print(f\"\\nResponse: {response.choices[0].message.content}\")\n```\n\n### Handling Flagged Content\n\nWhen content is flagged, you have several options:\n\n```python\ndef handle_flagged_content(text, moderation_result):\n    \"\"\"Handle content that has been flagged by the moderation API\"\"\"\n    if not moderation_result[\"flagged\"]:\n        # Content is safe, process normally\n        return process_safe_content(text)\n    \n    # Get the flagged categories\n    categories = moderation_result[\"categories\"]\n    \n    # Different handling strategies based on category and severity\n    if any(\"hate\" in category.lower() for category in categories):\n        return {\n            \"status\": \"rejected\",\n            \"message\": \"We cannot process content that contains hateful language.\"\n        }\n    elif any(\"sexual\" in category.lower() for category in categories):\n        return {\n            \"status\": \"rejected\",\n            \"message\": \"We cannot process content that contains explicit sexual content.\"\n        }\n    elif any(\"violence\" in category.lower() for category in categories):\n        return {\n            \"status\": \"rejected\",\n            \"message\": \"We cannot process content that contains violent content.\"\n        }\n    elif any(\"self-harm\" in category.lower() for category in categories):\n        return {\n            \"status\": \"referred\",\n            \"message\": \"If you're experiencing thoughts of self-harm, please contact a mental health professional or call a crisis helpline.\"\n        }\n    else:\n        # For other categories or lower severity, you might warn but still process\n        return {\n            \"status\": \"warned\",\n            \"message\": \"Some aspects of your content may be inappropriate. We've processed your request, but please review our content guidelines.\",\n            \"result\": process_safe_content(text)\n        }\n\ndef process_safe_content(text):\n    \"\"\"Process content that has passed moderation checks\"\"\"\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": text}]\n    )\n    \n    return {\n        \"status\": \"processed\",\n        \"result\": response.choices[0].message.content\n    }\n```\n\n### Pre-emptive Moderation System\n\nFor a more robust approach, implement pre-emptive moderation:\n\n```python\nclass ContentModerationSystem:\n    def __init__(self, openai_client):\n        self.client = openai_client\n        self.moderation_log = []\n    \n    def moderate_content(self, content, user_id=None):\n        \"\"\"Moderate content and log the result\"\"\"\n        response = self.client.moderations.create(input=content)\n        result = response.results[0]\n        \n        # Log the moderation result\n        log_entry = {\n            \"timestamp\": datetime.datetime.now().isoformat(),\n            \"user_id\": user_id,\n            \"content_preview\": content[:50] + \"...\" if len(content) \u003e 50 else content,\n            \"flagged\": result.flagged,\n            \"categories\": {k: v for k, v in result.categories.items() if v},\n            \"category_scores\": {k: getattr(result.category_scores, k) for k in result.categories.__dict__ if getattr(result.categories, k)}\n        }\n        \n        self.moderation_log.append(log_entry)\n        \n        return result\n    \n    def process_user_request(self, user_id, content):\n        \"\"\"Process a user request with moderation\"\"\"\n        # First, check the content\n        moderation_result = self.moderate_content(content, user_id)\n        \n        if moderation_result.flagged:\n            # Content is flagged, determine how to handle it\n            high_severity = any(\n                getattr(moderation_result.category_scores, category) \u003e 0.8\n                for category in moderation_result.categories.__dict__\n                if getattr(moderation_result.categories, category)\n            )\n            \n            if high_severity:\n                return {\n                    \"status\": \"rejected\",\n                    \"message\": \"Your request contains content that violates our usage policies.\"\n                }\n            else:\n                return {\n                    \"status\": \"warning\",\n                    \"message\": \"Your request contains potentially inappropriate content. Please review our content guidelines.\"\n                }\n        \n        # Content passed moderation, process the request\n        try:\n            response = self.client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[{\"role\": \"user\", \"content\": content}]\n            )\n            \n            # Also moderate the response to ensure it's appropriate\n            response_text = response.choices[0].message.content\n            response_moderation = self.moderate_content(response_text, \"system\")\n            \n            if response_moderation.flagged:\n                # The AI generated inappropriate content\n                return {\n                    \"status\": \"error\",\n                    \"message\": \"We couldn't generate an appropriate response. Please try rephrasing your request.\"\n                }\n            \n            return {\n                \"status\": \"success\",\n                \"response\": response_text\n            }\n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"message\": f\"An error occurred: {str(e)}\"\n            }\n    \n    def get_moderation_stats(self):\n        \"\"\"Get statistics about moderation results\"\"\"\n        total_requests = len(self.moderation_log)\n        flagged_requests = sum(1 for entry in self.moderation_log if entry[\"flagged\"])\n        \n        category_counts = {}\n        for entry in self.moderation_log:\n            if entry[\"flagged\"]:\n                for category in entry[\"categories\"]:\n                    category_counts[category] = category_counts.get(category, 0) + 1\n        \n        return {\n            \"total_requests\": total_requests,\n            \"flagged_requests\": flagged_requests,\n            \"flagged_percentage\": (flagged_requests / total_requests * 100) if total_requests \u003e 0 else 0,\n            \"category_breakdown\": category_counts\n        }\n```\n\nIn the next section, we'll explore error handling and best practices for working with the OpenAI API.\n# Error Handling and Best Practices\n\n## Common API Errors and How to Handle Them\n\nWhen working with the OpenAI API, you'll inevitably encounter errors. Understanding these errors and implementing proper handling strategies is crucial for building robust applications.\n\n### Authentication Errors\n\nAuthentication errors occur when there are issues with your API key:\n\n```python\nimport os\nfrom openai import OpenAI, AuthenticationError\n\ndef handle_authentication_error():\n    try:\n        # Intentionally use an invalid API key\n        client = OpenAI(\n            api_key=\"invalid_key\"\n        )\n        \n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n        )\n    except AuthenticationError as e:\n        print(f\"Authentication Error: {e}\")\n        print(\"Please check your API key and ensure it's valid.\")\n        # In a production application, you might:\n        # 1. Log the error\n        # 2. Alert administrators\n        # 3. Prompt the user to re-enter credentials\n        # 4. Fall back to a non-API solution\n```\n\n### Rate Limit Errors\n\nRate limit errors occur when you exceed OpenAI's request limits:\n\n```python\nfrom openai import RateLimitError\nimport time\n\ndef handle_rate_limit_error(max_retries=5):\n    retries = 0\n    backoff_time = 1  # Start with 1 second backoff\n    \n    while retries \u003c max_retries:\n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n            )\n            return response\n        except RateLimitError as e:\n            retries += 1\n            print(f\"Rate limit exceeded. Retrying in {backoff_time} seconds... (Attempt {retries}/{max_retries})\")\n            \n            if retries == max_retries:\n                print(\"Maximum retry attempts reached. Please try again later.\")\n                raise e\n            \n            time.sleep(backoff_time)\n            backoff_time *= 2  # Exponential backoff\n```\n\n### Invalid Request Errors\n\nInvalid request errors occur when your request parameters are incorrect:\n\n```python\nfrom openai import BadRequestError\n\ndef handle_invalid_request():\n    try:\n        # Intentionally use an invalid model name\n        response = client.chat.completions.create(\n            model=\"non-existent-model\",\n            messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n        )\n    except BadRequestError as e:\n        print(f\"Invalid Request Error: {e}\")\n        \n        # Extract error details\n        error_message = str(e)\n        \n        if \"model\" in error_message.lower():\n            print(\"The specified model does not exist or is not available.\")\n            # Fall back to a known working model\n            try:\n                response = client.chat.completions.create(\n                    model=\"gpt-3.5-turbo\",  # Fallback to a reliable model\n                    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n                )\n                print(\"Successfully used fallback model.\")\n                return response\n            except Exception as fallback_error:\n                print(f\"Fallback also failed: {fallback_error}\")\n```\n\n### Server Errors\n\nServer errors occur when there's an issue on OpenAI's end:\n\n```python\nfrom openai import APIError\n\ndef handle_server_error(max_retries=3):\n    retries = 0\n    \n    while retries \u003c max_retries:\n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n            )\n            return response\n        except APIError as e:\n            retries += 1\n            wait_time = 2 ** retries  # Exponential backoff\n            \n            print(f\"API Error: {e}\")\n            print(f\"Retrying in {wait_time} seconds... (Attempt {retries}/{max_retries})\")\n            \n            if retries == max_retries:\n                print(\"Maximum retry attempts reached.\")\n                raise e\n            \n            time.sleep(wait_time)\n```\n\n### Timeout Errors\n\nTimeout errors occur when a request takes too long to complete:\n\n```python\nfrom openai import APITimeoutError\n\ndef handle_timeout_error(max_retries=3):\n    retries = 0\n    \n    while retries \u003c max_retries:\n        try:\n            # Set a shorter timeout for demonstration\n            client = OpenAI(\n                api_key=os.environ.get(\"OPENAI_API_KEY\"),\n                timeout=5.0  # 5 second timeout\n            )\n            \n            response = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[{\"role\": \"user\", \"content\": \"Write a detailed essay on quantum physics\"}]\n            )\n            return response\n        except APITimeoutError as e:\n            retries += 1\n            print(f\"Timeout Error: {e}\")\n            print(f\"Retrying... (Attempt {retries}/{max_retries})\")\n            \n            if retries == max_retries:\n                print(\"Maximum retry attempts reached.\")\n                # Consider simplifying the request or using a different approach\n                raise e\n```\n\n### Comprehensive Error Handling\n\nHere's a comprehensive approach to handling various API errors:\n\n```python\nimport os\nimport time\nimport logging\nfrom openai import OpenAI, AuthenticationError, RateLimitError, APIError, BadRequestError, APITimeoutError, APIConnectionError\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(\"openai_api.log\"),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(\"openai_api\")\n\ndef create_openai_client():\n    \"\"\"Create an OpenAI client with proper error handling\"\"\"\n    try:\n        client = OpenAI(\n            api_key=os.environ.get(\"OPENAI_API_KEY\")\n        )\n        return client\n    except Exception as e:\n        logger.error(f\"Failed to initialize OpenAI client: {e}\")\n        raise\n\ndef make_api_request(client, messages, model=\"gpt-3.5-turbo\", max_retries=3, initial_backoff=1):\n    \"\"\"Make an API request with comprehensive error handling and retries\"\"\"\n    retries = 0\n    backoff_time = initial_backoff\n    \n    while True:\n        try:\n            response = client.chat.completions.create(\n                model=model,\n                messages=messages\n            )\n            return response\n        except AuthenticationError as e:\n            logger.error(f\"Authentication Error: {e}\")\n            raise  # Authentication errors should not be retried\n        except RateLimitError as e:\n            retries += 1\n            logger.warning(f\"Rate Limit Error: {e}. Attempt {retries}/{max_retries}\")\n            \n            if retries \u003e= max_retries:\n                logger.error(\"Maximum retry attempts reached for rate limit error.\")\n                raise\n            \n            # Exponential backoff with jitter\n            jitter = random.uniform(0, 0.1 * backoff_time)\n            sleep_time = backoff_time + jitter\n            logger.info(f\"Retrying in {sleep_time:.2f} seconds...\")\n            time.sleep(sleep_time)\n            backoff_time *= 2\n        except APITimeoutError as e:\n            retries += 1\n            logger.warning(f\"Timeout Error: {e}. Attempt {retries}/{max_retries}\")\n            \n            if retries \u003e= max_retries:\n                logger.error(\"Maximum retry attempts reached for timeout error.\")\n                raise\n            \n            time.sleep(backoff_time)\n            backoff_time *= 1.5  # Slightly gentler backoff for timeouts\n        except APIConnectionError as e:\n            retries += 1\n            logger.warning(f\"Connection Error: {e}. Attempt {retries}/{max_retries}\")\n            \n            if retries \u003e= max_retries:\n                logger.error(\"Maximum retry attempts reached for connection error.\")\n                raise\n            \n            time.sleep(backoff_time)\n            backoff_time *= 2\n        except BadRequestError as e:\n            logger.error(f\"Bad Request Error: {e}\")\n            \n            # Check if it's a model error and try to fall back\n            error_message = str(e).lower()\n            if \"model\" in error_message and model != \"gpt-3.5-turbo\":\n                logger.info(f\"Attempting to fall back to gpt-3.5-turbo model\")\n                return make_api_request(client, messages, model=\"gpt-3.5-turbo\", max_retries=max_retries)\n            else:\n                raise  # Other bad requests should not be retried\n        except APIError as e:\n            retries += 1\n            logger.warning(f\"API Error: {e}. Attempt {retries}/{max_retries}\")\n            \n            if retries \u003e= max_retries:\n                logger.error(\"Maximum retry attempts reached for API error.\")\n                raise\n            \n            time.sleep(backoff_time)\n            backoff_time *= 2\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e}\")\n            raise\n```\n\n## Rate Limits and How to Work Within Them\n\nOpenAI imposes rate limits to ensure fair usage and system stability. Understanding and working within these limits is essential for reliable applications.\n\n### Understanding Rate Limits\n\nRate limits are applied at several levels:\n\n1. **Requests per Minute (RPM)**: Limits the number of API requests you can make per minute\n2. **Tokens per Minute (TPM)**: Limits the total number of tokens (input + output) processed per minute\n3. **Tier-Based Limits**: Different account tiers have different rate limits\n\n### Implementing Retry Mechanisms\n\nA robust retry mechanism is essential for handling rate limit errors:\n\n```python\nimport time\nimport random\nfrom openai import RateLimitError\n\ndef retry_with_exponential_backoff(\n    func,\n    initial_delay=1,\n    exponential_base=2,\n    jitter=True,\n    max_retries=10\n):\n    \"\"\"Retry a function with exponential backoff.\"\"\"\n    \n    def wrapper(*args, **kwargs):\n        # Initialize variables\n        num_retries = 0\n        delay = initial_delay\n        \n        # Loop until a successful response or max_retries is hit\n        while True:\n            try:\n                return func(*args, **kwargs)\n            \n            # Retry on rate limit errors\n            except RateLimitError as e:\n                # Increment retries\n                num_retries += 1\n                \n                # Check if max retries has been reached\n                if num_retries \u003e max_retries:\n                    raise Exception(f\"Maximum number of retries ({max_retries}) exceeded.\")\n                \n                # Increment the delay\n                delay *= exponential_base * (1 + jitter * random.random())\n                \n                # Sleep for the delay\n                time.sleep(delay)\n            \n            # Raise other errors\n            except Exception as e:\n                raise e\n    \n    return wrapper\n\n# Example usage\n@retry_with_exponential_backoff\ndef make_openai_request(prompt):\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n```\n\n### Batching Requests Efficiently\n\nBatching requests can help you stay within rate limits while maximizing throughput:\n\n```python\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync def process_batch(prompts, batch_size=5, delay_between_batches=1):\n    \"\"\"Process a large number of prompts in batches\"\"\"\n    client = AsyncOpenAI(\n        api_key=os.environ.get(\"OPENAI_API_KEY\")\n    )\n    \n    results = []\n    \n    # Process prompts in batches\n    for i in range(0, len(prompts), batch_size):\n        batch = prompts[i:i+batch_size]\n        batch_results = []\n        \n        # Create tasks for concurrent processing\n        tasks = [\n            process_single_prompt(client, prompt)\n            for prompt in batch\n        ]\n        \n        # Execute batch concurrently\n        batch_results = await asyncio.gather(*tasks, return_exceptions=True)\n        results.extend(batch_results)\n        \n        # Delay between batches to avoid rate limits\n        if i + batch_size \u003c len(prompts):\n            print(f\"Processed batch {i//batch_size + 1}/{(len(prompts) + batch_size - 1)//batch_size}. Waiting...\")\n            await asyncio.sleep(delay_between_batches)\n    \n    return results\n\nasync def process_single_prompt(client, prompt):\n    \"\"\"Process a single prompt with error handling\"\"\"\n    try:\n        response = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n# Example usage\nasync def main():\n    prompts = [\n        \"Write a haiku about mountains\",\n        \"Explain quantum computing\",\n        \"Write a short story about a robot\",\n        # ... more prompts\n    ]\n    \n    results = await process_batch(prompts, batch_size=3, delay_between_batches=2)\n    \n    for i, result in enumerate(results):\n        print(f\"Result {i+1}: {result}\")\n\n# Run the async function\nasyncio.run(main())\n```\n\n### Caching Strategies\n\nImplementing caching can significantly reduce API calls for repeated or similar requests:\n\n```python\nimport hashlib\nimport json\nimport redis\n\nclass OpenAICache:\n    def __init__(self, redis_url=\"redis://localhost:6379/0\", expire_time=86400):\n        \"\"\"Initialize cache with Redis backend\"\"\"\n        self.redis_client = redis.from_url(redis_url)\n        self.expire_time = expire_time  # Cache expiration in seconds (default: 24 hours)\n    \n    def _generate_cache_key(self, model, messages, temperature=None):\n        \"\"\"Generate a unique cache key based on request parameters\"\"\"\n        # Create a dictionary of the parameters that affect the response\n        cache_dict = {\n            \"model\": model,\n            \"messages\": messages,\n            \"temperature\": temperature\n        }\n        \n        # Convert to a stable string representation and hash it\n        cache_str = json.dumps(cache_dict, sort_keys=True)\n        return f\"openai:cache:{hashlib.md5(cache_str.encode()).hexdigest()}\"\n    \n    def get_cached_response(self, model, messages, temperature=None):\n        \"\"\"Get a cached response if available\"\"\"\n        cache_key = self._generate_cache_key(model, messages, temperature)\n        cached_data = self.redis_client.get(cache_key)\n        \n        if cached_data:\n            return json.loads(cached_data)\n        return None\n    \n    def cache_response(self, model, messages, response, temperature=None):\n        \"\"\"Cache a response\"\"\"\n        cache_key = self._generate_cache_key(model, messages, temperature)\n        \n        # Store only the necessary parts of the response\n        cache_data = {\n            \"choices\": response.choices,\n            \"model\": response.model,\n            \"usage\": response.usage\n        }\n        \n        self.redis_client.setex(\n            cache_key,\n            self.expire_time,\n            json.dumps(cache_data)\n        )\n\n# Example usage\ndef get_completion_with_cache(prompt, cache, model=\"gpt-3.5-turbo\", temperature=0.7):\n    \"\"\"Get a completion with caching\"\"\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    \n    # Check cache first\n    cached_response = cache.get_cached_response(model, messages, temperature)\n    if cached_response:\n        print(\"Using cached response\")\n        return cached_response[\"choices\"][0][\"message\"][\"content\"]\n    \n    # If not in cache, make API call\n    print(\"Making API call\")\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    \n    # Cache the response\n    cache.cache_response(model, messages, response, temperature)\n    \n    return response.choices[0].message.content\n```\n\n## Logging and Monitoring API Usage\n\nProper logging and monitoring are essential for tracking API usage, debugging issues, and optimizing costs.\n\n### Setting Up Comprehensive Logging\n\n```python\nimport logging\nimport time\nimport uuid\nfrom datetime import datetime\n\nclass APILogger:\n    def __init__(self, log_file=\"openai_api.log\"):\n        \"\"\"Initialize the API logger\"\"\"\n        # Configure logging\n        self.logger = logging.getLogger(\"openai_api\")\n        self.logger.setLevel(logging.INFO)\n        \n        # File handler\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setLevel(logging.INFO)\n        \n        # Console handler\n        console_handler = logging.StreamHandler()\n        console_handler.setLevel(logging.WARNING)\n        \n        # Formatter\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        file_handler.setFormatter(formatter)\n        console_handler.setFormatter(formatter)\n        \n        # Add handlers\n        self.logger.addHandler(file_handler)\n        self.logger.addHandler(console_handler)\n    \n    def log_request(self, model, messages, temperature=None, max_tokens=None):\n        \"\"\"Log an API request\"\"\"\n        request_id = str(uuid.uuid4())\n        request_time = datetime.now().isoformat()\n        \n        # Calculate input tokens (approximate)\n        input_tokens = sum(len(m[\"content\"].split()) * 1.3 for m in messages)\n        \n        log_data = {\n            \"request_id\": request_id,\n            \"timestamp\": request_time,\n            \"model\": model,\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens,\n            \"input_tokens_approx\": int(input_tokens),\n            \"messages_count\": len(messages)\n        }\n        \n        self.logger.info(f\"API Request: {json.dumps(log_data)}\")\n        return request_id\n    \n    def log_response(self, request_id, response, elapsed_time):\n        \"\"\"Log an API response\"\"\"\n        response_time = datetime.now().isoformat()\n        \n        # Extract relevant information from the response\n        if hasattr(response, \"usage\"):\n            usage = {\n                \"prompt_tokens\": response.usage.prompt_tokens,\n                \"completion_tokens\": response.usage.completion_tokens,\n                \"total_tokens\": response.usage.total_tokens\n            }\n        else:\n            usage = {\"total_tokens\": \"unknown\"}\n        \n        log_data = {\n            \"request_id\": request_id,\n            \"timestamp\": response_time,\n            \"elapsed_time_ms\": int(elapsed_time * 1000),\n            \"model\": response.model,\n            \"usage\": usage\n        }\n        \n        self.logger.info(f\"API Response: {json.dumps(log_data)}\")\n    \n    def log_error(self, request_id, error, elapsed_time):\n        \"\"\"Log an API error\"\"\"\n        error_time = datetime.now().isoformat()\n        \n        log_data = {\n            \"request_id\": request_id,\n            \"timestamp\": error_time,\n            \"elapsed_time_ms\": int(elapsed_time * 1000),\n            \"error_type\": type(error).__name__,\n            \"error_message\": str(error)\n        }\n        \n        self.logger.error(f\"API Error: {json.dumps(log_data)}\")\n\n# Example usage\ndef make_api_call_with_logging(prompt, model=\"gpt-3.5-turbo\"):\n    \"\"\"Make an API call with comprehensive logging\"\"\"\n    api_logger = APILogger()\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    \n    # Log the request\n    request_id = api_logger.log_request(model, messages)\n    start_time = time.time()\n    \n    try:\n        # Make the API call\n        response = client.chat.completions.create(\n            model=model,\n            messages=messages\n        )\n        \n        # Calculate elapsed time\n        elapsed_time = time.time() - start_time\n        \n        # Log the response\n        api_logger.log_response(request_id, response, elapsed_time)\n        \n        return response.choices[0].message.content\n    except Exception as e:\n        # Calculate elapsed time\n        elapsed_time = time.time() - start_time\n        \n        # Log the error\n        api_logger.log_error(request_id, e, elapsed_time)\n        \n        # Re-raise the exception\n        raise\n```\n\n### Monitoring API Usage\n\nImplementing a dashboard for monitoring API usage can help you track costs and optimize usage:\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport json\n\nclass APIUsageMonitor:\n    def __init__(self, log_file=\"openai_api.log\"):\n        \"\"\"Initialize the API usage monitor\"\"\"\n        self.log_file = log_file\n    \n    def parse_logs(self, days=7):\n        \"\"\"Parse the log file and extract API usage data\"\"\"\n        # Calculate the cutoff date\n        cutoff_date = datetime.now() - timedelta(days=days)\n        \n        requests = []\n        responses = []\n        errors = []\n        \n        with open(self.log_file, \"r\") as f:\n            for line in f:\n                try:\n                    # Parse the log line\n                    parts = line.strip().split(\" - \")\n                    timestamp_str = parts[0]\n                    log_type = parts[2]\n                    log_data_str = \" - \".join(parts[3:])\n                    \n                    # Parse the timestamp\n                    timestamp = datetime.fromisoformat(timestamp_str.split(\",\")[0])\n                    \n                    # Skip entries before the cutoff date\n                    if timestamp \u003c cutoff_date:\n                        continue\n                    \n                    # Extract the JSON data\n                    if \"API Request\" in log_data_str:\n                        data = json.loads(log_data_str.replace(\"API Request: \", \"\"))\n                        requests.append(data)\n                    elif \"API Response\" in log_data_str:\n                        data = json.loads(log_data_str.replace(\"API Response: \", \"\"))\n                        responses.append(data)\n                    elif \"API Error\" in log_data_str:\n                        data = json.loads(log_data_str.replace(\"API Error: \", \"\"))\n                        errors.append(data)\n                except Exception as e:\n                    # Skip malformed log lines\n                    continue\n        \n        return {\n            \"requests\": requests,\n            \"responses\": responses,\n            \"errors\": errors\n        }\n    \n    def generate_usage_report(self, days=7):\n        \"\"\"Generate a usage report for the specified number of days\"\"\"\n        data = self.parse_logs(days)\n        \n        # Create DataFrames\n        requests_df = pd.DataFrame(data[\"requests\"])\n        responses_df = pd.DataFrame(data[\"responses\"])\n        errors_df = pd.DataFrame(data[\"errors\"])\n        \n        # Merge request and response data\n        if not responses_df.empty and not requests_df.empty:\n            merged_df = pd.merge(\n                requests_df,\n                responses_df,\n                on=\"request_id\",\n                suffixes=(\"_req\", \"_resp\")\n            )\n            \n            # Calculate daily token usage\n            merged_df[\"date\"] = pd.to_datetime(merged_df[\"timestamp_req\"]).dt.date\n            daily_usage = merged_df.groupby(\"date\").agg({\n                \"usage.total_tokens\": \"sum\",\n                \"request_id\": \"count\"\n            }).rename(columns={\n                \"usage.total_tokens\": \"total_tokens\",\n                \"request_id\": \"request_count\"\n            })\n            \n            # Calculate model usage\n            model_usage = merged_df.groupby(\"model_req\").agg({\n                \"usage.total_tokens\": \"sum\",\n                \"request_id\": \"count\"\n            }).rename(columns={\n                \"usage.total_tokens\": \"total_tokens\",\n                \"request_id\": \"request_count\"\n            })\n            \n            # Calculate error rate\n            total_requests = len(requests_df)\n            total_errors = len(errors_df)\n            error_rate = total_errors / total_requests if total_requests \u003e 0 else 0\n            \n            # Calculate average response time\n            avg_response_time = merged_df[\"elapsed_time_ms\"].mean() if \"elapsed_time_ms\" in merged_df.columns else 0\n            \n            # Estimate cost (approximate)\n            cost_per_1k_tokens = {\n                \"gpt-4o\": 0.01,  # $10 per 1M tokens\n                \"gpt-4\": 0.03,   # $30 per 1M tokens\n                \"gpt-3.5-turbo\": 0.001  # $1 per 1M tokens\n            }\n            \n            merged_df[\"cost\"] = merged_df.apply(\n                lambda row: (row[\"usage.total_tokens\"] / 1000) * cost_per_1k_tokens.get(row[\"model_req\"], 0.01),\n                axis=1\n            )\n            \n            total_cost = merged_df[\"cost\"].sum()\n            \n            return {\n                \"daily_usage\": daily_usage,\n                \"model_usage\": model_usage,\n                \"total_requests\": total_requests,\n                \"total_errors\": total_errors,\n                \"error_rate\": error_rate,\n                \"avg_response_time\": avg_response_time,\n                \"total_tokens\": merged_df[\"usage.total_tokens\"].sum(),\n                \"estimated_cost\": total_cost\n            }\n        else:\n            return {\n                \"error\": \"No data available for the specified period\"\n            }\n    \n    def plot_usage_trends(self, days=30):\n        \"\"\"Plot usage trends for the specified number of days\"\"\"\n        report = self.generate_usage_report(days)\n        \n        if \"error\" in report:\n            print(report[\"error\"])\n            return\n        \n        # Create a figure with subplots\n        fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n        \n        # Plot daily token usage\n        report[\"daily_usage\"][\"total_tokens\"].plot(\n            kind=\"bar\",\n            ax=axs[0, 0],\n            title=\"Daily Token Usage\"\n        )\n        axs[0, 0].set_ylabel(\"Tokens\")\n        axs[0, 0].set_xlabel(\"Date\")\n        \n        # Plot daily request count\n        report[\"daily_usage\"][\"request_count\"].plot(\n            kind=\"bar\",\n            ax=axs[0, 1],\n            title=\"Daily Request Count\"\n        )\n        axs[0, 1].set_ylabel(\"Requests\")\n        axs[0, 1].set_xlabel(\"Date\")\n        \n        # Plot model usage (tokens)\n        report[\"model_usage\"][\"total_tokens\"].plot(\n            kind=\"pie\",\n            ax=axs[1, 0],\n            title=\"Token Usage by Model\",\n            autopct=\"%1.1f%%\"\n        )\n        \n        # Plot model usage (requests)\n        report[\"model_usage\"][\"request_count\"].plot(\n            kind=\"pie\",\n            ax=axs[1, 1],\n            title=\"Request Count by Model\",\n            autopct=\"%1.1f%%\"\n        )\n        \n        # Add a title to the figure\n        fig.suptitle(f\"OpenAI API Usage Report (Last {days} Days)\", fontsize=16)\n        \n        # Adjust layout\n        plt.tight_layout()\n        plt.subplots_adjust(top=0.9)\n        \n        # Save the figure\n        plt.savefig(\"api_usage_report.png\")\n        \n        # Print summary statistics\n        print(f\"Summary Statistics (Last {days} Days):\")\n        print(f\"Total Requests: {report['total_requests']}\")\n        print(f\"Total Tokens: {report['total_tokens']}\")\n        print(f\"Error Rate: {report['error_rate']*100:.2f}%\")\n        print(f\"Average Response Time: {report['avg_response_time']:.2f} ms\")\n        print(f\"Estimated Cost: ${report['estimated_cost']:.2f}\")\n        \n        return \"api_usage_report.png\"\n```\n\n## Security Best Practices\n\nImplementing proper security measures is crucial when working with the OpenAI API.\n\n### API Key Management\n\n```python\nimport os\nfrom dotenv import load_dotenv\nimport keyring\n\nclass APIKeyManager:\n    def __init__(self, service_name=\"openai-api\"):\n        \"\"\"Initialize the API key manager\"\"\"\n        self.service_name = service_name\n    \n    def store_api_key(self, key, username=\"default\"):\n        \"\"\"Store the API key securely\"\"\"\n        keyring.set_password(self.service_name, username, key)\n        print(f\"API key stored securely for user '{username}'\")\n    \n    def get_api_key(self, username=\"default\"):\n        \"\"\"Retrieve the API key\"\"\"\n        key = keyring.get_password(self.service_name, username)\n        if not key:\n            raise ValueError(f\"No API key found for user '{username}'\")\n        return key\n    \n    def delete_api_key(self, username=\"default\"):\n        \"\"\"Delete the stored API key\"\"\"\n        keyring.delete_password(self.service_name, username)\n        print(f\"API key deleted for user '{username}'\")\n\n# Example usage\ndef setup_secure_client():\n    \"\"\"Set up a secure OpenAI client\"\"\"\n    # Try to get the API key from environment variables first\n    api_key = os.environ.get(\"OPENAI_API_KEY\")\n    \n    # If not found, try to get it from the secure storage\n    if not api_key:\n        try:\n            key_manager = APIKeyManager()\n            api_key = key_manager.get_api_key()\n        except Exception as e:\n            print(f\"Error retrieving API key: {e}\")\n            # Prompt the user for the API key\n            api_key = input(\"Please enter your OpenAI API key: \")\n            \n            # Ask if they want to store it securely\n            store_key = input(\"Do you want to store this key securely? (y/n): \").lower()\n            if store_key == \"y\":\n                key_manager = APIKeyManager()\n                key_manager.store_api_key(api_key)\n    \n    # Create the client with the API key\n    client = OpenAI(api_key=api_key)\n    return client\n```\n\n### Request Validation\n\nImplementing request validation can prevent security issues and improve reliability:\n\n```python\nimport re\nimport json\n\nclass RequestValidator:\n    def __init__(self):\n        \"\"\"Initialize the request validator\"\"\"\n        # Define validation rules\n        self.max_prompt_length = 4000\n        self.allowed_models = [\"gpt-4o\", \"gpt-4\", \"gpt-3.5-turbo\"]\n        self.sensitive_pattern = re.compile(\n            r'(password|api[_\\s]?key|secret|token|credential|auth[_\\s]?token)',\n            re.IGNORECASE\n        )\n    \n    def validate_prompt(self, prompt):\n        \"\"\"Validate a prompt for security and quality issues\"\"\"\n        issues = []\n        \n        # Check length\n        if len(prompt) \u003e self.max_prompt_length:\n            issues.append(f\"Prompt exceeds maximum length of {self.max_prompt_length} characters\")\n        \n        # Check for sensitive information\n        if self.sensitive_pattern.search(prompt):\n            issues.append(\"Prompt may contain sensitive information (passwords, API keys, etc.)\")\n        \n        # Check for excessive special characters (potential injection)\n        special_char_count = sum(1 for c in prompt if not c.isalnum() and not c.isspace())\n        if special_char_count \u003e len(prompt) * 0.3:\n            issues.append(\"Prompt contains an unusually high number of special characters\")\n        \n        return {\n            \"valid\": len(issues) == 0,\n            \"issues\": issues\n        }\n    \n    def validate_model(self, model):\n        \"\"\"Validate that the requested model is allowed\"\"\"\n        if model not in self.allowed_models:\n            return {\n                \"valid\": False,\n                \"issues\": [f\"Model '{model}' is not in the list of allowed models\"]\n            }\n        return {\"valid\": True, \"issues\": []}\n    \n    def validate_request(self, model, messages, temperature=None, max_tokens=None):\n        \"\"\"Validate a complete API request\"\"\"\n        issues = []\n        \n        # Validate model\n        model_validation = self.validate_model(model)\n        if not model_validation[\"valid\"]:\n            issues.extend(model_validation[\"issues\"])\n        \n        # Validate each message\n        for i, message in enumerate(messages):\n            if \"content\" in message and message[\"content\"]:\n                prompt_validation = self.validate_prompt(message[\"content\"])\n                if not prompt_validation[\"valid\"]:\n                    for issue in prompt_validation[\"issues\"]:\n                        issues.append(f\"Message {i+1}: {issue}\")\n        \n        # Validate temperature\n        if temperature is not None and (temperature \u003c 0 or temperature \u003e 2):\n            issues.append(\"Temperature must be between 0 and 2\")\n        \n        # Validate max_tokens\n        if max_tokens is not None and max_tokens \u003c 1:\n            issues.append(\"max_tokens must be at least 1\")\n        \n        return {\n            \"valid\": len(issues) == 0,\n            \"issues\": issues\n        }\n\n# Example usage\ndef make_validated_request(prompt, model=\"gpt-3.5-turbo\", temperature=0.7):\n    \"\"\"Make a validated API request\"\"\"\n    validator = RequestValidator()\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    \n    # Validate the request\n    validation_result = validator.validate_request(model, messages, temperature)\n    \n    if not validation_result[\"valid\"]:\n        print(\"Request validation failed:\")\n        for issue in validation_result[\"issues\"]:\n            print(f\"- {issue}\")\n        return None\n    \n    # Make the API call\n    try:\n        response = client.chat.completions.create(\n            model=model,\n            messages=messages,\n            temperature=temperature\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        print(f\"API request failed: {e}\")\n        return None\n```\n\n### Secure Proxy Implementation\n\nFor applications where clients need to access the API, implementing a secure proxy is recommended:\n\n```python\nfrom flask import Flask, request, jsonify\nimport jwt\nimport datetime\n\napp = Flask(__name__)\napp.config[\"SECRET_KEY\"] = \"your-secret-key\"  # Use a secure random key in production\n\n# OpenAI client\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n\n# User authentication (simplified for example)\n@app.route(\"/api/login\", methods=[\"POST\"])\ndef login():\n    # In a real application, validate credentials against a database\n    username = request.json.get(\"username\")\n    password = request.json.get(\"password\")\n    \n    # Simplified authentication\n    if username == \"demo\" and password == \"password\":\n        # Generate JWT token\n        token = jwt.encode(\n            {\n                \"user\": username,\n                \"exp\": datetime.datetime.utcnow() + datetime.timedelta(hours=1)\n            },\n            app.config[\"SECRET_KEY\"],\n            algorithm=\"HS256\"\n        )\n        \n        return jsonify({\"token\": token})\n    \n    return jsonify({\"error\": \"Invalid credentials\"}), 401\n\n# Middleware to verify JWT token\ndef token_required(f):\n    def decorated(*args, **kwargs):\n        token = request.headers.get(\"Authorization\")\n        \n        if not token:\n            return jsonify({\"error\": \"Token is missing\"}), 401\n        \n        try:\n            # Remove \"Bearer \" prefix if present\n            if token.startswith(\"Bearer \"):\n                token = token[7:]\n            \n            # Decode the token\n            data = jwt.decode(token, app.config[\"SECRET_KEY\"], algorithms=[\"HS256\"])\n        except:\n            return jsonify({\"error\": \"Invalid token\"}), 401\n        \n        return f(*args, **kwargs)\n    \n    return decorated\n\n# OpenAI API proxy endpoint\n@app.route(\"/api/openai/chat\", methods=[\"POST\"])\n@token_required\ndef openai_chat_proxy():\n    # Get request data\n    data = request.json\n    \n    # Validate required fields\n    if \"messages\" not in data:\n        return jsonify({\"error\": \"Messages are required\"}), 400\n    \n    # Set default values for optional parameters\n    model = data.get(\"model\", \"gpt-3.5-turbo\")\n    temperature = data.get(\"temperature\", 0.7)\n    max_tokens = data.get(\"max_tokens\", None)\n    \n    # Validate the request\n    validator = RequestValidator()\n    validation_result = validator.validate_request(\n        model, data[\"messages\"], temperature, max_tokens\n    )\n    \n    if not validation_result[\"valid\"]:\n        return jsonify({\n            \"error\": \"Validation failed\",\n            \"issues\": validation_result[\"issues\"]\n        }), 400\n    \n    # Make the API call\n    try:\n        response = client.chat.completions.create(\n            model=model,\n            messages=data[\"messages\"],\n            temperature=temperature,\n            max_tokens=max_tokens\n        )\n        \n        # Return the response\n        return jsonify({\n            \"content\": response.choices[0].message.content,\n            \"usage\": {\n                \"prompt_tokens\": response.usage.prompt_tokens,\n                \"completion_tokens\": response.usage.completion_tokens,\n                \"total_tokens\": response.usage.total_tokens\n            }\n        })\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n```\n\nIn the next section, we'll explore performance optimization techniques for working with the OpenAI API.\n# Performance Optimization Techniques\n\n## Prompt Engineering for Efficiency\n\nEffective prompt engineering can significantly improve the performance and efficiency of your OpenAI API usage.\n\n### Designing Clear and Concise Prompts\n\nWell-designed prompts lead to better responses while using fewer tokens:\n\n```python\n# Less efficient prompt\ninefficient_prompt = \"\"\"\nI need you to summarize a text about climate change. The text is quite long and contains a lot of information about global warming, rising sea levels, and the impact on ecosystems. I want you to make sure you capture all the key points while keeping the summary concise. Please make sure to mention the causes of climate change, the effects, and potential solutions. The text is as follows:\n\n[Long text about climate change...]\n\"\"\"\n\n# More efficient prompt\nefficient_prompt = \"\"\"\nSummarize the following text about climate change, covering causes, effects, and solutions:\n\n[Long text about climate change...]\n\"\"\"\n\n# The efficient prompt communicates the same requirements with fewer tokens\n```\n\n### Using System Messages Effectively\n\nSystem messages can set the stage for the entire conversation, reducing the need for repetitive instructions:\n\n```python\n# Example of effective system message usage\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\n            \"role\": \"system\", \n            \"content\": \"You are a technical documentation writer. Provide concise, accurate explanations with code examples when relevant. Use markdown formatting.\"\n        },\n        {\n            \"role\": \"user\", \n            \"content\": \"Explain how to implement pagination in a REST API.\"\n        }\n    ]\n)\n```\n\n### Structuring Multi-turn Conversations\n\nFor multi-turn conversations, maintain context efficiently:\n\n```python\ndef efficient_conversation():\n    # Initialize with a clear system message\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant that provides concise, accurate information.\"\n        }\n    ]\n    \n    while True:\n        user_input = input(\"You: \")\n        \n        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n            break\n        \n        # Add user message\n        messages.append({\"role\": \"user\", \"content\": user_input})\n        \n        # Get response\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=messages\n        )\n        \n        assistant_message = response.choices[0].message.content\n        print(f\"Assistant: {assistant_message}\")\n        \n        # Add assistant message to history\n        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n        \n        # Manage context window by summarizing or truncating when needed\n        if len(messages) \u003e 10:\n            # Summarize the conversation so far\n            summary_request = [\n                {\"role\": \"system\", \"content\": \"Summarize the key points of this conversation concisely.\"},\n                {\"role\": \"user\", \"content\": str(messages[1:-2])}  # Exclude system message and recent exchanges\n            ]\n            \n            summary_response = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=summary_request\n            )\n            \n            summary = summary_response.choices[0].message.content\n            \n            # Reset the conversation with the summary\n            messages = [\n                messages[0],  # Keep the original system message\n                {\"role\": \"system\", \"content\": f\"Previous conversation summary: {summary}\"},\n                messages[-2],  # Keep the last user message\n                messages[-1]   # Keep the last assistant message\n            ]\n```\n\n## Token Optimization Strategies\n\nOptimizing token usage can significantly reduce costs and improve performance.\n\n### Token Counting and Budgeting\n\n```python\nimport tiktoken\n\ndef count_tokens(text, model=\"gpt-4o\"):\n    \"\"\"Count the number of tokens in a text string.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    tokens = encoding.encode(text)\n    return len(tokens)\n\ndef count_message_tokens(messages, model=\"gpt-4o\"):\n    \"\"\"Count the number of tokens in a list of messages.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    \n    # From OpenAI's documentation on token counting\n    tokens_per_message = 3  # Every message follows \u003cim_start\u003e{role/name}\\n{content}\u003cim_end\u003e\\n\n    tokens_per_name = 1     # If there's a name, the role is omitted\n    \n    total_tokens = 0\n    for message in messages:\n        total_tokens += tokens_per_message\n        for key, value in message.items():\n            total_tokens += len(encoding.encode(value))\n            if key == \"name\":\n                total_tokens += tokens_per_name\n    \n    total_tokens += 3  # Every reply is primed with \u003cim_start\u003eassistant\n    \n    return total_tokens\n\ndef optimize_within_token_budget(messages, max_tokens=4000, model=\"gpt-4o\"):\n    \"\"\"Optimize messages to fit within a token budget.\"\"\"\n    current_tokens = count_message_tokens(messages, model)\n    \n    if current_tokens \u003c= max_tokens:\n        return messages\n    \n    # We need to reduce the token count\n    # Strategy: Keep system message, recent messages, and summarize older messages\n    \n    system_messages = [m for m in messages if m[\"role\"] == \"system\"]\n    non_system_messages = [m for m in messages if m[\"role\"] != \"system\"]\n    \n    # If we have too many messages, summarize the older ones\n    if len(non_system_messages) \u003e 4:\n        # Keep the most recent messages\n        recent_messages = non_system_messages[-4:]\n        older_messages = non_system_messages[:-4]\n        \n        # Create a summary of older messages\n        older_content = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in older_messages])\n        \n        summary_request = [\n            {\"role\": \"system\", \"content\": \"Summarize the following conversation extremely concisely:\"},\n            {\"role\": \"user\", \"content\": older_content}\n        ]\n        \n        summary_response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",  # Use a cheaper model for summarization\n            messages=summary_request,\n            max_tokens=200  # Limit the summary size\n        )\n        \n        summary = summary_response.choices[0].message.content\n        \n        # Replace older messages with a summary\n        optimized_messages = system_messages + [{\"role\": \"system\", \"content\": f\"Previous conversation summary: {summary}\"}] + recent_messages\n        \n        # Check if we're now within budget\n        if count_message_tokens(optimized_messages, model) \u003c= max_tokens:\n            return optimized_messages\n    \n    # If we're still over budget, truncate content\n    # Start with the oldest non-system messages\n    optimized_messages = system_messages.copy()\n    remaining_budget = max_tokens - count_message_tokens(optimized_messages, model)\n    \n    for message in non_system_messages:\n        message_tokens = count_tokens(message[\"content\"], model) + 4  # 4 tokens for message metadata\n        \n        if message_tokens \u003c= remaining_budget:\n            # Message fits within budget\n            optimized_messages.append(message)\n            remaining_budget -= message_tokens\n        else:\n            # Message needs truncation\n            encoding = tiktoken.encoding_for_model(model)\n            truncated_content = encoding.decode(encoding.encode(message[\"content\"])[:remaining_budget - 5])\n            truncated_message = {\n                \"role\": message[\"role\"],\n                \"content\": truncated_content + \"...\"\n            }\n            optimized_messages.append(truncated_message)\n            break\n    \n    return optimized_messages\n```\n\n### Chunking Large Documents\n\nWhen working with large documents, chunking can help manage token limits:\n\n```python\ndef process_large_document(document, chunk_size=2000, overlap=200):\n    \"\"\"Process a large document by breaking it into overlapping chunks.\"\"\"\n    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n    tokens = encoding.encode(document)\n    \n    results = []\n    \n    # Process document in chunks\n    for i in range(0, len(tokens), chunk_size - overlap):\n        # Get chunk with overlap\n        chunk_tokens = tokens[i:i + chunk_size]\n        chunk_text = encoding.decode(chunk_tokens)\n        \n        # Process the chunk\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are processing part of a larger document. Focus on extracting key information.\"},\n                {\"role\": \"user\", \"content\": f\"Process the following text (chunk {i // (chunk_size - overlap) + 1}):\\n\\n{chunk_text}\"}\n            ]\n        )\n        \n        results.append(response.choices[0].message.content)\n    \n    # Combine results\n    combined_response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are combining information from multiple document chunks. Create a coherent synthesis.\"},\n            {\"role\": \"user\", \"content\": f\"Combine these document processing results into a coherent whole:\\n\\n{results}\"}\n        ]\n    )\n    \n    return combined_response.choices[0].message.content\n```\n\n### Compression Techniques\n\nFor applications that need to maintain long conversation histories, compression can help:\n\n```python\ndef compress_conversation_history(messages):\n    \"\"\"Compress a conversation history to reduce token usage.\"\"\"\n    # Extract system messages\n    system_messages = [m for m in messages if m[\"role\"] == \"system\"]\n    \n    # Get non-system messages\n    conversation = [m for m in messages if m[\"role\"] != \"system\"]\n    \n    # If conversation is short, no need to compress\n    if len(conversation) \u003c= 4:\n        return messages\n    \n    # Prepare conversation for compression\n    conversation_text = \"\\n\\n\".join([\n        f\"{m['role'].upper()}: {m['content']}\"\n        for m in conversation\n    ])\n    \n    # Compress the conversation\n    compression_response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"system\", \n                \"content\": \"Compress the following conversation into a minimal form that preserves all important information and context. Focus on key points, decisions, and information shared.\"\n            },\n            {\"role\": \"user\", \"content\": conversation_text}\n        ]\n    )\n    \n    compressed_conversation = compression_response.choices[0].message.content\n    \n    # Create a new message list with the compressed history\n    compressed_messages = system_messages + [\n        {\"role\": \"system\", \"content\": f\"Compressed conversation history: {compressed_conversation}\"},\n        # Keep the most recent user message for context\n        conversation[-1]\n    ]\n    \n    return compressed_messages\n```\n\n## Parallel Processing and Batching\n\nFor applications that need to process multiple requests, parallel processing and batching can improve throughput.\n\n### Asynchronous Processing\n\n```python\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync def process_multiple_prompts(prompts, model=\"gpt-3.5-turbo\"):\n    \"\"\"Process multiple prompts in parallel using async.\"\"\"\n    client = AsyncOpenAI(\n        api_key=os.environ.get(\"OPENAI_API_KEY\")\n    )\n    \n    async def process_single_prompt(prompt):\n        try:\n            response = await client.chat.completions.create(\n                model=model,\n                messages=[{\"role\": \"user\", \"content\": prompt}]\n            )\n            return response.choices[0].message.content\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n    \n    # Create tasks for all prompts\n    tasks = [process_single_prompt(prompt) for prompt in prompts]\n    \n    # Execute all tasks concurrently\n    results = await asyncio.gather(*tasks)\n    \n    return results\n\n# Example usage\nasync def main():\n    prompts = [\n        \"Explain quantum computing in simple terms.\",\n        \"Write a short poem about the ocean.\",\n        \"What are the key features of Python?\",\n        \"Describe the process of photosynthesis.\",\n        \"What is the capital of France and some interesting facts about it?\"\n    ]\n    \n    results = await process_multiple_prompts(prompts)\n    \n    for i, result in enumerate(results):\n        print(f\"Result {i+1}:\\n{result}\\n\")\n\n# Run the async function\nasyncio.run(main())\n```\n\n### Controlled Concurrency\n\nTo avoid rate limits, implement controlled concurrency:\n\n```python\nimport asyncio\nfrom openai import AsyncOpenAI\nimport time\n\nasync def process_with_controlled_concurrency(prompts, max_concurrency=5, model=\"gpt-3.5-turbo\"):\n    \"\"\"Process prompts with controlled concurrency to avoid rate limits.\"\"\"\n    client = AsyncOpenAI(\n        api_key=os.environ.get(\"OPENAI_API_KEY\")\n    )\n    \n    # Semaphore to control concurrency\n    semaphore = asyncio.Semaphore(max_concurrency)\n    \n    async def process_with_semaphore(prompt):\n        async with semaphore:\n            try:\n                response = await client.chat.completions.create(\n                    model=model,\n                    messages=[{\"role\": \"user\", \"content\": prompt}]\n                )\n                return response.choices[0].message.content\n            except Exception as e:\n                return f\"Error: {str(e)}\"\n            finally:\n                # Add a small delay to avoid hitting rate limits\n                await asyncio.sleep(0.1)\n    \n    # Create tasks for all prompts\n    tasks = [process_with_semaphore(prompt) for prompt in prompts]\n    \n    # Execute tasks with controlled concurrency\n    results = await asyncio.gather(*tasks)\n    \n    return results\n```\n\n### Batch Processing with Progress Tracking\n\nFor large batches, implement progress tracking:\n\n```python\nimport asyncio\nimport time\nfrom tqdm import tqdm\n\nasync def batch_process_with_progress(prompts, batch_size=10, max_concurrency=5, model=\"gpt-3.5-turbo\"):\n    \"\"\"Process a large batch of prompts with progress tracking.\"\"\"\n    client = AsyncOpenAI(\n        api_key=os.environ.get(\"OPENAI_API_KEY\")\n    )\n    \n    # Semaphore to control concurrency\n    semaphore = asyncio.Semaphore(max_concurrency)\n    \n    # Results container\n    results = [None] * len(prompts)\n    \n    # Progress bar\n    pbar = tqdm(total=len(prompts), desc=\"Processing prompts\")\n    \n    async def process_prompt(index, prompt):\n        async with semaphore:\n            try:\n                response = await client.chat.completions.create(\n                    model=model,\n                    messages=[{\"role\": \"user\", \"content\": prompt}]\n                )\n                results[index] = response.choices[0].message.content\n            except Exception as e:\n                results[index] = f\"Error: {str(e)}\"\n            finally:\n                pbar.update(1)\n                # Add a small delay to avoid hitting rate limits\n                await asyncio.sleep(0.1)\n    \n    # Process in batches\n    for i in range(0, len(prompts), batch_size):\n        batch = prompts[i:i + batch_size]\n        \n        # Create tasks for the current batch\n        tasks = [\n            process_prompt(i + j, prompt)\n            for j, prompt in enumerate(batch)\n        ]\n        \n        # Execute batch\n        await asyncio.gather(*tasks)\n        \n        # Add a delay between batches\n        if i + batch_size \u003c len(prompts):\n            await asyncio.sleep(1)\n    \n    pbar.close()\n    return results\n```\n\n## Implementing Fallback Mechanisms\n\nRobust applications need fallback mechanisms to handle various failure scenarios.\n\n### Model Fallback Chain\n\n```python\ndef model_fallback_chain(prompt, models=None):\n    \"\"\"Try multiple models in sequence until one succeeds.\"\"\"\n    if models is None:\n        models = [\"gpt-4o\", \"gpt-4\", \"gpt-3.5-turbo\"]\n    \n    last_error = None\n    \n    for model in models:\n        try:\n            response = client.chat.completions.create(\n                model=model,\n                messages=[{\"role\": \"user\", \"content\": prompt}]\n            )\n            \n            # If successful, return the result and the model used\n            return {\n                \"content\": response.choices[0].message.content,\n                \"model\": model,\n                \"success\": True\n            }\n        except Exception as e:\n            last_error = str(e)\n            print(f\"Error with model {model}: {last_error}\")\n            continue\n    \n    # If all models fail, return the error\n    return {\n        \"content\": None,\n        \"model\": None,\n        \"success\": False,\n        \"error\": last_error\n    }\n```\n\n### Content Fallback Strategies\n\n```python\ndef content_fallback_strategy(prompt, max_attempts=3):\n    \"\"\"Try different prompt formulations if initial attempts fail.\"\"\"\n    # Original attempt\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        return response.choices[0].message.content\n    except Exception as original_error:\n        print(f\"Original attempt failed: {str(original_error)}\")\n    \n    # Fallback 1: Simplify the prompt\n    try:\n        simplified_prompt = f\"Please answer this question simply: {prompt}\"\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": simplified_prompt}]\n        )\n        return response.choices[0].message.content\n    except Exception as fallback1_error:\n        print(f\"Simplified prompt failed: {str(fallback1_error)}\")\n    \n    # Fallback 2: Break into smaller parts\n    try:\n        # This is a simplified example; in practice, you would use NLP to break the prompt\n        parts = prompt.split(\". \")\n        results = []\n        \n        for part in parts:\n            if part:\n                response = client.chat.completions.create(\n                    model=\"gpt-3.5-turbo\",\n                    messages=[{\"role\": \"user\", \"content\": part}]\n                )\n                results.append(response.choices[0].message.content)\n        \n        # Combine the results\n        combined_response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"user\", \"content\": f\"Combine these responses into a coherent answer: {results}\"}\n            ]\n        )\n        \n        return combined_response.choices[0].message.content\n    except Exception as fallback2_error:\n        print(f\"Breaking into parts failed: {str(fallback2_error)}\")\n    \n    # Final fallback: Return a generic response\n    return \"I'm sorry, I couldn't process your request at this time. Please try again later or rephrase your question.\"\n```\n\n### Hybrid Approaches\n\nFor critical applications, consider hybrid approaches that combine AI with traditional methods:\n\n```python\ndef hybrid_question_answering(question, knowledge_base=None):\n    \"\"\"Hybrid approach combining retrieval and generation.\"\"\"\n    # Step 1: Try to find an answer in the knowledge base\n    if knowledge_base:\n        kb_answer = search_knowledge_base(question, knowledge_base)\n        if kb_answer:\n            return {\n                \"answer\": kb_answer,\n                \"source\": \"knowledge_base\",\n                \"confidence\": \"high\"\n            }\n    \n    # Step 2: Try the OpenAI API\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[{\"role\": \"user\", \"content\": question}]\n        )\n        \n        return {\n            \"answer\": response.choices[0].message.content,\n            \"source\": \"openai_api\",\n            \"confidence\": \"medium\"\n        }\n    except Exception as e:\n        print(f\"API error: {str(e)}\")\n    \n    # Step 3: Fall back to a rule-based system\n    rule_based_answer = rule_based_qa_system(question)\n    if rule_based_answer:\n        return {\n            \"answer\": rule_based_answer,\n            \"source\": \"rule_based\",\n            \"confidence\": \"medium\"\n        }\n    \n    # Step 4: Final fallback\n    return {\n        \"answer\": \"I don't have enough information to answer that question at this time.\",\n        \"source\": \"fallback\",\n        \"confidence\": \"low\"\n    }\n\ndef search_knowledge_base(question, knowledge_base):\n    \"\"\"Search a knowledge base for an answer (simplified example).\"\"\"\n    # In a real implementation, this would use vector search or another retrieval method\n    for entry in knowledge_base:\n        if question.lower() in entry[\"question\"].lower():\n            return entry[\"answer\"]\n    return None\n\ndef rule_based_qa_system(question):\n    \"\"\"Simple rule-based QA system as a fallback.\"\"\"\n    # Simplified example with a few rules\n    question_lower = question.lower()\n    \n    if \"hours\" in question_lower and \"open\" in question_lower:\n        return \"Our hours of operation are Monday to Friday, 9 AM to 5 PM.\"\n    \n    if \"contact\" in question_lower or \"support\" in question_lower:\n        return \"You can contact our support team at support@example.com or call 1-800-555-1234.\"\n    \n    if \"price\" in question_lower or \"cost\" in question_lower:\n        return \"Our pricing information can be found on our website at example.com/pricing.\"\n    \n    return None\n```\n\n## Cost Optimization Strategies\n\nImplementing cost optimization strategies can help manage your OpenAI API expenses.\n\n### Tiered Model Selection\n\n```python\ndef tiered_model_selection(prompt, complexity_threshold=0.5):\n    \"\"\"Select the appropriate model based on prompt complexity.\"\"\"\n    # Analyze prompt complexity (simplified example)\n    words = prompt.split()\n    avg_word_length = sum(len(word) for word in words) / len(words) if words else 0\n    sentence_count = prompt.count(\".\") + prompt.count(\"!\") + prompt.count(\"?\")\n    avg_sentence_length = len(words) / sentence_count if sentence_count \u003e 0 else len(words)\n    \n    # Calculate complexity score (simplified)\n    complexity_score = (avg_word_length / 10) + (avg_sentence_length / 20)\n    \n    # Select model based on complexity\n    if complexity_score \u003e complexity_threshold:\n        # More complex prompts get the more capable model\n        model = \"gpt-4o\"\n    else:\n        # Simpler prompts get the more economical model\n        model = \"gpt-3.5-turbo\"\n    \n    print(f\"Prompt complexity: {complexity_score:.2f}, using model: {model}\")\n    \n    # Make the API call with the selected model\n    response = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    return response.choices[0].message.content\n```\n\n### Usage Monitoring and Budgeting\n\n```python\nclass APIBudgetManager:\n    def __init__(self, daily_budget=10.0):\n        \"\"\"Initialize the budget manager with a daily budget in USD.\"\"\"\n        self.daily_budget = daily_budget\n        self.usage_log = []\n        self.today = datetime.datetime.now().date()\n        \n        # Approximate costs per 1K tokens (check OpenAI's pricing page for current rates)\n        self.cost_per_1k_tokens = {\n            \"gpt-4o\": 0.01,  # $10 per 1M tokens\n            \"gpt-4\": 0.03,   # $30 per 1M tokens\n            \"gpt-3.5-turbo\": 0.001  # $1 per 1M tokens\n        }\n    \n    def log_usage(self, model, prompt_tokens, completion_tokens):\n        \"\"\"Log API usage.\"\"\"\n        # Reset if it's a new day\n        current_date = datetime.datetime.now().date()\n        if current_date != self.today:\n            self.today = current_date\n            self.usage_log = []\n        \n        # Calculate cost\n        total_tokens = prompt_tokens + completion_tokens\n        cost_per_1k = self.cost_per_1k_tokens.get(model, 0.01)  # Default to gpt-4o pricing if unknown\n        cost = (total_tokens / 1000) * cost_per_1k\n        \n        # Log the usage\n        self.usage_log.append({\n            \"timestamp\": datetime.datetime.now().isoformat(),\n            \"model\": model,\n            \"prompt_tokens\": prompt_tokens,\n            \"completion_tokens\": completion_tokens,\n            \"total_tokens\": total_tokens,\n            \"cost\": cost\n        })\n    \n    def get_daily_usage(self):\n        \"\"\"Get the total usage for today.\"\"\"\n        total_tokens = sum(entry[\"total_tokens\"] for entry in self.usage_log)\n        total_cost = sum(entry[\"cost\"] for entry in self.usage_log)\n        \n        return {\n            \"date\": self.today.isoformat(),\n            \"total_tokens\": total_tokens,\n            \"total_cost\": total_cost,\n            \"budget_remaining\": self.daily_budget - total_cost,\n            \"budget_percentage\": (total_cost / self.daily_budget) * 100 if self.daily_budget \u003e 0 else 0\n        }\n    \n    def check_budget(self, model, estimated_tokens):\n        \"\"\"Check if a request would exceed the daily budget.\"\"\"\n        # Get current usage\n        usage = self.get_daily_usage()\n        \n        # Estimate cost of the new request\n        cost_per_1k = self.cost_per_1k_tokens.get(model, 0.01)\n        estimated_cost = (estimated_tokens / 1000) * cost_per_1k\n        \n        # Check if it would exceed the budget\n        if usage[\"total_cost\"] + estimated_cost \u003e self.daily_budget:\n            return {\n                \"within_budget\": False,\n                \"estimated_cost\": estimated_cost,\n                \"budget_remaining\": usage[\"budget_remaining\"],\n                \"message\": f\"This request would exceed your daily budget of ${self.daily_budget:.2f}\"\n            }\n        \n        return {\n            \"within_budget\": True,\n            \"estimated_cost\": estimated_cost,\n            \"budget_remaining\": usage[\"budget_remaining\"] - estimated_cost,\n            \"message\": f\"Request is within budget. Estimated cost: ${estimated_cost:.4f}\"\n        }\n    \n    def make_budgeted_request(self, messages, model=\"gpt-3.5-turbo\"):\n        \"\"\"Make an API request while respecting the budget.\"\"\"\n        # Estimate token usage\n        estimated_tokens = count_message_tokens(messages, model) + 500  # Add buffer for completion\n        \n        # Check budget\n        budget_check = self.check_budget(model, estimated_tokens)\n        \n        if not budget_check[\"within_budget\"]:\n            print(budget_check[\"message\"])\n            \n            # Try with a cheaper model if available\n            if model == \"gpt-4o\" or model == \"gpt-4\":\n                print(\"Trying with gpt-3.5-turbo instead...\")\n                return self.make_budgeted_request(messages, \"gpt-3.5-turbo\")\n            \n            return {\n                \"error\": \"Budget exceeded\",\n                \"message\": budget_check[\"message\"]\n            }\n        \n        # Make the API call\n        try:\n            response = client.chat.completions.create(\n                model=model,\n                messages=messages\n            )\n            \n            # Log the actual usage\n            self.log_usage(\n                model,\n                response.usage.prompt_tokens,\n                response.usage.completion_tokens\n            )\n            \n            return {\n                \"content\": response.choices[0].message.content,\n                \"usage\": response.usage,\n                \"cost\": (response.usage.total_tokens / 1000) * self.cost_per_1k_tokens.get(model, 0.01)\n            }\n        except Exception as e:\n            return {\n                \"error\": str(e),\n                \"message\": \"API request failed\"\n            }\n```\n\nIn the next section, we'll explore practical use cases and real-world applications of the OpenAI API.\n# Practical Use Cases and Applications\n\n## Content Generation and Summarization\n\nThe OpenAI API excels at generating and transforming content for various applications.\n\n### Automated Content Creation\n\n```python\ndef generate_blog_post(topic, tone=\"professional\", length=\"medium\"):\n    \"\"\"Generate a complete blog post on a given topic.\"\"\"\n    # Define length parameters\n    length_params = {\n        \"short\": \"approximately 500 words\",\n        \"medium\": \"approximately 1000 words\",\n        \"long\": \"approximately 1500-2000 words\"\n    }\n    \n    # Define tone descriptions\n    tone_descriptions = {\n        \"professional\": \"formal and authoritative\",\n        \"conversational\": \"friendly and approachable\",\n        \"technical\": \"detailed and precise\",\n        \"humorous\": \"light-hearted and entertaining\"\n    }\n    \n    # Create the prompt\n    prompt = f\"\"\"\n    Write a {tone_descriptions.get(tone, 'well-written')} blog post about {topic}. \n    The post should be {length_params.get(length, 'approximately 1000 words')} and include:\n    \n    1. An engaging introduction that hooks the reader\n    2. Well-structured body paragraphs with subheadings\n    3. Practical insights or actionable takeaways\n    4. A conclusion that summarizes key points\n    \n    Format the post in Markdown.\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a professional content writer who specializes in creating engaging, well-researched blog posts.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n    \n    return response.choices[0].message.content\n\n# Example usage\nblog_post = generate_blog_post(\n    topic=\"How Artificial Intelligence is Transforming Healthcare\",\n    tone=\"conversational\",\n    length=\"medium\"\n)\n\n# Save the blog post to a file\nwith open(\"ai_healthcare_blog.md\", \"w\") as f:\n    f.write(blog_post)\n```\n\n### Document Summarization\n\n```python\ndef summarize_document(document, summary_type=\"executive\"):\n    \"\"\"Summarize a document with different summary types.\"\"\"\n    # Define summary types\n    summary_types = {\n        \"executive\": \"Create a concise executive summary highlighting the most important points and conclusions.\",\n        \"bullet\": \"Create a bullet-point summary of the key points.\",\n        \"detailed\": \"Create a detailed summary that captures all main points and supporting details.\",\n        \"eli5\": \"Summarize this document as if explaining to a 10-year-old.\"\n    }\n    \n    # Create the prompt\n    prompt = f\"\"\"\n    {summary_types.get(summary_type, summary_types[\"executive\"])}\n    \n    Document:\n    {document}\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    return response.choices[0].message.content\n```\n\n### Content Transformation\n\n```python\ndef transform_content(content, transformation_type):\n    \"\"\"Transform content from one format or style to another.\"\"\"\n    transformations = {\n        \"academic_to_blog\": \"Transform this academic text into an engaging blog post while preserving the key information.\",\n        \"technical_to_simple\": \"Rewrite this technical content in simple, easy-to-understand language.\",\n        \"bullet_to_narrative\": \"Convert these bullet points into a flowing narrative text.\",\n        \"long_to_short\": \"Condense this content into a much shorter version while preserving the key points.\",\n        \"formal_to_casual\": \"Rewrite this formal content in a more casual, conversational tone.\"\n    }\n    \n    prompt = f\"\"\"\n    {transformations.get(transformation_type, \"Transform this content appropriately.\")}\n    \n    Content:\n    {content}\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    return response.choices[0].message.content\n```\n\n## Conversational AI and Chatbots\n\nThe OpenAI API is particularly well-suited for building conversational applications.\n\n### Building a Customer Support Chatbot\n\n```python\nimport json\n\nclass CustomerSupportChatbot:\n    def __init__(self, product_knowledge_base=None):\n        \"\"\"Initialize the customer support chatbot.\"\"\"\n        self.client = OpenAI(\n            api_key=os.environ.get(\"OPENAI_API_KEY\")\n        )\n        self.product_knowledge_base = product_knowledge_base\n        self.conversation_history = []\n        self.system_message = {\n            \"role\": \"system\",\n            \"content\": \"\"\"\n            You are a helpful customer support assistant for our technology company.\n            Be friendly, concise, and solution-oriented.\n            If you don't know the answer to a question, don't make up information - instead, offer to escalate to a human agent.\n            \"\"\"\n        }\n    \n    def get_product_info(self, product_query):\n        \"\"\"Retrieve product information from the knowledge base.\"\"\"\n        if not self.product_knowledge_base:\n            return None\n        \n        # Simple keyword matching (in a real system, use vector search)\n        for product in self.product_knowledge_base:\n            if product_query.lower() in product[\"name\"].lower() or any(keyword in product_query.lower() for keyword in product[\"keywords\"]):\n                return product\n        \n        return None\n    \n    def handle_message(self, user_message):\n        \"\"\"Process a user message and generate a response.\"\"\"\n        # Add the user message to the conversation history\n        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n        \n        # Check if this is a product query\n        product_info = self.get_product_info(user_message)\n        if product_info:\n            # Add product information to the context\n            product_context = f\"\"\"\n            Relevant product information:\n            Name: {product_info['name']}\n            Description: {product_info['description']}\n            Price: {product_info['price']}\n            Features: {', '.join(product_info['features'])}\n            \"\"\"\n            \n            self.conversation_history.append({\"role\": \"system\", \"content\": product_context})\n        \n        # Prepare the messages for the API call\n        messages = [self.system_message] + self.conversation_history\n        \n        # Make the API call\n        response = self.client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",  # Using a cost-effective model for customer support\n            messages=messages\n        )\n        \n        # Extract the assistant's response\n        assistant_response = response.choices[0].message.content\n        \n        # Add the response to the conversation history\n        self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n        \n        # Manage conversation history length\n        if len(self.conversation_history) \u003e 10:\n            # Keep only the most recent messages\n            self.conversation_history = self.conversation_history[-10:]\n        \n        return assistant_response\n\n# Example product knowledge base\nproduct_kb = [\n    {\n        \"name\": \"TechPro Laptop X1\",\n        \"description\": \"A high-performance laptop for professionals\",\n        \"price\": \"$1,299\",\n        \"features\": [\"14-inch 4K display\", \"16GB RAM\", \"512GB SSD\", \"Intel Core i7\", \"12-hour battery life\"],\n        \"keywords\": [\"laptop\", \"computer\", \"techpro\", \"x1\"]\n    },\n    {\n        \"name\": \"SmartHome Hub\",\n        \"description\": \"Central control for all your smart home devices\",\n        \"price\": \"$199\",\n        \"features\": [\"Voice control\", \"Compatible with 100+ devices\", \"Energy monitoring\", \"Automated routines\"],\n        \"keywords\": [\"smart home\", \"hub\", \"automation\", \"iot\"]\n    }\n]\n\n# Initialize the chatbot\nchatbot = CustomerSupportChatbot(product_kb)\n\n# Example conversation\nprint(\"Customer Support Bot: Hello! How can I help you today?\")\n\nwhile True:\n    user_input = input(\"You: \")\n    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n        print(\"Customer Support Bot: Thank you for contacting us. Have a great day!\")\n        break\n    \n    response = chatbot.handle_message(user_input)\n    print(f\"Customer Support Bot: {response}\")\n```\n\n### Multi-turn Conversation Management\n\n```python\nclass ConversationManager:\n    def __init__(self, persona=\"assistant\"):\n        \"\"\"Initialize the conversation manager with a specific persona.\"\"\"\n        self.client = OpenAI(\n            api_key=os.environ.get(\"OPENAI_API_KEY\")\n        )\n        self.conversation_history = []\n        self.personas = {\n            \"assistant\": \"You are a helpful, friendly assistant.\",\n            \"tutor\": \"You are a patient, knowledgeable tutor who helps explain concepts clearly.\",\n            \"therapist\": \"You are an empathetic listener who helps people process their thoughts and feelings.\",\n            \"coach\": \"You are a motivational coach who helps people set and achieve goals.\"\n        }\n        self.system_message = {\n            \"role\": \"system\",\n            \"content\": self.personas.get(persona, self.personas[\"assistant\"])\n        }\n    \n    def add_context(self, context):\n        \"\"\"Add additional context to the conversation.\"\"\"\n        context_message = {\n            \"role\": \"system\",\n            \"content\": context\n        }\n        self.conversation_history.append(context_message)\n    \n    def process_message(self, user_message):\n        \"\"\"Process a user message and generate a response.\"\"\"\n        # Add the user message to the conversation history\n        self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n        \n        # Prepare the messages for the API call\n        messages = [self.system_message] + self.conversation_history\n        \n        # Make the API call\n        response = self.client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages\n        )\n        \n        # Extract the assistant's response\n        assistant_response = response.choices[0].message.content\n        \n        # Add the response to the conversation history\n        self.conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n        \n        return assistant_response\n    \n    def summarize_conversation(self):\n        \"\"\"Generate a summary of the conversation so far.\"\"\"\n        if len(self.conversation_history) \u003c 2:\n            return \"The conversation has just started.\"\n        \n        summary_request = [\n            {\"role\": \"system\", \"content\": \"Summarize the key points of this conversation concisely.\"},\n            {\"role\": \"user\", \"content\": str(self.conversation_history)}\n        ]\n        \n        response = self.client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=summary_request\n        )\n        \n        return response.choices[0].message.content\n    \n    def save_conversation(self, filename=\"conversation.json\"):\n        \"\"\"Save the conversation history to a file.\"\"\"\n        with open(filename, \"w\") as f:\n            json.dump({\n                \"system_message\": self.system_message,\n                \"conversation\": self.conversation_history\n            }, f, indent=2)\n        \n        return f\"Conversation saved to {filename}\"\n    \n    def load_conversation(self, filename=\"conversation.json\"):\n        \"\"\"Load a conversation history from a file.\"\"\"\n        try:\n            with open(filename, \"r\") as f:\n                data = json.load(f)\n                self.system_message = data[\"system_message\"]\n                self.conversation_history = data[\"conversation\"]\n            \n            return f\"Conversation loaded from {filename}\"\n        except Exception as e:\n            return f\"Error loading conversation: {str(e)}\"\n```\n\n## Data Analysis and Processing\n\nThe OpenAI API can be used for various data analysis and processing tasks.\n\n### Text Classification and Categorization\n\n```python\ndef classify_text(text, categories):\n    \"\"\"Classify text into one of the provided categories.\"\"\"\n    categories_str = \", \".join(categories)\n    \n    prompt = f\"\"\"\n    Classify the following text into exactly one of these categories: {categories_str}\n    \n    Text: {text}\n    \n    Category:\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0.3  # Lower temperature for more deterministic results\n    )\n    \n    return response.choices[0].message.content.strip()\n\ndef batch_classify_texts(texts, categories):\n    \"\"\"Classify multiple texts in batch.\"\"\"\n    results = []\n    \n    for text in texts:\n        category = classify_text(text, categories)\n        results.append({\n            \"text\": text,\n            \"category\": category\n        })\n    \n    return results\n\n# Example usage\ncustomer_feedback = [\n    \"The product was amazing and exceeded my expectations!\",\n    \"I've been waiting for a refund for two weeks now.\",\n    \"How do I reset my password?\",\n    \"The checkout process was confusing and I couldn't complete my order.\"\n]\n\ncategories = [\"Positive Feedback\", \"Complaint\", \"Question\", \"Bug Report\"]\n\nclassification_results = batch_classify_texts(customer_feedback, categories)\n\nfor result in classification_results:\n    print(f\"Text: {result['text']}\")\n    print(f\"Category: {result['category']}\")\n    print()\n```\n\n### Named Entity Recognition\n\n```python\ndef extract_entities(text, entity_types=None):\n    \"\"\"Extract named entities from text.\"\"\"\n    if entity_types is None:\n        entity_types = [\"Person\", \"Organization\", \"Location\", \"Date\", \"Product\"]\n    \n    entity_types_str = \", \".join(entity_types)\n    \n    prompt = f\"\"\"\n    Extract all {entity_types_str} entities from the following text.\n    Format the output as a JSON object with entity types as keys and lists of extracted entities as values.\n    \n    Text: {text}\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    # Extract the JSON from the response\n    result = response.choices[0].message.content\n    \n    # Find JSON in the response\n    import re\n    json_match = re.search(r'```json\\n(.*?)\\n```', result, re.DOTALL)\n    if json_match:\n        result = json_match.group(1)\n    \n    try:\n        return json.loads(result)\n    except json.JSONDecodeError:\n        # If JSON parsing fails, return the raw text\n        return {\"error\": \"Failed to parse JSON\", \"raw_result\": result}\n```\n\n### Sentiment Analysis\n\n```python\ndef analyze_sentiment(text, detailed=False):\n    \"\"\"Analyze the sentiment of a text.\"\"\"\n    if detailed:\n        prompt = f\"\"\"\n        Perform a detailed sentiment analysis of the following text.\n        Include:\n        1. Overall sentiment (positive, negative, or neutral)\n        2. Sentiment score (-1 to 1, where -1 is very negative and 1 is very positive)\n        3. Key emotional tones detected\n        4. Specific positive and negative aspects mentioned\n        \n        Format the output as JSON.\n        \n        Text: {text}\n        \"\"\"\n    else:\n        prompt = f\"\"\"\n        Analyze the sentiment of the following text as positive, negative, or neutral.\n        Include a score from -1 to 1, where -1 is very negative and 1 is very positive.\n        \n        Text: {text}\n        \n        Format the output as JSON with \"sentiment\" and \"score\" fields.\n        \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    result = response.choices[0].message.content\n    \n    # Find JSON in the response\n    import re\n    json_match = re.search(r'```json\\n(.*?)\\n```', result, re.DOTALL)\n    if json_match:\n        result = json_match.group(1)\n    \n    try:\n        return json.loads(result)\n    except json.JSONDecodeError:\n        # If JSON parsing fails, return the raw text\n        return {\"error\": \"Failed to parse JSON\", \"raw_result\": result}\n\ndef batch_sentiment_analysis(texts):\n    \"\"\"Analyze sentiment for multiple texts in batch.\"\"\"\n    results = []\n    \n    for text in texts:\n        sentiment = analyze_sentiment(text)\n        results.append({\n            \"text\": text,\n            \"sentiment\": sentiment\n        })\n    \n    return results\n```\n\n## Educational Applications\n\nThe OpenAI API can be used to create powerful educational tools and resources.\n\n### Automated Tutoring System\n\n```python\nclass TutoringSystem:\n    def __init__(self, subject=\"general\"):\n        \"\"\"Initialize the tutoring system for a specific subject.\"\"\"\n        self.client = OpenAI(\n            api_key=os.environ.get(\"OPENAI_API_KEY\")\n        )\n        self.conversation_history = []\n        \n        # Define subject-specific system messages\n        self.subjects = {\n            \"math\": \"You are a patient and helpful math tutor. Explain concepts step by step, provide examples, and guide students to the answer rather than giving it directly.\",\n            \"science\": \"You are a knowledgeable science tutor. Explain scientific concepts clearly, relate them to real-world examples, and correct misconceptions gently.\",\n            \"programming\": \"You are a programming tutor. Explain coding concepts clearly, provide code examples, and help debug issues by guiding students through the troubleshooting process.\",\n            \"history\": \"You are a history tutor. Provide accurate historical information, explain cause and effect relationships, and help students understand different perspectives on historical events.\",\n            \"general\": \"You are a helpful tutor. Explain concepts clearly, provide examples, and guide students to deeper understanding through thoughtful questions.\"\n        }\n        \n        self.system_message = {\n            \"role\": \"system\",\n            \"content\": self.subjects.get(subject, self.subjects[\"general\"])\n        }\n    \n    def ask_question(self, question):\n        \"\"\"Ask a question to the tutoring system.\"\"\"\n        # Add the question to the conversation history\n        self.conversation_history.append({\"role\": \"user\", \"content\": question})\n        \n        # Prepare the messages for the API call\n        messages = [self.system_message] + self.conversation_history\n        \n        # Make the API call\n        response = self.client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=messages\n        )\n        \n        # Extract the tutor's response\n        tutor_response = response.choices[0].message.content\n        \n        # Add the response to the conversation history\n        self.conversation_history.append({\"role\": \"assistant\", \"content\": tutor_response})\n        \n        return tutor_response\n    \n    def generate_practice_problems(self, topic, difficulty=\"medium\", number=3):\n        \"\"\"Generate practice problems on a specific topic.\"\"\"\n        difficulties = {\n            \"easy\": \"basic, introductory level\",\n            \"medium\": \"intermediate level with some complexity\",\n            \"hard\": \"challenging, requiring deep understanding\"\n        }\n        \n        difficulty_desc = difficulties.get(difficulty, difficulties[\"medium\"])\n        \n        prompt = f\"\"\"\n        Generate {number} {difficulty_desc} practice problems about {topic}.\n        For each problem:\n        1. Provide a clear problem statement\n        2. Include the correct answer\n        3. Provide a step-by-step solution\n        \n        Format each problem with clear separation between the problem, answer, and solution.\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"system\", \"content\": self.system_message[\"content\"]},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        \n        return response.choices[0].message.content\n    \n    def explain_concept(self, concept, detail_level=\"medium\"):\n        \"\"\"Provide an explanation of a concept at the specified detail level.\"\"\"\n        detail_levels = {\n            \"basic\": \"simple terms a beginner would understand\",\n            \"medium\": \"moderate detail appropriate for someone with some background knowledge\",\n            \"advanced\": \"in-depth detail for someone with substantial background knowledge\"\n        }\n        \n        detail_desc = detail_levels.get(detail_level, detail_levels[\"medium\"])\n        \n        prompt = f\"\"\"\n        Explain the concept of {concept} in {detail_desc}.\n        Include:\n        1. A clear definition\n        2. Key principles or components\n        3. Real-world examples or applications\n        4. Common misconceptions, if any\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"system\", \"content\": self.system_message[\"content\"]},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        \n        return response.choices[0].message.content\n```\n\n### Quiz and Assessment Generation\n\n```python\ndef generate_quiz(topic, num_questions=5, question_types=None):\n    \"\"\"Generate a quiz on a specific topic.\"\"\"\n    if question_types is None:\n        question_types = [\"multiple_choice\", \"true_false\", \"short_answer\"]\n    \n    question_types_str = \", \".join(question_types)\n    \n    prompt = f\"\"\"\n    Create a quiz about {topic} with {num_questions} questions.\n    Include a mix of {question_types_str} questions.\n    \n    For each question:\n    1. Provide a clear question\n    2. For multiple choice, provide 4 options labeled A, B, C, D\n    3. Include the correct answer\n    4. Add a brief explanation of why the answer is correct\n    \n    Format the output as a JSON object with an array of question objects.\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    result = response.choices[0].message.content\n    \n    # Find JSON in the response\n    import re\n    json_match = re.search(r'```json\\n(.*?)\\n```', result, re.DOTALL)\n    if json_match:\n        result = json_match.group(1)\n    \n    try:\n        return json.loads(result)\n    except json.JSONDecodeError:\n        # If JSON parsing fails, return the raw text\n        return {\"error\": \"Failed to parse JSON\", \"raw_result\": result}\n\ndef format_quiz_for_display(quiz_data):\n    \"\"\"Format quiz data for display.\"\"\"\n    if \"error\" in quiz_data:\n        return f\"Error: {quiz_data['error']}\\n\\n{quiz_data['raw_result']}\"\n    \n    formatted_quiz = \"# Quiz\\n\\n\"\n    \n    for i, question in enumerate(quiz_data[\"questions\"]):\n        formatted_quiz += f\"## Question {i+1}: {question['question']}\\n\\n\"\n        \n        if \"options\" in question:\n            for option_key, option_value in question[\"options\"].items():\n                formatted_quiz += f\"{option_key}. {option_value}\\n\"\n            formatted_quiz += \"\\n\"\n        \n        formatted_quiz += f\"**Correct Answer:** {question['correct_answer']}\\n\\n\"\n        formatted_quiz += f\"**Explanation:** {question['explanation']}\\n\\n\"\n        formatted_quiz += \"---\\n\\n\"\n    \n    return formatted_quiz\n```\n\n## Creative Applications\n\nThe OpenAI API can be used for various creative applications.\n\n### Story Generation\n\n```python\ndef generate_story(prompt, genre=None, length=\"medium\", style=None):\n    \"\"\"Generate a creative story based on a prompt.\"\"\"\n    # Define length parameters\n    length_params = {\n        \"short\": \"approximately 500 words\",\n        \"medium\": \"approximately 1000 words\",\n        \"long\": \"approximately 2000 words\"\n    }\n    \n    # Create the system message\n    system_content = \"You are a creative storyteller who writes engaging, imaginative stories.\"\n    \n    if genre:\n        system_content += f\" You specialize in {genre} stories.\"\n    \n    if style:\n        system_content += f\" Your writing style is {style}.\"\n    \n    # Create the user prompt\n    user_prompt = f\"\"\"\n    Write a {length_params.get(length, 'medium-length')} story based on the following prompt:\n    \n    {prompt}\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_content},\n            {\"role\": \"user\", \"content\": user_prompt}\n        ]\n    )\n    \n    return response.choices[0].message.content\n\n# Example usage\nstory = generate_story(\n    prompt=\"A scientist discovers a way to communicate with plants and learns they have been watching us all along.\",\n    genre=\"science fiction\",\n    length=\"short\",\n    style=\"suspenseful with a touch of humor\"\n)\n\n# Save the story to a file\nwith open(\"plant_communication_story.md\", \"w\") as f:\n    f.write(story)\n```\n\n### Art and Image Prompt Generation\n\n```python\ndef generate_image_prompts(concept, num_prompts=3, style=None):\n    \"\"\"Generate detailed prompts for image generation based on a concept.\"\"\"\n    styles_desc = f\"in {style} style\" if style else \"in various artistic styles\"\n    \n    prompt = f\"\"\"\n    Create {num_prompts} detailed image generation prompts based on the concept: \"{concept}\"\n    \n    Each prompt should:\n    1. Be highly descriptive and visual\n    2. Include details about composition, lighting, mood, and colors\n    3. Be {styles_desc}\n    4. Be optimized for text-to-image AI systems\n    \n    Format each prompt separately and make each one unique and creative.\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    return response.choices[0].message.content\n\n# Example usage\nimage_prompts = generate_image_prompts(\n    concept=\"A futuristic city where nature and technology have merged harmoniously\",\n    num_prompts=5,\n    style=\"cyberpunk meets solarpunk\"\n)\n\nprint(image_prompts)\n```\n\n## Business Applications\n\nThe OpenAI API can be used for various business applications to improve efficiency and decision-making.\n\n### Automated Email Response System\n\n```python\ndef categorize_email(email_body):\n    \"\"\"Categorize an email into predefined categories.\"\"\"\n    categories = [\n        \"Customer Support\",\n        \"Sales Inquiry\",\n        \"Partnership Opportunity\",\n        \"Job Application\",\n        \"Feedback\",\n        \"Complaint\",\n        \"Other\"\n    ]\n    \n    prompt = f\"\"\"\n    Categorize the following email into one of these categories: {', '.join(categories)}\n    \n    Email:\n    {email_body}\n    \n    Category:\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0.3\n    )\n    \n    return response.choices[0].message.content.strip()\n\ndef generate_email_response(email_body, sender_name, company_name):\n    \"\"\"Generate an appropriate response to an email.\"\"\"\n    # First, categorize the email\n    category = categorize_email(email_body)\n    \n    # Define response templates based on category\n    templates = {\n        \"Customer Support\": \"You are a helpful customer support representative. Address the customer's issue professionally and provide a solution or next steps.\",\n        \"Sales Inquiry\": \"You are a sales representative. Be helpful and informative about our products/services without being pushy.\",\n        \"Partnership Opportunity\": \"You are a business development manager. Express interest in potential partnerships while requesting more specific information.\",\n        \"Job Application\": \"You are an HR representative. Acknowledge receipt of the application and explain the next steps in the hiring process.\",\n        \"Feedback\": \"You are a customer experience manager. Thank the sender for their feedback and explain how it will be used to improve.\",\n        \"Complaint\": \"You are a customer relations specialist. Apologize for the inconvenience, show empathy, and offer a solution or escalation path.\",\n        \"Other\": \"You are a helpful company representative. Respond appropriately to the email content.\"\n    }\n    \n    system_content = templates.get(category, templates[\"Other\"])\n    \n    prompt = f\"\"\"\n    Write a professional email response to the following email from {sender_name}.\n    \n    Original Email:\n    {email_body}\n    \n    Sign the email as \"Customer Relations Team, {company_name}\"\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_content},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n    \n    return {\n        \"category\": category,\n        \"response\": response.choices[0].message.content\n    }\n```\n\n### Meeting Summarization\n\n```python\ndef summarize_meeting(transcript, format_type=\"detailed\"):\n    \"\"\"Summarize a meeting transcript.\"\"\"\n    formats = {\n        \"brief\": \"Create a brief summary (2-3 paragraphs) of the key points discussed in the meeting.\",\n        \"detailed\": \"Create a detailed summary of the meeting including all main topics, decisions, and action items.\",\n        \"action_items\": \"Extract only the action items from the meeting, including who is responsible and deadlines if mentioned.\",\n        \"decisions\": \"Extract only the decisions made during the meeting.\"\n    }\n    \n    format_instruction = formats.get(format_type, formats[\"detailed\"])\n    \n    prompt = f\"\"\"\n    {format_instruction}\n    \n    Meeting Transcript:\n    {transcript}\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    return response.choices[0].message.content\n\ndef format_meeting_summary_for_email(summary, meeting_title, meeting_date):\n    \"\"\"Format a meeting summary for email distribution.\"\"\"\n    prompt = f\"\"\"\n    Format the following meeting summary as a professional email to send to meeting participants.\n    Include a clear subject line, greeting, the summary content, and a professional closing.\n    \n    Meeting Title: {meeting_title}\n    Meeting Date: {meeting_date}\n    \n    Summary:\n    {summary}\n    \"\"\"\n    \n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    \n    return response.choices[0].message.content\n```\n\n## Integrating with Other Technologies\n\nThe OpenAI API can be integrated with various other technologies to create powerful applications.\n\n### Integration with Database Systems\n\n```python\nimport sqlite3\n\nclass AIDataAnalyst:\n    def __init__(self, database_path):\n        \"\"\"Initialize the AI data analyst with a database connection.\"\"\"\n        self.client = OpenAI(\n            api_key=os.environ.get(\"OPENAI_API_KEY\")\n        )\n        self.conn = sqlite3.connect(database_path)\n        self.cursor = self.conn.cursor()\n        \n        # Get database schema\n        self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = self.cursor.fetchall()\n        \n        self.schema = {}\n        for table in tables:\n            table_name = table[0]\n            self.cursor.execute(f\"PRAGMA table_info({table_name});\")\n            columns = self.cursor.fetchall()\n            self.schema[table_name] = [column[1] for column in columns]\n    \n    def generate_sql_query(self, question):\n        \"\"\"Generate an SQL query based on a natural language question.\"\"\"\n        schema_str = \"\"\n        for table, columns in self.schema.items():\n            schema_str += f\"Table: {table}\\n\"\n            schema_str += f\"Columns: {', '.join(columns)}\\n\\n\"\n        \n        prompt = f\"\"\"\n        Based on the following database schema, write an SQL query to answer the question.\n        \n        Database Schema:\n        {schema_str}\n        \n        Question: {question}\n        \n        SQL Query:\n        \"\"\"\n        \n        response = self.client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        \n        # Extract the SQL query from the response\n        sql_query = response.choices[0].message.content.strip()\n        \n        # Remove markdown code blocks if present\n        import re\n        sql_match = re.search(r'```sql\\n(.*?)\\n```', sql_query, re.DOTALL)\n        if sql_match:\n            sql_query = sql_match.group(1)\n        \n        return sql_query\n    \n    def execute_query(self, sql_query):\n        \"\"\"Execute an SQL query and return the results.\"\"\"\n        try:\n            self.cursor.execute(sql_query)\n            columns = [description[0] for description in self.cursor.description]\n            results = self.cursor.fetchall()\n            \n            return {\n                \"columns\": columns,\n                \"results\": results\n            }\n        except Exception as e:\n            return {\n                \"error\": str(e)\n            }\n    \n    def analyze_data(self, question):\n        \"\"\"Answer a question about the data by generating and executing an SQL query.\"\"\"\n        # Generate the SQL query\n        sql_query = self.generate_sql_query(question)\n        \n        # Execute the query\n        query_results = self.execute_query(sql_query)\n        \n        if \"error\" in query_results:\n            return {\n                \"question\": question,\n                \"sql_query\": sql_query,\n                \"error\": query_results[\"error\"]\n            }\n        \n        # Format the results\n        formatted_results = []\n        for row in query_results[\"results\"]:\n            formatted_row = {}\n            for i, column in enumerate(query_results[\"columns\"]):\n                formatted_row[column] = row[i]\n            formatted_results.append(formatted_row)\n        \n        # Generate analysis of the results\n        analysis_prompt = f\"\"\"\n        Analyze the following data to answer the question: \"{question}\"\n        \n        SQL Query:\n        {sql_query}\n        \n        Query Results:\n        {formatted_results}\n        \n        Provide a clear, concise analysis of what the data shows in relation to the question.\n        \"\"\"\n        \n        analysis_response = self.client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[{\"role\": \"user\", \"content\": analysis_prompt}]\n        )\n        \n        return {\n            \"question\": question,\n            \"sql_query\": sql_query,\n            \"results\": formatted_results,\n            \"analysis\": analysis_response.choices[0].message.content\n        }\n```\n\n### Integration with Web Applications\n\n```python\nfrom flask import Flask, request, jsonify, render_template\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/api/analyze', methods=['POST'])\ndef analyze_text():\n    data = request.json\n    text = data.get('text', '')\n    analysis_type = data.get('analysis_type', 'sentiment')\n    \n    if not text:\n        return jsonify({\"error\": \"No text provided\"}), 400\n    \n    client = OpenAI(\n        api_key=os.environ.get(\"OPENAI_API_KEY\")\n    )\n    \n    if analysis_type == 'sentiment':\n        prompt = f\"Perform sentiment analysis on the following text. Return a JSON object with 'sentiment' (positive, negative, or neutral) and 'score' (-1 to 1) fields.\\n\\nText: {text}\"\n    elif analysis_type == 'summary':\n        prompt = f\"Summarize the following text in a concise paragraph.\\n\\nText: {text}\"\n    elif analysis_type == 'keywords':\n        prompt = f\"Extract the top 5 keywords or key phrases from the following text. Return them as a JSON array.\\n\\nText: {text}\"\n    else:\n        return jsonify({\"error\": \"Invalid analysis type\"}), 400\n    \n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": prompt}]\n        )\n        \n        result = response.choices[0].message.content\n        \n        # For sentiment and keywords, try to parse JSON\n        if analysis_type in ['sentiment', 'keywords']:\n            try:\n                import re\n                import json\n                \n                # Try to extract JSON if it's in a code block\n                json_match = re.search(r'```json\\n(.*?)\\n```', result, re.DOTALL)\n                if json_match:\n                    result = json_match.group(1)\n                \n                # Parse the JSON\n                result = json.loads(result)\n            except json.JSONDecodeError:\n                # If JSON parsing fails, return the raw text\n                result = {\"result\": result}\n        else:\n            result = {\"result\": result}\n        \n        return jsonify(result)\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```\n\nIn the next section, we'll explore pricing and cost management strategies for the OpenAI API.\n# Pricing and Cost Management\n\n## Understanding OpenAI API Pricing\n\nThe OpenAI API uses a pay-as-you-go pricing model based on token usage. Understanding this pricing structure is essential for managing costs effectively.\n\n### Token-Based Pricing Model\n\nOpenAI's pricing is based on tokens, which are the basic units of text that the models process:\n\n1. **Input Tokens**: Text sent to the model (your prompts)\n2. **Output Tokens**: Text generated by the model (the responses)\n3. **Total Tokens**: The sum of input and output tokens\n\nPricing varies by model, with more capable models costing more per token:\n\n| Model | Input Price (per 1M tokens) | Output Price (per 1M tokens) |\n|-------|-----------------------------|-----------------------------|\n| GPT-4o | $10 | $30 |\n| GPT-4 | $30 | $60 |\n| GPT-3.5 Turbo | $1 | $2 |\n| Text Embedding Models | $0.10 - $1.00 | N/A |\n\n### Calculating Costs\n\nTo estimate costs for your application, you need to:\n\n1. Estimate the number of tokens in your inputs and outputs\n2. Multiply by the per-token cost for your chosen model\n3. Factor in your expected usage volume\n\nHere's a simple Python function to estimate costs:\n\n```python\ndef estimate_api_cost(\n    input_tokens_per_request,\n    output_tokens_per_request,\n    requests_per_day,\n    model=\"gpt-3.5-turbo\",\n    days=30\n):\n    \"\"\"Estimate monthly OpenAI API costs based on usage patterns.\"\"\"\n    # Model pricing (per 1M tokens as of 2025)\n    pricing = {\n        \"gpt-4o\": {\"input\": 10.0, \"output\": 30.0},\n        \"gpt-4\": {\"input\": 30.0, \"output\": 60.0},\n        \"gpt-3.5-turbo\": {\"input\": 1.0, \"output\": 2.0},\n        \"text-embedding-3-small\": {\"input\": 0.1, \"output\": 0.0},\n        \"text-embedding-3-large\": {\"input\": 1.0, \"output\": 0.0}\n    }\n    \n    if model not in pricing:\n        raise ValueError(f\"Unknown model: {model}\")\n    \n    # Calculate daily token usage\n    daily_input_tokens = input_tokens_per_request * requests_per_day\n    daily_output_tokens = output_tokens_per_request * requests_per_day\n    \n    # Calculate monthly token usage\n    monthly_input_tokens = daily_input_tokens * days\n    monthly_output_tokens = daily_output_tokens * days\n    \n    # Calculate costs\n    input_cost = (monthly_input_tokens / 1_000_000) * pricing[model][\"input\"]\n    output_cost = (monthly_output_tokens / 1_000_000) * pricing[model][\"output\"]\n    total_cost = input_cost + output_cost\n    \n    return {\n        \"model\": model,\n        \"monthly_input_tokens\": monthly_input_tokens,\n        \"monthly_output_tokens\": monthly_output_tokens,\n        \"monthly_total_tokens\": monthly_input_tokens + monthly_output_tokens,\n        \"input_cost\": input_cost,\n        \"output_cost\": output_cost,\n        \"total_cost\": total_cost\n    }\n\n# Example usage\ncost_estimate = estimate_api_cost(\n    input_tokens_per_request=200,\n    output_tokens_per_request=800,\n    requests_per_day=1000,\n    model=\"gpt-3.5-turbo\",\n    days=30\n)\n\nprint(f\"Estimated monthly cost: ${cost_estimate['total_cost']:.2f}\")\nprint(f\"Input cost: ${cost_estimate['input_cost']:.2f}\")\nprint(f\"Output cost: ${cost_estimate['output_cost']:.2f}\")\nprint(f\"Total tokens: {cost_estimate['monthly_total_tokens']:,}\")\n```\n\n## Cost Optimization Strategies\n\nImplementing cost optimization strategies can help you manage your OpenAI API expenses effectively.\n\n### Model Selection Optimization\n\nChoosing the right model for each task can significantly impact costs:\n\n```python\ndef select_optimal_model(task_type, complexity, budget_sensitivity):\n    \"\"\"Select the optimal model based on task requirements and budget constraints.\"\"\"\n    # Define task types and their minimum required capabilities\n    task_requirements = {\n        \"simple_generation\": {\"min_capability\": \"basic\"},\n        \"complex_reasoning\": {\"min_capability\": \"advanced\"},\n        \"creative_writing\": {\"min_capability\": \"intermediate\"},\n        \"code_generation\": {\"min_capability\": \"advanced\"},\n        \"summarization\": {\"min_capability\": \"basic\"},\n        \"classification\": {\"min_capability\": \"basic\"},\n        \"embeddings\": {\"min_capability\": \"embeddings\"}\n    }\n    \n    # Define model capabilities\n    model_capabilities = {\n        \"gpt-4o\": {\"capability\": \"advanced\", \"cost\": \"high\"},\n        \"gpt-4\": {\"capability\": \"advanced\", \"cost\": \"very_high\"},\n        \"gpt-3.5-turbo\": {\"capability\": \"intermediate\", \"cost\": \"low\"},\n        \"text-embedding-3-large\": {\"capability\": \"embeddings\", \"cost\": \"medium\"},\n        \"text-embedding-3-small\": {\"capability\": \"embeddings\", \"cost\": \"very_low\"}\n    }\n    \n    # Get the minimum required capability for the task\n    if task_type not in task_requirements:\n        raise ValueError(f\"Unknown task type: {task_type}\")\n    \n    min_capability = task_requirements[task_type][\"min_capability\"]\n    \n    # Filter models by minimum capability\n    suitable_models = []\n    for model, attributes in model_capabilities.items():\n        if min_capability == \"embeddings\" and attributes[\"capability\"] == \"embeddings\":\n            suitable_models.append(model)\n        elif min_capability == \"advanced\" and attributes[\"capability\"] == \"advanced\":\n            suitable_models.append(model)\n        elif min_capability == \"intermediate\" and attributes[\"capability\"] in [\"intermediate\", \"advanced\"]:\n            suitable_models.append(model)\n        elif min_capability == \"basic\" and attributes[\"capability\"] in [\"basic\", \"intermediate\", \"advanced\"]:\n            suitable_models.append(model)\n    \n    # Adjust based on complexity\n    if complexity == \"high\" and \"gpt-4o\" in suitable_models:\n        suitable_models = [model for model in suitable_models if model in [\"gpt-4o\", \"gpt-4\"]]\n    elif complexity == \"low\" and \"gpt-3.5-turbo\" in suitable_models:\n        suitable_models = [\"gpt-3.5-turbo\"]\n    \n    # Adjust based on budget sensitivity\n    if budget_sensitivity == \"high\":\n        # Sort by cost (ascending)\n        cost_ranking = {\"very_low\": 1, \"low\": 2, \"medium\": 3, \"high\": 4, \"very_high\": 5}\n        suitable_models.sort(key=lambda model: cost_ranking[model_capabilities[model][\"cost\"]])\n        return suitable_models[0]  # Return the cheapest suitable model\n    else:\n        # For low budget sensitivity, prefer capability over cost\n        capability_ranking = {\"basic\": 1, \"intermediate\": 2, \"advanced\": 3, \"embeddings\": 1}\n        suitable_models.sort(key=lambda model: -capability_ranking[model_capabilities[model][\"capability\"]])\n        return suitable_models[0]  # Return the most capable suitable model\n\n# Example usage\nrecommended_model = select_optimal_model(\n    task_type=\"summarization\",\n    complexity=\"low\",\n    budget_sensitivity=\"high\"\n)\n\nprint(f\"Recommended model: {recommended_model}\")\n```\n\n### Prompt Engineering for Cost Efficiency\n\nOptimizing your prompts can reduce token usage and costs:\n\n```python\ndef optimize_prompt_for_cost(original_prompt, model=\"gpt-3.5-turbo\"):\n    \"\"\"Optimize a prompt to reduce token usage while maintaining effectiveness.\"\"\"\n    # Calculate original token count\n    original_token_count = count_tokens(original_prompt, model)\n    \n    # Create a system message that instructs the model to optimize the prompt\n    system_message = \"\"\"\n    You are a prompt optimization assistant. Your task is to rewrite prompts to be more token-efficient while maintaining their effectiveness.\n    \n    Guidelines for optimization:\n    1. Remove unnecessary words and phrases\n    2. Use concise language\n    3. Maintain all key instructions and context\n    4. Preserve the original intent and requirements\n    5. Ensure the optimized prompt will produce the same quality of response\n    \"\"\"\n    \n    # Create the optimization request\n    optimization_prompt = f\"\"\"\n    Original prompt ({original_token_count} tokens):\n    {original_prompt}\n    \n    Please optimize this prompt to use fewer tokens while maintaining its effectiveness.\n    \"\"\"\n    \n    # Get the optimized prompt\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",  # Using a cheaper model for optimization\n        messages=[\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": optimization_prompt}\n        ]\n    )\n    \n    optimized_prompt = response.choices[0].message.content\n    \n    # Clean up the response to extract just the optimized prompt\n    import re\n    clean_prompt_match = re.search(r'Optimized prompt:(.*?)(?:\\n\\n|$)', optimized_prompt, re.DOTALL)\n    if clean_prompt_match:\n        optimized_prompt = clean_prompt_match.group(1).strip()\n    \n    # Calculate new token count\n    optimized_token_count = count_tokens(optimized_prompt, model)\n    \n    return {\n        \"original_prompt\": original_prompt,\n        \"optimized_prompt\": optimized_prompt,\n        \"original_token_count\": original_token_count,\n        \"optimized_token_count\": optimized_token_count,\n        \"token_reduction\": original_token_count - optimized_token_count,\n        \"reduction_percentage\": ((original_token_count - optimized_token_count) / original_token_count) * 100 if original_token_count \u003e 0 else 0\n    }\n```\n\n### Caching Strategies\n\nImplementing caching can significantly reduce API calls for repeated or similar requests:\n\n```python\nimport hashlib\nimport json\nimport os\nimport time\n\nclass SimpleFileCache:\n    def __init__(self, cache_dir=\"./cache\", expire_time=86400):\n        \"\"\"Initialize a simple file-based cache.\"\"\"\n        self.cache_dir = cache_dir\n        self.expire_time = expire_time  # Cache expiration in seconds (default: 24 hours)\n        \n        # Create cache directory if it doesn't exist\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    def _generate_cache_key(self, model, messages, temperature=None):\n        \"\"\"Generate a unique cache key based on request parameters.\"\"\"\n        # Create a dictionary of the parameters that affect the response\n        cache_dict = {\n            \"model\": model,\n            \"messages\": messages,\n            \"temperature\": temperature\n        }\n        \n        # Convert to a stable string representation and hash it\n        cache_str = json.dumps(cache_dict, sort_keys=True)\n        return hashlib.md5(cache_str.encode()).hexdigest()\n    \n    def _get_cache_path(self, cache_key):\n        \"\"\"Get the file path for a cache key.\"\"\"\n        return os.path.join(self.cache_dir, f\"{cache_key}.json\")\n    \n    def get_cached_response(self, model, messages, temperature=None):\n        \"\"\"Get a cached response if available and not expired.\"\"\"\n        cache_key = self._generate_cache_key(model, messages, temperature)\n        cache_path = self._get_cache_path(cache_key)\n        \n        if os.path.exists(cache_path):\n            # Check if cache is expired\n            if time.time() - os.path.getmtime(cache_path) \u003e self.expire_time:\n                # Cache is expired, remove it\n                os.remove(cache_path)\n                return None\n            \n            # Cache is valid, return it\n            with open(cache_path, \"r\") as f:\n                return json.load(f)\n        \n        return None\n    \n    def cache_response(self, model, messages, response, temperature=None):\n        \"\"\"Cache a response.\"\"\"\n        cache_key = self._generate_cache_key(model, messages, temperature)\n        cache_path = self._get_cache_path(cache_key)\n        \n        # Convert response to a serializable format\n        if hasattr(response, \"model_dump\"):\n            response_data = response.model_dump()\n        else:\n            # For older versions of the API\n            response_data = {\n                \"choices\": [{\"message\": {\"content\": response.choices[0].message.content}}],\n                \"model\": response.model,\n                \"usage\": {\n                    \"prompt_tokens\": response.usage.prompt_tokens,\n                    \"completion_tokens\": response.usage.completion_tokens,\n                    \"total_tokens\": response.usage.total_tokens\n                }\n            }\n        \n        # Save to cache file\n        with open(cache_path, \"w\") as f:\n            json.dump(response_data, f)\n\ndef get_completion_with_cache(prompt, cache, model=\"gpt-3.5-turbo\", temperature=0.7):\n    \"\"\"Get a completion with caching to reduce API calls.\"\"\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    \n    # Check cache first\n    cached_response = cache.get_cached_response(model, messages, temperature)\n    if cached_response:\n        print(\"Using cached response\")\n        return cached_response[\"choices\"][0][\"message\"][\"content\"]\n    \n    # If not in cache, make API call\n    print(\"Making API call\")\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    \n    # Cache the response\n    cache.cache_response(model, messages, response, temperature)\n    \n    return response.choices[0].message.content\n```\n\n### Batch Processing\n\nProcessing requests in batches can optimize token usage and reduce costs:\n\n```python\ndef batch_process_texts(texts, processor_function, batch_size=10, delay_between_batches=1):\n    \"\"\"Process a large number of texts in batches to manage API usage.\"\"\"\n    results = []\n    \n    # Process texts in batches\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i+batch_size]\n        batch_results = []\n        \n        print(f\"Processing batch {i//batch_size + 1}/{(len(texts) + batch_size - 1)//batch_size}\")\n        \n        # Process each text in the batch\n        for text in batch:\n            result = processor_function(text)\n            batch_results.append(result)\n        \n        results.extend(batch_results)\n        \n        # Delay between batches to avoid rate limits\n        if i + batch_size \u003c len(texts):\n            print(f\"Waiting {delay_between_batches} seconds before next batch...\")\n            time.sleep(delay_between_batches)\n    \n    return results\n\n# Example usage\ndef summarize_text(text):\n    \"\"\"Summarize a text using the OpenAI API.\"\"\"\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"Summarize the following text in one paragraph.\"},\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n    \n    return {\n        \"original_text\": text,\n        \"summary\": response.choices[0].message.content\n    }\n\n# Process a list of texts in batches\narticles = [\n    \"Long article text 1...\",\n    \"Long article text 2...\",\n    # ... more articles\n]\n\nsummaries = batch_process_texts(\n    texts=articles,\n    processor_function=summarize_text,\n    batch_size=5,\n    delay_between_batches=2\n)\n```\n\n## Monitoring and Budgeting\n\nImplementing robust monitoring and budgeting systems is essential for managing API costs.\n\n### Usage Tracking System\n\n```python\nimport csv\nimport datetime\nimport os\n\nclass APIUsageTracker:\n    def __init__(self, log_file=\"api_usage_log.csv\"):\n        \"\"\"Initialize the API usage tracker.\"\"\"\n        self.log_file = log_file\n        \n        # Create log file with headers if it doesn't exist\n        if not os.path.exists(log_file):\n            with open(log_file, \"w\", newline=\"\") as f:\n                writer = csv.writer(f)\n                writer.writerow([\n                    \"timestamp\", \"model\", \"prompt_tokens\", \"completion_tokens\", \n                    \"total_tokens\", \"estimated_cost\", \"request_id\", \"endpoint\"\n                ])\n    \n    def log_usage(self, model, prompt_tokens, completion_tokens, endpoint=\"chat.completions\", request_id=None):\n        \"\"\"Log API usage to the CSV file.\"\"\"\n        # Calculate total tokens\n        total_tokens = prompt_tokens + completion_tokens\n        \n        # Calculate estimated cost\n        cost_per_1k_tokens = {\n            \"gpt-4o\": {\"input\": 0.01, \"output\": 0.03},\n            \"gpt-4\": {\"input\": 0.03, \"output\": 0.06},\n            \"gpt-3.5-turbo\": {\"input\": 0.001, \"output\": 0.002},\n            \"text-embedding-3-small\": {\"input\": 0.0001, \"output\": 0},\n            \"text-embedding-3-large\": {\"input\": 0.001, \"output\": 0}\n        }\n        \n        model_costs = cost_per_1k_tokens.get(model, {\"input\": 0.01, \"output\": 0.03})\n        input_cost = (prompt_tokens / 1000) * model_costs[\"input\"]\n        output_cost = (completion_tokens / 1000) * model_costs[\"output\"]\n        estimated_cost = input_cost + output_cost\n        \n        # Generate request ID if not provided\n        if request_id is None:\n            request_id = f\"req_{int(time.time())}_{os.urandom(4).hex()}\"\n        \n        # Log to CSV\n        with open(self.log_file, \"a\", newline=\"\") as f:\n            writer = csv.writer(f)\n            writer.writerow([\n                datetime.datetime.now().isoformat(),\n                model,\n                prompt_tokens,\n                completion_tokens,\n                total_tokens,\n                estimated_cost,\n                request_id,\n                endpoint\n            ])\n        \n        return {\n            \"request_id\": request_id,\n            \"estimated_cost\": estimated_cost,\n            \"total_tokens\": total_tokens\n        }\n    \n    def get_usage_summary(self, days=30):\n        \"\"\"Get a summary of API usage for the specified number of days.\"\"\"\n        # Calculate the cutoff date\n        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)\n        cutoff_date_str = cutoff_date.isoformat()\n        \n        # Initialize summary data\n        summary = {\n            \"total_requests\": 0,\n            \"total_tokens\": 0,\n            \"total_cost\": 0,\n            \"model_usage\": {},\n            \"daily_usage\": {},\n            \"endpoint_usage\": {}\n        }\n        \n        # Read the log file\n        with open(self.log_file, \"r\", newline=\"\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                # Skip entries before the cutoff date\n                if row[\"timestamp\"] \u003c cutoff_date_str:\n                    continue\n                \n                # Extract data\n                model = row[\"model\"]\n                total_tokens = int(row[\"total_tokens\"])\n                estimated_cost = float(row[\"estimated_cost\"])\n                endpoint = row[\"endpoint\"]\n                date = row[\"timestamp\"].split(\"T\")[0]  # Extract date part\n                \n                # Update summary\n                summary[\"total_requests\"] += 1\n                summary[\"total_tokens\"] += total_tokens\n                summary[\"total_cost\"] += estimated_cost\n                \n                # Update model usage\n                if model not in summary[\"model_usage\"]:\n                    summary[\"model_usage\"][model] = {\n                        \"requests\": 0,\n                        \"tokens\": 0,\n                        \"cost\": 0\n                    }\n                summary[\"model_usage\"][model][\"requests\"] += 1\n                summary[\"model_usage\"][model][\"tokens\"] += total_tokens\n                summary[\"model_usage\"][model][\"cost\"] += estimated_cost\n                \n                # Update daily usage\n                if date not in summary[\"daily_usage\"]:\n                    summary[\"daily_usage\"][date] = {\n                        \"requests\": 0,\n                        \"tokens\": 0,\n                        \"cost\": 0\n                    }\n                summary[\"daily_usage\"][date][\"requests\"] += 1\n                summary[\"daily_usage\"][date][\"tokens\"] += total_tokens\n                summary[\"daily_usage\"][date][\"cost\"] += estimated_cost\n                \n                # Update endpoint usage\n                if endpoint not in summary[\"endpoint_usage\"]:\n                    summary[\"endpoint_usage\"][endpoint] = {\n                        \"requests\": 0,\n                        \"tokens\": 0,\n                        \"cost\": 0\n                    }\n                summary[\"endpoint_usage\"][endpoint][\"requests\"] += 1\n                summary[\"endpoint_usage\"][endpoint][\"tokens\"] += total_tokens\n                summary[\"endpoint_usage\"][endpoint][\"cost\"] += estimated_cost\n        \n        return summary\n```\n\n### Budget Alerts and Limits\n\n```python\nclass APIBudgetManager:\n    def __init__(self, monthly_budget=100.0, alert_thresholds=None, usage_tracker=None):\n        \"\"\"Initialize the API budget manager.\"\"\"\n        self.monthly_budget = monthly_budget\n        self.alert_thresholds = alert_thresholds or [0.5, 0.8, 0.9, 0.95]\n        self.alerted_thresholds = set()\n        self.usage_tracker = usage_tracker or APIUsageTracker()\n        \n        # Reset alerts at the beginning of each month\n        self._last_reset = datetime.datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n    \n    def check_budget_status(self):\n        \"\"\"Check the current budget status and trigger alerts if necessary.\"\"\"\n        # Check if we need to reset alerts (new month)\n        now = datetime.datetime.now()\n        if now.month != self._last_reset.month or now.year != self._last_reset.year:\n            self.alerted_thresholds = set()\n            self._last_reset = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n        \n        # Get current usage\n        usage_summary = self.usage_tracker.get_usage_summary(days=30)\n        current_spend = usage_summary[\"total_cost\"]\n        \n        # Calculate percentage of budget used\n        budget_used_percentage = (current_spend / self.monthly_budget) * 100\n        \n        # Check thresholds\n        alerts = []\n        for threshold in self.alert_thresholds:\n            threshold_percentage = threshold * 100\n            if budget_used_percentage \u003e= threshold_percentage and threshold not in self.alerted_thresholds:\n                alerts.append({\n                    \"threshold\": threshold,\n                    \"threshold_percentage\": threshold_percentage,\n                    \"current_spend\": current_spend,\n                    \"budget\": self.monthly_budget,\n                    \"budget_used_percentage\": budget_used_percentage,\n                    \"message\": f\"Budget alert: {budget_used_percentage:.1f}% of monthly budget used (${current_spend:.2f} of ${self.monthly_budget:.2f})\"\n                })\n                self.alerted_thresholds.add(threshold)\n        \n        return {\n            \"current_spend\": current_spend,\n            \"monthly_budget\": self.monthly_budget,\n            \"budget_used_percentage\": budget_used_percentage,\n            \"budget_remaining\": self.monthly_budget - current_spend,\n            \"alerts\": alerts\n        }\n    \n    def enforce_budget_limit(self, estimated_cost):\n        \"\"\"Check if a request would exceed the budget limit.\"\"\"\n        # Get current usage\n        usage_summary = self.usage_tracker.get_usage_summary(days=30)\n        current_spend = usage_summary[\"total_cost\"]\n        \n        # Check if the request would exceed the budget\n        if current_spend + estimated_cost \u003e self.monthly_budget:\n            return {\n                \"allowed\": False,\n                \"reason\": f\"Budget limit reached. Current spend: ${current_spend:.2f}, Budget: ${self.monthly_budget:.2f}\",\n                \"current_spend\": current_spend,\n                \"budget_remaining\": self.monthly_budget - current_spend,\n                \"estimated_cost\": estimated_cost\n            }\n        \n        return {\n            \"allowed\": True,\n            \"current_spend\": current_spend,\n            \"budget_remaining\": self.monthly_budget - current_spend,\n            \"estimated_cost\": estimated_cost\n        }\n    \n    def log_and_check(self, model, prompt_tokens, completion_tokens, endpoint=\"chat.completions\"):\n        \"\"\"Log usage and check budget status in one operation.\"\"\"\n        # Log the usage\n        log_result = self.usage_tracker.log_usage(\n            model=model,\n            prompt_tokens=prompt_tokens,\n            completion_tokens=completion_tokens,\n            endpoint=endpoint\n        )\n        \n        # Check budget status\n        budget_status = self.check_budget_status()\n        \n        return {\n            \"log_result\": log_result,\n            \"budget_status\": budget_status,\n            \"alerts\": budget_status[\"alerts\"]\n        }\n```\n\n## Enterprise Considerations\n\nFor enterprise users, there are additional considerations for managing OpenAI API usage.\n\n### Volume Discounts\n\nOpenAI offers volume discounts for enterprise customers with high usage. These discounts can significantly reduce per-token costs for large-scale applications.\n\n### Enterprise Agreements\n\nEnterprise agreements with OpenAI can provide:\n\n1. **Custom Rate Limits**: Higher rate limits to accommodate enterprise-scale applications\n2. **SLAs**: Service Level Agreements for reliability and uptime\n3. **Dedicated Support**: Priority support channels for enterprise customers\n4. **Custom Features**: Access to custom features or model configurations\n\n### Cost Allocation and Chargeback\n\nFor enterprises using the OpenAI API across multiple teams or projects, implementing cost allocation and chargeback mechanisms is important:\n\n```python\nclass EnterpriseUsageTracker(APIUsageTracker):\n    def __init__(self, log_file=\"enterprise_api_usage_log.csv\"):\n        \"\"\"Initialize the enterprise API usage tracker with team/project tracking.\"\"\"\n        super().__init__(log_file)\n        \n        # Create log file with extended headers if it doesn't exist\n        if not os.path.exists(log_file):\n            with open(log_file, \"w\", newline=\"\") as f:\n                writer = csv.writer(f)\n                writer.writerow([\n                    \"timestamp\", \"model\", \"prompt_tokens\", \"completion_tokens\", \n                    \"total_tokens\", \"estimated_cost\", \"request_id\", \"endpoint\",\n                    \"team\", \"project\", \"user_id\", \"purpose\"\n                ])\n    \n    def log_usage(self, model, prompt_tokens, completion_tokens, endpoint=\"chat.completions\", \n                  request_id=None, team=None, project=None, user_id=None, purpose=None):\n        \"\"\"Log API usage with team/project information for cost allocation.\"\"\"\n        # Calculate costs as in the parent class\n        total_tokens = prompt_tokens + completion_tokens\n        \n        cost_per_1k_tokens = {\n            \"gpt-4o\": {\"input\": 0.01, \"output\": 0.03},\n            \"gpt-4\": {\"input\": 0.03, \"output\": 0.06},\n            \"gpt-3.5-turbo\": {\"input\": 0.001, \"output\": 0.002},\n            \"text-embedding-3-small\": {\"input\": 0.0001, \"output\": 0},\n            \"text-embedding-3-large\": {\"input\": 0.001, \"output\": 0}\n        }\n        \n        model_costs = cost_per_1k_tokens.get(model, {\"input\": 0.01, \"output\": 0.03})\n        input_cost = (prompt_tokens / 1000) * model_costs[\"input\"]\n        output_cost = (completion_tokens / 1000) * model_costs[\"output\"]\n        estimated_cost = input_cost + output_cost\n        \n        # Generate request ID if not provided\n        if request_id is None:\n            request_id = f\"req_{int(time.time())}_{os.urandom(4).hex()}\"\n        \n        # Log to CSV with extended information\n        with open(self.log_file, \"a\", newline=\"\") as f:\n            writer = csv.writer(f)\n            writer.writerow([\n                datetime.datetime.now().isoformat(),\n                model,\n                prompt_tokens,\n                completion_tokens,\n                total_tokens,\n                estimated_cost,\n                request_id,\n                endpoint,\n                team or \"unknown\",\n                project or \"unknown\",\n                user_id or \"unknown\",\n                purpose or \"unknown\"\n            ])\n        \n        return {\n            \"request_id\": request_id,\n            \"estimated_cost\": estimated_cost,\n            \"total_tokens\": total_tokens\n        }\n    \n    def get_team_usage_summary(self, days=30):\n        \"\"\"Get a summary of API usage by team for the specified number of days.\"\"\"\n        # Calculate the cutoff date\n        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)\n        cutoff_date_str = cutoff_date.isoformat()\n        \n        # Initialize summary data\n        summary = {\n            \"total_cost\": 0,\n            \"team_usage\": {},\n            \"project_usage\": {},\n            \"user_usage\": {}\n        }\n        \n        # Read the log file\n        with open(self.log_file, \"r\", newline=\"\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                # Skip entries before the cutoff date\n                if row[\"timestamp\"] \u003c cutoff_date_str:\n                    continue\n                \n                # Extract data\n                estimated_cost = float(row[\"estimated_cost\"])\n                team = row.get(\"team\", \"unknown\")\n                project = row.get(\"project\", \"unknown\")\n                user_id = row.get(\"user_id\", \"unknown\")\n                \n                # Update summary\n                summary[\"total_cost\"] += estimated_cost\n                \n                # Update team usage\n                if team not in summary[\"team_usage\"]:\n                    summary[\"team_usage\"][team] = 0\n                summary[\"team_usage\"][team] += estimated_cost\n                \n                # Update project usage\n                if project not in summary[\"project_usage\"]:\n                    summary[\"project_usage\"][project] = 0\n                summary[\"project_usage\"][project] += estimated_cost\n                \n                # Update user usage\n                if user_id not in summary[\"user_usage\"]:\n                    summary[\"user_usage\"][user_id] = 0\n                summary[\"user_usage\"][user_id] += estimated_cost\n        \n        return summary\n    \n    def generate_cost_allocation_report(self, month=None, year=None):\n        \"\"\"Generate a cost allocation report for a specific month.\"\"\"\n        # Default to current month if not specified\n        if month is None or year is None:\n            now = datetime.datetime.now()\n            month = month or now.month\n            year = year or now.year\n        \n        # Calculate start and end dates for the month\n        start_date = datetime.datetime(year, month, 1)\n        if month == 12:\n            end_date = datetime.datetime(year + 1, 1, 1)\n        else:\n            end_date = datetime.datetime(year, month + 1, 1)\n        \n        start_date_str = start_date.isoformat()\n        end_date_str = end_date.isoformat()\n        \n        # Initialize report data\n        report = {\n            \"period\": f\"{year}-{month:02d}\",\n            \"total_cost\": 0,\n            \"team_allocation\": {},\n            \"project_allocation\": {},\n            \"user_allocation\": {}\n        }\n        \n        # Read the log file\n        with open(self.log_file, \"r\", newline=\"\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                # Only include entries for the specified month\n                if row[\"timestamp\"] \u003c start_date_str or row[\"timestamp\"] \u003e= end_date_str:\n                    continue\n                \n                # Extract data\n                estimated_cost = float(row[\"estimated_cost\"])\n                team = row.get(\"team\", \"unknown\")\n                project = row.get(\"project\", \"unknown\")\n                user_id = row.get(\"user_id\", \"unknown\")\n                \n                # Update report\n                report[\"total_cost\"] += estimated_cost\n                \n                # Update team allocation\n                if team not in report[\"team_allocation\"]:\n                    report[\"team_allocation\"][team] = 0\n                report[\"team_allocation\"][team] += estimated_cost\n                \n                # Update project allocation\n                if project not in report[\"project_allocation\"]:\n                    report[\"project_allocation\"][project] = 0\n                report[\"project_allocation\"][project] += estimated_cost\n                \n                # Update user allocation\n                if user_id not in report[\"user_allocation\"]:\n                    report[\"user_allocation\"][user_id] = 0\n                report[\"user_allocation\"][user_id] += estimated_cost\n        \n        # Calculate percentages\n        if report[\"total_cost\"] \u003e 0:\n            for team, cost in report[\"team_allocation\"].items():\n                report[\"team_allocation\"][team] = {\n                    \"cost\": cost,\n                    \"percentage\": (cost / report[\"total_cost\"]) * 100\n                }\n            \n            for project, cost in report[\"project_allocation\"].items():\n                report[\"project_allocation\"][project] = {\n                    \"cost\": cost,\n                    \"percentage\": (cost / report[\"total_cost\"]) * 100\n                }\n            \n            for user, cost in report[\"user_allocation\"].items():\n                report[\"user_allocation\"][user] = {\n                    \"cost\": cost,\n                    \"percentage\": (cost / report[\"total_cost\"]) * 100\n                }\n        \n        return report\n```\n\nIn the next section, we'll explore future trends and developments in the OpenAI API ecosystem.\n# Future Trends and Developments\n\n## Emerging Capabilities and Features\n\nThe OpenAI API ecosystem continues to evolve rapidly, with new capabilities and features being developed to enhance its utility and accessibility.\n\n### Multimodal Advancements\n\nMultimodal AI, which can process and generate multiple types of media, represents one of the most significant trends in AI development:\n\n1. **Enhanced Image Understanding**: Future models will likely have improved capabilities for understanding complex visual scenes, diagrams, and charts.\n\n2. **Video Processing**: The ability to analyze and understand video content is a natural extension of current image capabilities.\n\n3. **Audio Integration**: Voice input and output capabilities may be integrated more deeply into the API, enabling more natural conversational interfaces.\n\n4. **Cross-modal Reasoning**: Future models will excel at reasoning across different modalities, such as answering questions about images or generating images based on text descriptions.\n\n### Tool Use and Function Calling\n\nThe function calling capability is likely to expand in several ways:\n\n1. **More Complex Tool Interactions**: Models may gain the ability to use tools in more sophisticated ways, including chaining multiple tools together.\n\n2. **Autonomous Agents**: Future developments may enable the creation of more autonomous AI agents that can plan and execute complex tasks with minimal human intervention.\n\n3. **Specialized Tool Libraries**: We may see the emergence of specialized tool libraries for different domains, such as data analysis, creative writing, or scientific research.\n\n### Fine-tuning and Customization\n\nCustomization capabilities are expected to become more powerful and accessible:\n\n1. **Simplified Fine-tuning**: The process of fine-tuning models may become more streamlined and require less technical expertise.\n\n2. **Domain-Specific Optimization**: Models optimized for specific domains or industries may become more common.\n\n3. **Personalization**: Models may gain the ability to adapt to individual users' preferences and communication styles over time.\n\n## Preparing for Future API Changes\n\nAs the OpenAI API continues to evolve, developers should prepare for future changes to ensure their applications remain compatible and take advantage of new capabilities.\n\n### Versioning and Compatibility\n\n```python\nclass APIVersionManager:\n    def __init__(self):\n        \"\"\"Initialize the API version manager.\"\"\"\n        self.client = OpenAI(\n            api_key=os.environ.get(\"OPENAI_API_KEY\")\n        )\n        \n        # Define known model versions and their end-of-life dates\n        self.model_eol_dates = {\n            \"gpt-3.5-turbo-0301\": datetime.datetime(2024, 6, 13),\n            \"gpt-4-0314\": datetime.datetime(2024, 7, 5),\n            # Add more models and their EOL dates as announced\n        }\n    \n    def check_model_status(self, model):\n        \"\"\"Check if a model is deprecated or approaching EOL.\"\"\"\n        # Check if the model has a known EOL date\n        if model in self.model_eol_dates:\n            eol_date = self.model_eol_dates[model]\n            today = datetime.datetime.now()\n            \n            # Calculate days until EOL\n            days_until_eol = (eol_date - today).days\n            \n            if days_until_eol \u003c 0:\n                return {\n                    \"status\": \"deprecated\",\n                    \"message\": f\"Model {model} has been deprecated since {eol_date.strftime('%Y-%m-%d')}\",\n                    \"recommendation\": \"Upgrade to a newer model version immediately.\"\n                }\n            elif days_until_eol \u003c 30:\n                return {\n                    \"status\": \"warning\",\n                    \"message\": f\"Model {model} will be deprecated in {days_until_eol} days\",\n                    \"recommendation\": \"Plan to upgrade to a newer model version soon.\"\n                }\n            else:\n                return {\n                    \"status\": \"active\",\n                    \"message\": f\"Model {model} is active but has a scheduled EOL date of {eol_date.strftime('%Y-%m-%d')}\",\n                    \"recommendation\": \"Consider planning for an upgrade before the EOL date.\"\n                }\n        \n        # For models without known EOL dates, check if they're latest pointers\n        if model in [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4o\"]:\n            return {\n                \"status\": \"active_pointer\",\n                \"message\": f\"Model {model} is a pointer to the latest version\",\n                \"recommendation\": \"This model will automatically use the latest version, but behavior may change over time.\"\n            }\n        \n        # For specific dated versions without known EOL\n        if \"-\" in model and any(char.isdigit() for char in model):\n            return {\n                \"status\": \"specific_version\",\n                \"message\": f\"Model {model} is a specific version\",\n                \"recommendation\": \"Monitor OpenAI announcements for deprecation notices.\"\n            }\n        \n        # For unknown models\n        return {\n            \"status\": \"unknown\",\n            \"message\": f\"Model {model} status is unknown\",\n            \"recommendation\": \"Verify this is a valid model identifier.\"\n        }\n    \n    def get_recommended_upgrade_path(self, current_model):\n        \"\"\"Get the recommended upgrade path for a model.\"\"\"\n        # Define upgrade paths for known models\n        upgrade_paths = {\n            \"gpt-3.5-turbo-0301\": \"gpt-3.5-turbo\",\n            \"gpt-4-0314\": \"gpt-4\",\n            # Add more upgrade paths as needed\n        }\n        \n        if current_model in upgrade_paths:\n            return upgrade_paths[current_model]\n        \n        # For models without specific upgrade paths, recommend the latest in the same family\n        if current_model.startswith(\"gpt-3.5\"):\n            return \"gpt-3.5-turbo\"\n        elif current_model.startswith(\"gpt-4\"):\n            return \"gpt-4o\"\n        \n        # Default recommendation\n        return \"gpt-4o\"\n    \n    def create_version_resilient_client(self, preferred_model=None, fallback_models=None):\n        \"\"\"Create a client that handles model versioning gracefully.\"\"\"\n        if preferred_model is None:\n            preferred_model = \"gpt-4o\"\n        \n        if fallback_models is None:\n            fallback_models = [\"gpt-4\", \"gpt-3.5-turbo\"]\n        \n        # Check the status of the preferred model\n        model_status = self.check_model_status(preferred_model)\n        \n        if model_status[\"status\"] == \"deprecated\":\n            # If deprecated, use the recommended upgrade\n            preferred_model = self.get_recommended_upgrade_path(preferred_model)\n        \n        # Create a wrapper function for chat completions\n        def create_chat_completion(messages, temperature=0.7, max_tokens=None):\n            models_to_try = [preferred_model] + fallback_models\n            last_error = None\n            \n            for model in models_to_try:\n                try:\n                    response = self.client.chat.completions.create(\n                        model=model,\n                        messages=messages,\n                        temperature=temperature,\n                        max_tokens=max_tokens\n                    )\n                    \n                    return {\n                        \"success\": True,\n                        \"model_used\": model,\n                        \"response\": response,\n                        \"content\": response.choices[0].message.content\n                    }\n                except Exception as e:\n                    last_error = str(e)\n                    print(f\"Error with model {model}: {last_error}\")\n                    continue\n            \n            # If all models fail\n            return {\n                \"success\": False,\n                \"error\": last_error\n            }\n        \n        return create_chat_completion\n```\n\n### Staying Informed About API Changes\n\nTo stay informed about API changes and new features:\n\n1. **Subscribe to the OpenAI Newsletter**: The official newsletter provides updates on new features, model releases, and deprecation notices.\n\n2. **Follow the OpenAI Blog**: The blog often contains detailed information about new capabilities and best practices.\n\n3. **Join the Developer Community**: Participating in forums and community discussions can provide early insights into changes and workarounds.\n\n4. **Monitor the OpenAI Status Page**: The status page provides information about service disruptions and planned maintenance.\n\n5. **Set Up Automated Monitoring**: Implement automated monitoring for API changes and deprecation notices:\n\n```python\nimport requests\nimport json\nimport datetime\nimport os\n\nclass APIChangeMonitor:\n    def __init__(self, cache_file=\"api_changes_cache.json\"):\n        \"\"\"Initialize the API change monitor.\"\"\"\n        self.cache_file = cache_file\n        self.last_check = None\n        self.known_changes = []\n        \n        # Load cache if it exists\n        if os.path.exists(cache_file):\n            with open(cache_file, \"r\") as f:\n                cache_data = json.load(f)\n                self.last_check = datetime.datetime.fromisoformat(cache_data[\"last_check\"])\n                self.known_changes = cache_data[\"known_changes\"]\n    \n    def check_for_changes(self):\n        \"\"\"Check for API changes and updates.\"\"\"\n        # In a real implementation, this would call an API or scrape the OpenAI website\n        # For demonstration purposes, we'll simulate checking for changes\n        \n        # Record the check time\n        current_time = datetime.datetime.now()\n        \n        # Simulate fetching changes\n        new_changes = self._fetch_changes()\n        \n        # Filter out already known changes\n        known_change_ids = [change[\"id\"] for change in self.known_changes]\n        truly_new_changes = [change for change in new_changes if change[\"id\"] not in known_change_ids]\n        \n        # Update the cache\n        self.known_changes.extend(truly_new_changes)\n        self.last_check = current_time\n        \n        # Save the updated cache\n        with open(self.cache_file, \"w\") as f:\n            json.dump({\n                \"last_check\": self.last_check.isoformat(),\n                \"known_changes\": self.known_changes\n            }, f, indent=2)\n        \n        return truly_new_changes\n    \n    def _fetch_changes(self):\n        \"\"\"Simulate fetching changes from the OpenAI API or website.\"\"\"\n        # In a real implementation, this would make HTTP requests\n        # For demonstration, we'll return simulated changes\n        \n        return [\n            {\n                \"id\": \"change-001\",\n                \"date\": \"2025-03-15\",\n                \"title\": \"GPT-4o Now Available\",\n                \"description\": \"GPT-4o is now available through the API, offering improved performance and multimodal capabilities.\",\n                \"impact\": \"low\",\n                \"type\": \"new_feature\"\n            },\n            {\n                \"id\": \"change-002\",\n                \"date\": \"2025-04-01\",\n                \"title\": \"GPT-3.5-turbo-0301 Deprecation\",\n                \"description\": \"GPT-3.5-turbo-0301 will be deprecated on June 13, 2025. Please migrate to the latest GPT-3.5-turbo model.\",\n                \"impact\": \"medium\",\n                \"type\": \"deprecation\"\n            }\n        ]\n    \n    def get_high_impact_changes(self, days=30):\n        \"\"\"Get high-impact changes from the last N days.\"\"\"\n        cutoff_date = datetime.datetime.now() - datetime.timedelta(days=days)\n        \n        high_impact_changes = []\n        for change in self.known_changes:\n            change_date = datetime.datetime.fromisoformat(change[\"date\"])\n            if change_date \u003e= cutoff_date and change[\"impact\"] in [\"medium\", \"high\"]:\n                high_impact_changes.append(change)\n        \n        return high_impact_changes\n```\n\n## Community Resources and Support\n\nThe OpenAI API has a vibrant community of developers and resources that can help you stay up-to-date and solve problems.\n\n### Official Resources\n\n1. **OpenAI Documentation**: The official documentation is the primary source of information about the API.\n\n2. **OpenAI Cookbook**: The cookbook contains practical examples and guides for common use cases.\n\n3. **OpenAI Help Center**: The help center provides answers to frequently asked questions and troubleshooting guides.\n\n### Community Resources\n\n1. **GitHub Repositories**: Many developers share their projects and examples on GitHub.\n\n2. **Stack Overflow**: Stack Overflow has a growing number of questions and answers related to the OpenAI API.\n\n3. **Reddit Communities**: Subreddits like r/OpenAI and r/MachineLearning often discuss API-related topics.\n\n4. **Discord Servers**: Several Discord servers are dedicated to AI development and the OpenAI API.\n\n### Building Your Own Knowledge Base\n\nCreating your own knowledge base of API information and examples can be valuable:\n\n```python\nclass APIKnowledgeBase:\n    def __init__(self, base_dir=\"openai_api_knowledge\"):\n        \"\"\"Initialize the API knowledge base.\"\"\"\n        self.base_dir = base_dir\n        \n        # Create the base directory if it doesn't exist\n        os.makedirs(base_dir, exist_ok=True)\n        \n        # Create subdirectories for different types of information\n        self.directories = {\n            \"examples\": os.path.join(base_dir, \"examples\"),\n            \"errors\": os.path.join(base_dir, \"errors\"),\n            \"solutions\": os.path.join(base_dir, \"solutions\"),\n            \"best_practices\": os.path.join(base_dir, \"best_practices\")\n        }\n        \n        for directory in self.directories.values():\n            os.makedirs(directory, exist_ok=True)\n    \n    def add_example(self, title, code, description, tags=None):\n        \"\"\"Add a code example to the knowledge base.\"\"\"\n        if tags is None:\n            tags = []\n        \n        # Create a filename from the title\n        filename = self._create_filename(title)\n        filepath = os.path.join(self.directories[\"examples\"], filename)\n        \n        # Create the example content\n        content = f\"\"\"# {title}\n\n## Description\n{description}\n\n## Tags\n{', '.join(tags)}\n\n## Code\n```python\n{code}\n```\n\n## Date Added\n{datetime.datetime.now().strftime('%Y-%m-%d')}\n\"\"\"\n        \n        # Save the example\n        with open(filepath, \"w\") as f:\n            f.write(content)\n        \n        return filepath\n    \n    def add_error_solution(self, error_message, solution, context=None, tags=None):\n        \"\"\"Add an error solution to the knowledge base.\"\"\"\n        if tags is None:\n            tags = []\n        \n        if context is None:\n            context = \"\"\n        \n        # Create a filename from the error message\n        filename = self._create_filename(error_message[:50])\n        filepath = os.path.join(self.directories[\"errors\"], filename)\n        \n        # Create the error solution content\n        content = f\"\"\"# Error: {error_message}\n\n## Context\n{context}\n\n## Solution\n{solution}\n\n## Tags\n{', '.join(tags)}\n\n## Date Added\n{datetime.datetime.now().strftime('%Y-%m-%d')}\n\"\"\"\n        \n        # Save the error solution\n        with open(filepath, \"w\") as f:\n            f.write(content)\n        \n        return filepath\n    \n    def add_best_practice(self, title, content, category=None, tags=None):\n        \"\"\"Add a best practice to the knowledge base.\"\"\"\n        if tags is None:\n            tags = []\n        \n        if category is None:\n            category = \"General\"\n        \n        # Create a filename from the title\n        filename = self._create_filename(title)\n        filepath = os.path.join(self.directories[\"best_practices\"], filename)\n        \n        # Create the best practice content\n        formatted_content = f\"\"\"# {title}\n\n## Category\n{category}\n\n## Best Practice\n{content}\n\n## Tags\n{', '.join(tags)}\n\n## Date Added\n{datetime.datetime.now().strftime('%Y-%m-%d')}\n\"\"\"\n        \n        # Save the best practice\n        with open(filepath, \"w\") as f:\n            f.write(formatted_content)\n        \n        return filepath\n    \n    def search(self, query, categories=None):\n        \"\"\"Search the knowledge base for entries matching the query.\"\"\"\n        if categories is None:\n            categories = list(self.directories.keys())\n        \n        results = []\n        \n        for category in categories:\n            if category not in self.directories:\n                continue\n            \n            directory = self.directories[category]\n            \n            for filename in os.listdir(directory):\n                filepath = os.path.join(directory, filename)\n                \n                with open(filepath, \"r\") as f:\n                    content = f.read()\n                \n                if query.lower() in content.lower():\n                    # Extract the title from the first line\n                    title = content.split(\"\\n\")[0].strip(\"# \")\n                    \n                    results.append({\n                        \"category\": category,\n                        \"title\": title,\n                        \"filepath\": filepath,\n                        \"preview\": content[:200] + \"...\" if len(content) \u003e 200 else content\n                    })\n        \n        return results\n    \n    def _create_filename(self, title):\n        \"\"\"Create a filename from a title.\"\"\"\n        # Replace spaces with underscores and remove special characters\n        filename = \"\".join(c if c.isalnum() or c == \" \" else \"_\" for c in title)\n        filename = filename.replace(\" \", \"_\").lower()\n        \n        # Add .md extension\n        return f\"{filename}.md\"\n```\n\n## Conclusion and Next Steps\n\nThe OpenAI API represents a powerful tool for developers looking to integrate advanced AI capabilities into their applications. By understanding its features, best practices, and future trends, you can leverage its full potential while managing costs and ensuring reliability.\n\n### Key Takeaways\n\n1. **Understand the API Structure**: Familiarize yourself with the different components of the API, including the Chat Completions API, Responses API, and specialized services.\n\n2. **Choose the Right Model**: Select the appropriate model for your use case based on capability requirements, context length needs, and budget constraints.\n\n3. **Implement Best Practices**: Follow best practices for error handling, rate limiting, and security to build robust applications.\n\n4. **Optimize for Cost**: Use techniques like caching, batching, and prompt optimization to manage API costs effectively.\n\n5. **Stay Informed**: Keep up with API changes and new features to ensure your applications remain compatible and take advantage of new capabilities.\n\n### Getting Started\n\nIf you're new to the OpenAI API, here are some recommended next steps:\n\n1. **Create an OpenAI Account**: Sign up at [platform.openai.com](https://platform.openai.com) to get your API key.\n\n2. **Explore the Documentation**: Review the official documentation to understand the API's capabilities and limitations.\n\n3. **Start with Simple Examples**: Begin with basic examples to familiarize yourself with the API before building more complex applications.\n\n4. **Join the Community**: Engage with the developer community to learn from others' experiences and share your own.\n\n5. **Experiment and Iterate**: The best way to learn is by doing. Start building, experiment with different approaches, and iterate based on results.\n\nBy following these guidelines and leveraging the information in this guide, you'll be well-equipped to build powerful, cost-effective applications with the OpenAI API.\n\nHappy building!\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 py-12\",\"children\":[[\"$\",\"$L13\",null,{\"href\":\"/blog\",\"className\":\"inline-flex items-center text-blue-600 hover:text-blue-800 mb-6 transition-colors duration-200\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":20,\"height\":20,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left mr-2\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"text-lg\",\"children\":\"Back to blog\"}]]}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 lg:grid-cols-[1fr_280px] gap-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-3xl mx-auto lg:mx-0 w-full\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-3xl md:text-4xl lg:text-5xl font-bold mb-6 text-gray-900 dark:text-white leading-tight\",\"children\":\"The Complete Guide to OpenAI API: A Practical Developer's Handbook\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center text-sm text-gray-600 dark:text-gray-400 mb-8 space-x-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":16,\"height\":16,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-calendar mr-2\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1cmpym\",{\"d\":\"M8 2v4\"}],[\"$\",\"path\",\"4m81vk\",{\"d\":\"M16 2v4\"}],[\"$\",\"rect\",\"1hopcy\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"8toen8\",{\"d\":\"M3 10h18\"}],\"$undefined\"]}],\"2025-04-03\"]}],[\"$\",\"span\",null,{\"className\":\"flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":16,\"height\":16,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-clock mr-2\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"polyline\",\"68esgv\",{\"points\":\"12 6 12 12 16 14\"}],\"$undefined\"]}],\"125 min read\"]}],[\"$\",\"span\",null,{\"className\":\"flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":16,\"height\":16,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag mr-2\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"Artificial Intelligence\"]}],[\"$\",\"span\",null,{\"className\":\"flex items-center\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":16,\"height\":16,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-user mr-2\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"975kel\",{\"d\":\"M19 21v-2a4 4 0 0 0-4-4H9a4 4 0 0 0-4 4v2\"}],[\"$\",\"circle\",\"17ys0d\",{\"cx\":\"12\",\"cy\":\"7\",\"r\":\"4\"}],\"$undefined\"]}],\"Hung Pham\"]}]]}],[\"$\",\"$L14\",null,{\"src\":\"$undefined\",\"alt\":\"The Complete Guide to OpenAI API: A Practical Developer's Handbook\",\"width\":800,\"height\":400,\"className\":\"rounded-lg mb-8 object-cover w-full\"}],[\"$\",\"div\",null,{\"className\":\"block lg:hidden mb-8\",\"children\":[\"$\",\"$L15\",null,{\"className\":\"bg-gray-50 dark:bg-gray-800/50 p-3 rounded-lg shadow-sm\"}]}],[\"$\",\"article\",null,{\"className\":\"overflow-hidden\",\"children\":[[\"$\",\"$L16\",null,{\"content\":\"$17\"}],\"$L18\",\"$L19\"]}]]}],\"$L1a\"]}]]}]\n"])</script><script>self.__next_f.push([1,"18:[\"$\",\"div\",null,{\"className\":\"mt-12\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-2xl font-semibold mb-4 text-gray-900 dark:text-white\",\"children\":\"Tags\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-12\",\"children\":[[\"$\",\"span\",\"AI\",{\"className\":\"bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium\",\"children\":\"AI\"}],[\"$\",\"span\",\"OpenAI\",{\"className\":\"bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium\",\"children\":\"OpenAI\"}],[\"$\",\"span\",\"API\",{\"className\":\"bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium\",\"children\":\"API\"}],[\"$\",\"span\",\"Web Development\",{\"className\":\"bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium\",\"children\":\"Web Development\"}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium\",\"children\":\"AI Agents\"}],[\"$\",\"span\",\"AI Tools\",{\"className\":\"bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200 px-3 py-1 rounded-full text-sm font-medium\",\"children\":\"AI Tools\"}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold mb-4\",\"children\":\"Related Posts\"}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-2 gap-4\",\"children\":[[\"$\",\"a\",\"building-ai-agents-nextjs-langchain\",{\"className\":\"block rounded-lg shadow-md hover:shadow-lg transition-all duration-300 border border-gray-200 dark:border-gray-700 p-6\",\"href\":\"/blog/building-ai-agents-nextjs-langchain\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-semibold text-gray-900 dark:text-white\",\"children\":\"Building AI Agents with Next.js and LangChain: A Comprehensive Guide\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 dark:text-gray-400 leading-relaxed\",\"children\":\"Explore the fascinating world of AI agents and learn how to build them using Next.js and LangChain. This guide covers everything from the basics to advanced techniques.\"}]]}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"19:[\"$\",\"div\",null,{\"className\":\"mt-16 pt-8 border-t border-gray-200 dark:border-gray-700\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-2xl font-semibold mb-6 text-gray-900 dark:text-white\",\"children\":\"About the Author\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center bg-gray-100 dark:bg-gray-800 p-6 rounded-lg\",\"children\":[[\"$\",\"$L14\",null,{\"src\":{\"src\":\"/_next/static/media/LowkeyDev.9bd0d6a3.png\",\"height\":320,\"width\":320,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAPFBMVEX9/f3Bu7Pn5eKMfnCrm5abhH3z8fH5+fl1YVP39/eEal6CXlqIc2q7sKm0qKSakIzV0c1IMimgb23W0dGyihgCAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAOklEQVR4nAXBhQHAIBAAsYN3rLb/rk2IzwmiCDvlXR10bU0r6qTKo+Bmr60LXOYcowE7M6VDxN1ap34/JwGqUX/NFwAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":8},\"alt\":\"Hung Pham\",\"width\":80,\"height\":80,\"className\":\"rounded-full mr-6\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-xl font-semibold mb-2 text-gray-900 dark:text-white\",\"children\":\"Hung Pham\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 dark:text-gray-400 leading-relaxed\",\"children\":\"A passionate Software Developer and technologist exploring the intersections of code and creativity.\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"1a:[\"$\",\"aside\",null,{\"className\":\"hidden lg:block\",\"children\":[\"$\",\"div\",null,{\"className\":\"sticky top-24\",\"children\":[\"$\",\"$L15\",null,{\"className\":\"bg-gray-50 dark:bg-gray-800/50 p-3 rounded-lg shadow-sm\"}]}]}]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\na:null\n"])</script><script>self.__next_f.push([1,"1b:I[80622,[],\"IconMark\"]\nc:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"The Complete Guide to OpenAI API: A Practical Developer's Handbook | Hung Pham\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Explore a complete guide to the OpenAI API, covering everything from setup and core functionality to advanced features, performance optimization, error handling, and practical use cases. Perfect for developers looking to integrate and leverage OpenAI models effectively.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"$L1b\",\"3\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"11:\"$c:metadata\"\n"])</script></body></html>